[["index.html", "NEON Ecological Forecasting Challenge Introduction", " NEON Ecological Forecasting Challenge Hosted by the Ecological Forecasting Initative Research Coordination Network and supported by National Science Foundation (DEB-1926388) Last modified: 2022-03-31 Introduction The National Science Foundation funded Ecological Forecasting Initiative Research Coordination Network (EFI-RCN) is hosting a NEON Ecological Forecast Challenge with the goal to create a community of practice that builds capacity for ecological forecasting by leveraging NEON data products. The Challenge revolves around the five theme areas listed below that span aquatic and terrestrial systems, and population, community, and ecosystem processes across a broad range of ecoregions that uses data collected by NEON. As a community, we are excited to learn more about the predictability of ecological processes by forecasting NEON data prior to its release. What modeling frameworks, mechanistic processes, and statistical approaches best capture community, population, and ecosystem dynamics? These questions are answerable by a community generating a diverse array of forecasts. The Challenge is open to any individual or team that wants to submit forecasts and includes categories for different career stages. Individuals or team contacts can register to submit forecasts Here The design of the Challenge is the result of contributions of over 200 participants in the May 2020 virtual EFI-RCN meeting, including partner organizations, and the hard work from the Design Teams that have developed the protocols for each of the themes. Computational resources are supported by NSF funded CyVerse, Jetstream, and XSEDE. We have prepared introductory videos from the December 9, 2020 AGU EFI Town Hall. They provide an overview of the Challenge Challenge cyberinfrastructure NEON data streams EFI-RCN Steering Committee Lead: R. Quinn Thomas (Virginia Tech) Program Manager: Jody Peters (University of Notre Dame) Michael Dietze (Boston University) Melissa Kenney (University of Minnesota) Christine Laney (NEON) Jason McLachlan (University of Notre Dame) Carl Boettiger (University of California, Berkeley) Cayelan Carey (Virginia Tech) Andy Fox (UCAR) Leah Johnson (Virginia Tech) Whitney Woelmer (Virginia Tech; Student member) Alyssa Willson (University of Notre Dame; Student member) Video Introducng the NEON Ecological Forecasting Challenge. This video was originally recorded for the 2021 Early Career Annual Meeting "],["theme-aquatic-ecosystems.html", "1 Theme: Aquatic Ecosystems 1.1 Overview 1.2 Challenge 1.3 Data: Targets 1.4 Timeline 1.5 Observed data latency 1.6 Submissions 1.7 Meterological inputs for modeling 1.8 Useful functions 1.9 Null models 1.10 FAQ 1.11 Design Team 1.12 Partners 1.13 References", " 1 Theme: Aquatic Ecosystems What: Freshwater surface water temperature, oxygen, and chlorophyll-a. Where: 2 lakes and 3 river/stream NEON sites. When: Forecasts produced daily with a 35-day forecast horizon. Forecast submissions are accepted daily throughout 2022. The only requirement is that submissions are predictions of the future at the time the forecast is submitted. Why: Freshwater surface water temperature, dissolved oxygen, and chlorophyll-a are critical for life in aquatic environments and can represent the health of the system Who: Open to any individual or team that registers How: REGISTER your team and submit forecast. If you registered for the Round 1 (2021) and are using the same team and method then you do not need to re-register. The video below is an overview of the Aquatic Ecosystems Challenge that was recorded for the 2021 Early Career Annual Meeting We held a Q&amp;A session on May 21, 2021. You can find a recording from that session HERE. 1.1 Overview In streams and rivers, forecasting water temperature can be meaningful for protecting aquatic communities while maintaining socio-economic benefits (Ouellet-Proulx et al. 2017). In lentic systems, successfully forecasting surface water temperatures can be important for fisheries and water utilities that need to manage the outflowing temperatures (Zhu et al. 2020). Recently, water temperature forecasts in lakes have been used to predict seasonal turnover when nutrients from the bottom can be mixed to the surface and impair the water quality. Dissolved oxygen concentration is a critically important variable in limnology. Forecasts of dissolved oxygen in freshwaters is the first step to understanding other freshwater ecosystem processes. For example, oxygen serves as the gatekeeper to other biogeochemical reactions that occur in rivers and lakes. Preemptive forecasts of dissolved oxygen concentrations can anticipate periods of high or low oxygen availability, thereby providing insight into how the ecosystem may change at relatively short timescales. chlorophyll-a is a metric of phytoplankton biomass. Phytoplankton biomass are the base of the aquatic food-web and an important indicator of water quality for managers. 1.2 Challenge This design challenge asks teams to produce forecasts of mean daily surface water temperature, dissolved oxygen, and/or chlorophyll-a in 2 NEON lake and/or 3 NEON river/stream sites for 35-days in the future. You can chose to submit to either the lakes or the streams or both. You can also chose to submit any of the three focal variables (temperature, oxygen, and chlorophyll). Teams are asked to submit their 35-day forecasts of NEON surface mean daily surface water temperature, dissolved oxygen, and/or chlorophyll-a along with uncertainty estimates and metadata. NEON surface water temperature, dissolved oxygen, and chlorophyll-a collected prior to the current date will be provided and may be used to build and improve the forecast models. Other data can be used as long as teams provide access (minimum of URL, but ideally a script) to all teams in the challenge. 1.3 Data: Targets The R script for generating the evaluation and training data (i.e., targets) can be found at: https://github.com/eco4cast/neon4cast-aquatics The challenge uses the following NEON data products: - DP1.20264.001: Temperature at specific depth in surface water - DP1.20288.001: Water quality (includes oxygen and chlorophyll-a) A file with previously released NEON data that has been processed into targets is provided below. The target script can be found here. The same processing will be applied to new data that are used for forecast evaluation. Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/aquatics/aquatics-targets.csv.gz&quot;) ## # A tibble: 9,763 × 10 ## time siteID oxygen temperature chla oxygen_sd temperature_sd chla_sd ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2017-08-27 BARC NA 31.4 NA NA 0.00162 NA ## 2 2017-08-27 BARC NA 31.5 NA NA 0.00121 NA ## 3 2017-08-28 BARC NA 31.1 NA NA 0.00155 NA ## 4 2017-08-28 BARC NA 31.1 NA NA 0.00117 NA ## 5 2017-08-29 BARC NA 31.2 NA NA 0.00211 NA ## 6 2017-08-29 BARC NA 31.1 NA NA 0.00168 NA ## 7 2017-08-30 BARC NA 31.5 NA NA 0.00208 NA ## 8 2017-08-30 BARC NA 31.4 NA NA 0.00210 NA ## 9 2017-08-31 BARC NA 31.7 NA NA 0.00193 NA ## 10 2017-08-31 BARC NA 31.7 NA NA 0.00176 NA ## # … with 9,753 more rows, and 2 more variables: depth_oxygen &lt;dbl&gt;, ## # depth_temperature &lt;dbl&gt; The target file has the following columns time: date of observation siteID: NEON site code oxygen: oxygen (mg/L) temperature: temperature (Celsius) chla: chlorophyll-a (mg/L) oxygen_sd: standard deviation of oxygen observation as reported by NEON temperature_sd: standard deviation of temperature observation as reported by NEON chla_sd: standard deviation of temperature observation as reported by NEON depth_oxygen: depth in meters of oxygen and chlorophyll observation depth_temperature: depth in meters of temperature observation 1.3.1 Surface Mean Daily Dissolved Oxygen Concentration Definition Dissolved oxygen (DO) is the concentration of oxygen dissolved in water. NEON’s 30-minute time resolution from deployed water quality sondes among the freshwater sites reports this concentration as mg L-1. We have adapted the available NEON DO data to output the mean daily DO concentration in mg L-1 from a water quality sonde deployed 1m below the water surface at a lake site (BARC and CRAM) and a water quality sonde deployed in a stream site (COMO, MCDI, POSE). Common DO concentrations range between 0 and 12 mg L-1 and DO concentrations less than 2 mg L-1 are considered hypoxic. Motivation Dissolved oxygen concentration is a critically important variable in limnology. Forecasts of dissolved oxygen in freshwaters is the first step to understanding other freshwater ecosystem processes. For example, oxygen serves as the gatekeeper to other biogeochemical reactions that occur as well as determine the variety and health of aquatic organisms present in rivers and lakes. Preemptive forecasts of dissolved oxygen concentrations can anticipate periods of high or low oxygen availability, thereby providing insight into how the ecosystem may change at relatively short timescales. 1.3.2 Surface Mean Daily Water Temperature Definition Water temperature is the temperature of the water. NEON’s 30-minute time resolution from deployed water temperature sondes in the freshwater sites reports this in degrees Celsius (°C). We have adapted the available NEON water temperature data to output the mean daily water temperature in °C from temperature thermisters deployed 0-1m below the water surface at the lake sites (BARC and CRAM) and a water temperature sonde deployed in a stream site (COMO, MCDI, POSE). Common water temperatures in lakes and streams range between 4 and 35 °C. Motivation In streams and rivers, forecasting water temperature can be meaningful for protecting aquatic communities while maintaining socio-economic benefits (Ouellet-Proulx et al. 2017). In lentic and lotic systems, successfully forecasting water temperatures can be important for management of fisheries and water utilities that rely on specific threshold temperatures (Zhu et al. 2020). Recently, lake temperature forecasts have been used to predict seasonal turnover, mixing bottom nutrients into the surface and impairing water quality. 1.3.3 Chlorophyll-a Definition chlorophyll-a (chla) is the concentration of chlorophyll-a in the water column, as measured using florescence. NEON’s 30-minute time resolution from deployed water quality sondes among the freshwater sites reports this concentration as mg L-1. We have adapted the available NEON chla data to output the mean daily chla concentration in mg L-1 from a water quality sonde deployed ~-0.3 - 1m below the water surface at a lake site (BARC and CRAM) and a water quality sonde deployed in a stream site (COMO, MCDI, POSE). Motivation Phytoplankton biomass are the base of the aquatic food-web and an important indicator of water quality for managers. 1.3.4 Focal sites Information on the sites can be found here: site_data &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/eco4cast/neon4cast-aquatics/master/Aquatic_NEON_Field_Site_Metadata_20210928.csv&quot;) siteID site name waterbody type latitude longtitude NEON site URL BARC Lake Barco NEON Lake 29.67598 -82.00841 https://www.neonscience.org/field-sites/barc COMO Como Creek NEON Wadeable Stream 40.03496 -105.54416 https://www.neonscience.org/field-sites/como CRAM Crampton Lake NEON Lake 46.20967 -89.47369 https://www.neonscience.org/field-sites/cram MCDI McDiffett Creek NEON Wadeable Stream 38.94586 -96.44302 https://www.neonscience.org/field-sites/mcdi POSE Posey Creek NEON Wadeable Stream 38.89431 -78.14726 https://www.neonscience.org/field-sites/pose 1.4 Timeline Forecasts for a minimum of 35 days can be submitted daily by 11:59 pm UTC throughout 2022. A minimum of 35 days in the future must be forecasted for each submission. For example, a forecast submitted on February 1 should be for at least February 1st – March 7th. New forecasts can be submitted daily as new weather forecasts and observations (e.g., new flux data is released by NEON) become available. The key is that submissions are predictions of the future. Even that daily submissions are allowed and encouraged as new observations and weather forecasts become available, the automation of forecast generation may be ideal. There are many ways to automate scripts that are written to download observations and meteorology drivers, generate forecasts, and submit forecasts. Two tools that many have used are cron jobs (see the R package cronR) that execute tasks at user specified times and github actions. See more at Frequently Asked Questions Cron jobs work on unix and mac systems. An example of a script that executes a cron job using R can be found here. 1.5 Observed data latency NEON data officially releases the temperature, oxygen, and chlorophyll-a data on their data portal and API in monthly data packages. Data for a given month is scheduled to be released around the 15th of the following month. As a result there will be a gap of 2 weeks - 6 weeks between the last available observation and the start of your forecast. 1.6 Submissions Instructions for submitting forecasts are found here: Submission Instructions The specific file format for the aquatics theme is here: Aquatics 1.7 Meterological inputs for modeling Information about forecasted meteorology that is available for you to use when generating your forecasts can be found here: Meteorology Inputs 1.8 Useful functions Functions for validating, evaluating and submitting forecasts can be found here: Helpful Functions Functions for downloading and working with the meteorology forecasts can be be found here: Access EFI snapshots of NOAA forecasts at NEON sites 1.9 Null models A climatology null model is automatically generated each day to served as a simple baseline model. This climatology null model forecasts that the nee or lee will be equal to the historical mean of that day of year. Code for the climatology null model can be found here 1.10 FAQ Answers to frequency asks questions can be found here: Frequently Asked Questions 1.11 Design Team James Guinnip, Kansas State University Sarah Burnet, University of Idaho Ryan McClure, Virginia Tech Chris Brown, National Oceanic and Atmospheric Administration Cayelan Carey, Virginia Tech Whitney Woelmer, Virginia Tech Jake Zwart, United States Geological Survey 1.12 Partners The challenge is hosted by the Ecological Forecasting Initiative (EFI; https://ecoforecast.org/) and its U.S. National Science Foundation sponsored Research Coordination Network (EFI-RCN; https://ecoforecast.org/rcn/). Data used in the challenge are from the National Ecological Observatory Network (NEON): https://www.neonscience.org/. Scientists from NOAA and USGS have been involved in the design of the challenge. 1.13 References Ouellet-Proulx, S., St-Hilaire, A., and Bouchar, M.-A.. 2017. Water temperature ensemble forecasts: Implementation using the CEQUEAU model on two contrasted river systems. Water 9(7):457. https://doi.org/10.3390/w9070457 Zhu, S., Ptak, M., Yaseen, Z.M., Dai, J. and Sivakumar, B. 2020. Forecasting surface water temperature in lakes: a comparison of approaches. Journal of Hydrology 585, 124809. https://doi.org/10.1016/j.jhydrol.2020.124809 "],["theme-carbon-and-water-fluxes.html", "2 Theme: Carbon and Water Fluxes 2.1 Overview 2.2 Challenge 2.3 Data: Targets 2.4 Timeline 2.5 Flux data latency 2.6 Submissions 2.7 Meterological inputs for modeling 2.8 Null models 2.9 FAQ 2.10 Design team 2.11 Partners", " 2 Theme: Carbon and Water Fluxes What: Net ecosystem exchange of CO2 and evapotranspiration in terrestrial ecosystems Where: 10 NEON sites across the conterminous U.S. When: Daily forecasts for 35-days in the future. Forecast submissions are accepted daily throughout 2022. The only requirement is that submissions are predictions of the future at the time the forecast is submitted. Why: Carbon and water cycling are fundamental for climate and water regulation services provided by ecosystems Who: Open to any individual or team that registers How: REGISTER your team and submit forecast. If you registered for the Round 1 (2021) and are using the same team and method then you do not need to re-register. The video below is an overview of the Terrestrial Carbon and Water Fluxes Challenge that was recorded for the 2021 Early Career Annual Meeting We held a Q&amp;A session on January 22, 2021. You can find a recording from that session HERE. 2.1 Overview The exchange of water and carbon dioxide between the atmosphere and the land is akin to earth’s terrestrial ecosystems breathing rate and lung capacity. One of the best ways to monitor changes in the amount of carbon and water in an ecosystem is the eddy-covariance method. This method observes the net amount of carbon and water entering and exiting ecosystems at half-hourly timesteps, which is important because it can provide information on ecosystem processes such as photosynthesis, respiration, and transpiration, their sensitivities to ongoing climate and land use change, and greenhouse gas budgets for carbon accounting and natural climate solutions. Forecasts of carbon uptake and release along with water use can provide insights into future production of food, fiber, timber, and carbon credits. Additionally, forecasts will highlight the influence that stress and disturbance have on carbon and water cycling. 2.2 Challenge This forecasting challenge asks teams to forecast net ecosystem exchange of carbon dioxide (NEE) and latent heat flux of evapotranspiration (LE) across 10 NEON sites with differing climates. Forecasts can be submitted the 30-minute and/or daily time step over the next 35-days. Weather forecasts from NOAA Global Ensemble Forecast System are provided to use as model drivers (if forecasting model uses meteorological inputs). Forecasts can be submitted each day in 2022. Teams are asked to submit their forecast of measured NEON NEE and LE, along with uncertainty estimates and metadata. Any existing NEE and LE may be used to build and improve the models used to generate forecasts. Other data can be used so long as they are not from the month being forecast and the data are made publicly available (minimum of URL, but ideally a script) and accessible to all teams in the challenge. 2.3 Data: Targets The challenge uses the following NEON data products: DP4.00200.001: Bundled data products - eddy covariance A file with previously released NEON data that has been processed into “targets” is provided below. The same processing will be applied to new data that are used for forecast evaluation. A processing script is available on the neon4cast-terrestrial GitHub repository: https://github.com/eco4cast/neon4cast-terrestrial/blob/master/02_terrestrial_targets.R 2.3.1 Net ecosystem exchange Definition Net ecosystem exchange (NEE) is the net movement of carbon dioxide from the atmosphere to the ecosystem. At the 30-minute time resolution it is reported as \\(\\mu\\)mol CO2 m-2 s-1. At the daily time resolution it is reported as g C m-2 day-1. Negative values correspond to an ecosystem absorbing CO2 from the atmosphere, positive values correspond to an ecosystem emitting CO2 to the atmosphere. Motivation NEE quantifies the net exchange of CO2 between the ecosystem and the atmosphere over that 30-minute or daily time period. Assessing skill at predicting 1/2 hourly - sub daily measurements provides more insight into ability to capture diel processes. The diel curve contains information on how plants and soil immediately respond to variations in meteorology. Making daily predictions will allow us to rapidly assess skill and provide information in a timeframe pertinent to inform and implement natural resource management. It also allows for models that do not produce sub-daily estimates to participate 2.3.2 Latent heat flux Definition Latent heat flux is the movement of water as water vapor from the ecosystem to the atmosphere. It is reported as W m-2 (equivalent to J m-2 s-1). At the daily time resolution it is reported as mean W m-2. Positive values correspond to a transfer of water vapor from the ecosystem to the atmosphere. Motivation Latent heat measures the water loss from an ecosystem to the atmosphere through evapotranspiration (transpiration through plants + evaporation from surfaces). Forecasting latent heat (evapotranspiration) can provide insights to water stress for plants and the efficiency that plants are using water relative to NEE, and to the amount of liquid water remaining in the soil for soil moisture forecasting 2.3.3 Focal sites Information on the sites can be found here: site_data &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/eco4cast/neon4cast-terrestrial/master/Terrestrial_NEON_Field_Site_Metadata_20210928.csv&quot;) siteID site name vegetation type latitude longtitude NEON site URL BART Bartlett Experimental Forest NEON Deciduous Forest|Evergreen Forest|Mixed Forest 44.06389 -71.28737 https://www.neonscience.org/field-sites/bart CLBJ Lyndon B. Johnson National Grassland NEON Deciduous Forest|Grassland/Herbaceous 33.40123 -97.57000 https://www.neonscience.org/field-sites/clbj KONZ Konza Prairie Biological Station NEON Deciduous Forest|Grassland/Herbaceous 39.10077 -96.56307 https://www.neonscience.org/field-sites/konz ORNL Oak Ridge NEON Deciduous Forest|Evergreen Forest|Pasture/Hay 35.96413 -84.28259 https://www.neonscience.org/field-sites/ornl OSBS Ordway-Swisher Biological Station NEON Emergent Herbaceous Wetlands|Evergreen Forest|Woody Wetlands 29.68928 -81.99343 https://www.neonscience.org/field-sites/osbs SJER San Joaquin Experimental Range NEON Evergreen Forest|Grassland/Herbaceous|Shrub/Scrub 37.10878 -119.73228 https://www.neonscience.org/field-sites/sjer SRER Santa Rita Experimental Range NEON Shrub/Scrub 31.91068 -110.83549 https://www.neonscience.org/field-sites/srer TALL Talladega National Forest NEON Deciduous Forest|Evergreen Forest|Mixed Forest 32.95047 -87.39326 https://www.neonscience.org/field-sites/tall UNDE University of Notre Dame Environmental Research Center NEON Deciduous Forest|Mixed Forest|Woody Wetlands 46.23391 -89.53725 https://www.neonscience.org/field-sites/unde WREF Wind River Experimental Forest NEON Evergreen Forest 45.82049 -121.95191 https://www.neonscience.org/field-sites/wref 2.3.4 30-minute target data calculation To create the data for evaluation (and training) for NEE and LE we extract NEE and LE that pass the turbulence quality control flags (qfqm.fluxCo2.turb.qfFinl = 0 ) provided by NEON and has flux values between -50 and 50 umol CO2 m-2 s-1. The table with the half-hour NEE and LE has the following columns time: YYYY-MM-DD HH:MM for the start of the 30-minute period in UTC siteID: NEON site code (e.g., BART) nee: umol CO2 m-2 s-1 le: W m-2 nee_sd_intercept: intercept in the nee observation uncertainty standard deviation nee_sd_slopeP: slope in the relationship between nee and observation uncertainty standard deviation for positive values of nee nee_sd_slopeN: slope in the relationship between nee and observation uncertainty standard deviation for negative values of nee le_sd_intercept: intercept in the le observation uncertainty standard deviation le_sd_slopeP:slope in the relationship between le and observation uncertainty standard deviation for positive values of le le_sd_slopeN: slope in the relationship between le and observation uncertainty standard deviation for negative values of le The observation uncertainty estimates for nee and le are derived from the PEcAN project and can be used by sd_nee &lt;- nee_sd_intercept + nee_sd_slopeP * nee. They are not supplied by NEON. Here is the download link and format of the terrestrial_30min target file: readr::read_csv(&quot;https://data.ecoforecast.org/targets/terrestrial_30min/terrestrial_30min-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 900,760 × 10 ## time siteID nee le nee_sd_intercept nee_sd_slopeP ## &lt;dttm&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2017-02-01 10:00:00 BART -0.574 -0.413 1.13 0.205 ## 2 2017-02-01 10:30:00 BART 0.297 -0.127 1.13 0.205 ## 3 2017-02-01 11:00:00 BART NA NA 1.13 0.205 ## 4 2017-02-01 11:30:00 BART NA NA 1.13 0.205 ## 5 2017-02-01 12:00:00 BART 0.224 -0.0333 1.13 0.205 ## 6 2017-02-01 12:30:00 BART 2.12 1.44 1.13 0.205 ## 7 2017-02-01 13:00:00 BART 2.18 2.49 1.13 0.205 ## 8 2017-02-01 13:30:00 BART NA NA 1.13 0.205 ## 9 2017-02-01 14:00:00 BART NA NA 1.13 0.205 ## 10 2017-02-01 14:30:00 BART NA NA 1.13 0.205 ## # … with 900,750 more rows, and 4 more variables: nee_sd_slopeN &lt;dbl&gt;, ## # le_sd_intercept &lt;dbl&gt;, le_sd_slopeP &lt;dbl&gt;, le_sd_slopeN &lt;dbl&gt; The code used to generate the targets from NEON data can be found here 2.3.5 Daily target data calculation To evaluate the models that produce daily flux forecasts, we select only days with at least 24 of 48 half hours that pass the quality control flags. For these days, we average the half-hours and convert carbon to daily units (gC/m2/day). The daily data table has the following columns. time: YYYY-MM-DD (the day is determined using UTC time) siteID: NEON site code (e.g., BART) nee: g C m-2 day-1 le: W m-2 Here is the download link and format of the terrestrial_daily target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/terrestrial_daily/terrestrial_daily-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 18,770 × 4 ## time siteID nee le ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2017-02-01 BART NA NA ## 2 2017-02-01 CLBJ NA NA ## 3 2017-02-01 KONZ NA NA ## 4 2017-02-01 ORNL NA NA ## 5 2017-02-01 OSBS NA NA ## 6 2017-02-01 SJER NA NA ## 7 2017-02-01 SRER NA NA ## 8 2017-02-01 TALL NA NA ## 9 2017-02-01 UNDE NA NA ## 10 2017-02-01 WREF NA NA ## # … with 18,760 more rows The code used to generate the targets from NEON data can be found here 2.4 Timeline Forecasts for a minimum of 35 days can be submitted daily by 6 pm ET throughout 2022. A minimum of 35 days in the future must be forecasted for each submission. For example, a forecast submitted on February 1 should be for at least February 1st – March 7th, but it could be for the full spring. New forecasts can be submitted daily as new weather forecasts and observations (e.g., NEE) become available. Processed NEE and LE data will be available daily by 11:59 pm ET for each day. The key is that submissions are predictions of the future. Daily submissions are allowed and encouraged as new observations and weather forecasts become available, therefore the automation of forecast generation may be ideal. There are many ways to automate scripts that are written to download observations and metreology drivers, generate forecasts, and submit forecasts. Two tools that many have used are cron jobs (see the R package cronR) that execute tasks at user specifics times and github actions. See more at Frequently Asked Questions Cron jobs work on unix and mac systems. An example of a script that executes a cron job using R can be found here. 2.5 Flux data latency NEON data officially releases the flux data on their data portal and API in monthly data packages. Data for a given month is scheduled to be released around the 15th of the following month. NEON is also processing flux data with only a 5 day delay (latency). Any data that has been processed but not included in a released monthly package is available on NEON s3 storage. The list of files that can be downloaded can found here. Our targets file is the combination of NEON’s monthly releases and the files on the s3 bucket. As a result, flux data within 5-days of the restart of a forecast are available to inform the forecast. The reduction of the latency from monthly to 5-days allows this theme to forecast in real-time - a major advancement for this forecasting challenge. Thank you NEON! 2.6 Submissions Instructions for submitting forecasts are found here: Submission Instructions The specific file format for the terrestrial_daily theme is here: Terrestrial daily The specific file format for the terrestrial_30min theme is here: Terrestrial 30 min 2.7 Meterological inputs for modeling Information about forecasted meteorology that is available for you to use when generating your forecasts can be found here: Meteorology Inputs ## Useful functions Functions for validating, evaluating and submitting forecasts can be found here: Helpful Functions Functions for downloading and working with the meteorology forecasts can be be found here: Access EFI snapshots of NOAA forecasts at NEON sites 2.8 Null models Two null models are automatically generated each day - these are simple baseline models. The persistence null model uses the most recent measurement of nee or le and predicts that the values will be constant in the future. The climatology null model forecasts that the nee or lee will be equal to the historical mean of that day of year. We apply both the persistence and climatology model to the daily fluxes and the climatology to the 30 minute fluxes Code for the daily persistence null model can be found here Code for the daily climatology null model can be found here Code for the 30 minute climatology null model can be found here 2.9 FAQ Answers to frequency asks questions can be found here: Frequently Asked Questions 2.10 Design team George Burba, LI-COR Biosciences Jamie Cleverly, Terrestrial Ecosystem Research Network (TERN) Ankur Desai, University of Wisconsin, Madison Mike Dietze, Boston University Andy Fox, Joint Center for Satellite Data Assimilation William Hammond, Oklahoma State University Danica Lombardozzi, National Center for Atmospheric Research Quinn Thomas, Virginia Tech Jody Peters, University of Notre Dame Alex Young, SUNY - College of Environmental Science &amp; Forestry 2.11 Partners Data used in the challenge are from the National Ecological Observatory Network (NEON) Ameriflux is an excellent database of eddy-covariance data, including historical data for some of the four challenge sites. Terrestrial Ecosystem Research Network (TERN) has been involved in the design of the challenge. "],["theme-tick-populations.html", "3 Theme: Tick Populations 3.1 Overview 3.2 Challenge 3.3 Data: Targets 3.4 Timeline 3.5 Submissions 3.6 Meterological inputs for modeling 3.7 Useful functions 3.8 Null models 3.9 FAQ 3.10 Design team 3.11 Partners", " 3 Theme: Tick Populations What: Amblyomma americanum nymphal tick abundance per sampled area Where: 9 NEON sites When: Weekly forecasts for 4 weeks into the future starting March 31-September 30, 2022. Forecasts are submitted monthly and later submissions after the March 31 start are permissible. Why: There is a correlation between tick population abundance and disease incidence, meaning forecasts for tick abundance have the potential to aid in our understanding of disease risk through time and space. Who: Open to any individual or team that registers How: REGISTER your team and submit forecast. If you registered for the Round 1 (2021) and are using the same team and method then you do not need to re-register. The video below is an overview of the Tick Populations Challenge that was recorded for the 2021 Early Career Annual Meeting We held a Q&amp;A session on March 24, 2021. You can find a recording from that session HERE. 3.1 Overview Target species for the population forecasts are Amblyomma americanum nymphal ticks. A. americanum is a vector of ehrlichiosis, tularemia, and southern tick-associated rash illness. The species is present in the eastern United States, and their populations are expanding. There is a correlation between tick population abundance and disease incidence, meaning forecasts for tick abundance have the potential to aid in our understanding of disease risk through time and space. 3.2 Challenge The challenge is open to any individual, group, or institution that may want to participate. The goals of this challenge are to forecast the density of Amblyomma americanum nymphs (ticks/1600m^2) each epidemiological week (Sun-Sat) at nine NEON sites. Due to the latency in the taxonomic data reported by NEON, the challenge will be for the 2021 field season. Teams must post information about any additional data they wish to use on the theme Slack channel so that other teams can potentially use the data as well. 3.3 Data: Targets The challenge uses the following NEON data products: DP1.10093.001: Ticks sampled using drag cloths A file with previously released NEON data that has been processed into “targets” is provided below. The same processing will be applied to new data that are used for forecast evaluation. This processing script is available in the neon4cast-ticks GitHub repository. 3.3.1 Amblyomma americanum nymphs Definition The density of Amblyomma americanum nymphs per week. Density is defined as the total number of individuals caught in a week across the forested plots divided by the total area sampled in the forested plots during the week. Densities are presented as ticks per 1600m^2, as 1600m^2 is the size of an individual NEON tick plot. Motivation We chose to use the density of Amblyomma americanum nymphs for several reasons. The first is that Amblyomma americanum is a vector of multiple pathogens, many of which cause human disease, and a forecast for their abundance could aid decisions in public health and personal protective measures. For simplicity, we chose to focus on one species for the abundance challenge, and the Amblyomma americanum nymphs are the most abundant tick observed in the NEON data. Most ticks are observed in to forested plots, and by standardizing the data to density of ticks observed per unit effort in the forested plots, we hope to avoid forecasters predicting sampling effort. We scaled the density to be representative of ticks per plot, which is more interpretable than ticks per square meter. Also, tick drags occur every three weeks. By having the challenge be for forecasting every week, participants won’t have to predict which weeks drags occur. 3.3.2 Focal sites Information on the sites can be found here: site_data &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/eco4cast/neon4cast-ticks/master/Ticks_NEON_Field_Site_Metadata_20210928.csv&quot;) siteID site name vegetation type latitude longtitude NEON site URL BLAN Blandy Experimental Farm NEON Deciduous Forest|Pasture/Hay 39.03370 -78.04179 https://www.neonscience.org/field-sites/blan KONZ Konza Prairie Biological Station NEON Deciduous Forest|Grassland/Herbaceous 39.10077 -96.56307 https://www.neonscience.org/field-sites/konz LENO Lenoir Landing NEON Deciduous Forest|Woody Wetlands 31.85386 -88.16118 https://www.neonscience.org/field-sites/leno ORNL Oak Ridge NEON Deciduous Forest|Evergreen Forest|Pasture/Hay 35.96413 -84.28259 https://www.neonscience.org/field-sites/ornl OSBS Ordway-Swisher Biological Station NEON Emergent Herbaceous Wetlands|Evergreen Forest|Woody Wetlands 29.68928 -81.99343 https://www.neonscience.org/field-sites/osbs SCBI Smithsonian Conservation Biology Institute NEON Deciduous Forest|Evergreen Forest|Pasture/Hay 38.89292 -78.13949 https://www.neonscience.org/field-sites/scbi SERC Smithsonian Environmental Research Center NEON Cultivated Crops|Deciduous Forest 38.89013 -76.56001 https://www.neonscience.org/field-sites/serc TALL Talladega National Forest NEON Deciduous Forest|Evergreen Forest|Mixed Forest 32.95047 -87.39326 https://www.neonscience.org/field-sites/tall UKFS University of Kansas Field Station NEON Deciduous Forest|Pasture/Hay 39.04043 -95.19215 https://www.neonscience.org/field-sites/ukfs 3.3.3 Target data calculation Tick drags occur every three weeks at the NEON sites used in this challenge. The sampling season at each site is determined by phenological milestones, beginning and ending within two weeks of green-up and senescence, respectively. The 1m^2 cloth is dragged for 160m (and at least 80m), and ticks are collected intermittently. They are then sent to a lab for taxonomic identification. Ticks are then identified by life stage and taxonomic rank. The target data is for Amblyomma americanum nymphs that were identified to the species level; i.e. ticks identified as being in the Amblyomma genus are not included. Use of 2021 data: The forecasting challenge is for the 2021 field season, thus environmental covariates are known. However, in the spirit of keeping this as much of a “forecasting” challenge as possible, we ask that for four week forecast period teams use the NOAA GEFS forecasting data. 3.3.4 Target file Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/ticks/ticks-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 477 × 4 ## time mmwrWeek siteID amblyomma_americanum ## &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2015-04-19 16 BLAN 0 ## 2 2015-05-10 19 BLAN 9.82 ## 3 2015-05-31 22 BLAN 10 ## 4 2015-06-07 23 BLAN 19.4 ## 5 2015-06-21 25 BLAN 3.14 ## 6 2015-07-12 28 BLAN 3.66 ## 7 2015-08-02 31 BLAN 0 ## 8 2015-08-23 34 BLAN 0 ## 9 2015-09-13 37 BLAN 0 ## 10 2015-10-11 41 BLAN 0 ## # … with 467 more rows time: YYYY-MM-DD The first day (Sunday) of the MMWR week mmwrWeek: The MMWR week that starts on Sunday, consistent with CDC version of the epidemiological week siteID: Site where ticks are observed (HARV) Amblyomma americanum: Density (ticks / 1600m^2) of Amblyomma americanum ticks 3.4 Timeline The challenge will begin on March 31, 2022 at 11:59 PM Eastern Standard Time, and will run through October 31, 2022. Each forecast will be for the four MMWR weeks during that month. For example, the forecast that is due on March 31, 2022 will be for MMWR weeks 10-13 of 2021 because the Sundays (the start of each MMWR week) in March 2021 correspond to MMWR weeks 10-13. Likewise, the forecast due April 30, 2022 will be for MMWR weeks 14-17 of 2021. A table of which weeks to forecast at each deadline can be found below. It is unclear when the provisional 2021 tick taxonomic data will be released. If any is released during the challenge, teams will be able to use it if the data is for weeks that have already been forecasted. For example, if the provisional 2021 data is released on July 15, 2022, teams can use the 2021 data up to MMWR week 26 to calibrate their models for the forecasts due July 31, 2022. 2022 Forecast Submission date 2021 Target Epidemiological weeks March 31 10-13 April 30 14-17 May 31 18-22 June 30 23-26 July 31 27-30 August 31 31-35 September 31 36-39 October 31 40-44 3.5 Submissions Instructions for submitting forecasts are found here: Submission Instructions With the specific file format here: Ticks 3.6 Meterological inputs for modeling Information about forecasted meteorology that is available for you to use when generating your forecasts can be found here: Meteorology Inputs 3.7 Useful functions Functions for validating, evaluating and submitting forecasts can be found here: Helpful Functions Functions for downloading and working with the meteorology forecasts can be be found here: Access EFI snapshots of NOAA forecasts at NEON sites 3.8 Null models The null model will be automatically generated each month, and is the historical mean for each week at each site. For weeks that don’t have observations, the forecast is a linear interpolation between the preceding and following weeks. 3.9 FAQ Answers to frequency asks questions can be found here: Frequently Asked Questions 3.10 Design team Matt Bitters, University of Colorado, Boulder Melissa Chen, University of Colorado, Boulder John Foster, Boston University Leah Johnson, Virginia Tech Shannon LaDeau, Cary Institute of Ecosystem Studies Cat Lippi, University of Florida Brett Melbourne, University of Colorado, Boulder Wynne Moss, University of Colorado, Boulder Sadie Ryan, University of Florida 3.11 Partners Data used in the challenge are collected by the National Ecological Observatory Network (NEON; https://www.neonscience.org/). "],["theme-phenology.html", "4 Theme: Phenology 4.1 Overview 4.2 Challenge 4.3 Data: Targets 4.4 Timeline 4.5 Submissions 4.6 Meterological inputs for modeling 4.7 Useful functions 4.8 Null models 4.9 FAQ 4.10 Design team 4.11 Partners 4.12 References", " 4 Theme: Phenology What: Terrestrial phenology defined by daily greenness and redness of plants Where: 10 deciduous broadleaf forest, 6 grassland, and 2 shrubland NEON sites in the continental U.S. When: Daily forecasts for 35-days in the future. Forecast submissions are accepted daily throughout 2022. The only requirement is that submissions are predictions of the future at the time the forecast is submitted. Why: Phenology has been identified as one of the primary ecological fingerprints of global climate change. Who: Open to any individual or team that registers How: REGISTER your team and submit forecast. If you registered for the Round 1 (2021) and are using the same team and method then you do not need to re-register. The video below is an overview of the Phenology Challenge that was recorded for the 2021 Early Career Annual Meeting We held a Q&amp;A session on January 27, 2021. You can find a recording from that session HERE. 4.1 Overview Phenology has been shown to be a robust integrator of the effects of year-to-year climate variability and longer-term climate change on natural systems (e.g., recent warming trends). Experimental studies have shown how other global change factors (e.g., elevated CO2 and N deposition) can also influence phenology. There is a need to better document biological responses to a changing world, and improved phenological monitoring at scales from individual organisms to ecosystems, regions, and continents will contribute to achieving this goal. Phenology researchers often use digital cameras (such as those that are part of the PhenoCam Network) that take regular repeated images of plant canopies to monitor changes in greenness and redness throughout the year. The PhenoCam Network is a cooperative continental-scale phenological observatory that uses digital repeat photography to track vegetation phenology in a diverse range of ecosystems across North America and around the World. Imagery and data are made publicly available in near-real-time through the PhenoCam webpage: http://phenocam.sr.unh.edu/. 4.2 Challenge This is an open ecological forecasting challenge to forecast spring green-up of the greenness (gcc) and redness (rcc) indices, as measured by digital cameras at various NEON sites. The forecasts will be forecasts of daily mean gcc and rcc (specifically the 90% quantile called the gcc_90 and rcc_90) for a region of interests with each site’s digital photograph. Teams must provide access (minimum of URL, but ideally a script) to any additional data they wish to use to all teams in the challenge. Teams of various career stages and disciplines are encouraged to submit forecasts. 4.3 Data: Targets The challenge uses the following NEON data products: DP1.00033.001: Phenology images A file with previously released NEON data that has been processed into “targets” is provided below. The same processing will be applied to new data that are used for forecast evaluation. The processing script is available on the neon4cast-phenology GitHub repository. 4.3.1 Green chromatic coordinate (gcc) Definition The ratio of the green digital number to the sum of the red, green, blue digital numbers from a digital camera. gcc_90 is the 90th percentile of the gcc within a set of pixel called a region of interest (ROI) Motivation Quantitative metrics of vegetation color extracted from PhenoCam imagery provide data that are consistent with ground observations of phenology and as well as other conventional vegetation indices across ecosystems. 4.3.2 Red chromatic coordinate (rcc) Definition The ratio of the red digital number to the sum of the red, green, blue digital numbers from a digital camera. rcc_90 is the 90th percentile of the rcc within a set of pixel called a region of interest (ROI) Motivation While gcc is primarily a metric of vegetation greeness, rcc is more a metric of fall color. Adding rcc to the autumn forecast challenge has two motivations. First, from an end-user’s perspective the timing of peak fall coloration has aesthetic value, which translates into economic for tourism. Second, from the ecological perspective, autumn phenology involves two distinct (but coupled) processes, senescence (loss of leaf chlorophyll and photosythetic activity; translocation of nutrients) and abscission (actual leaf fall). Forecasting two indices helps us disentangle our ability to predict these two processes. 4.3.3 Focal sites Information on the sites can be found here: site_data &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/eco4cast/neon4cast-phenology/master/Phenology_NEON_Field_Site_Metadata_20210928.csv&quot;) siteID site name Phenocam vegetation type Phenocam code Phenocam ROI NEON site URL BART Bartlett Experimental Forest NEON deciduous broadleaf NEON.D01.BART.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/bart CLBJ Lyndon B. Johnson National Grassland NEON deciduous broadleaf NEON.D11.CLBJ.DP1.00033 DB_2000 https://www.neonscience.org/field-sites/clbj DELA Dead Lake NEON deciduous broadleaf NEON.D08.DELA.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/dela GRSM Great Smoky Mountains National Park NEON deciduous broadleaf NEON.D07.GRSM.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/grsm HARV Harvard Forest &amp; Quabbin Watershed NEON deciduous broadleaf NEON.D01.HARV.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/harv MLBS Mountain Lake Biological Station NEON deciduous broadleaf NEON.D07.MLBS.DP1.00033 DB_2000 https://www.neonscience.org/field-sites/mlbs SCBI Smithsonian Conservation Biology Institute NEON deciduous broadleaf NEON.D02.SCBI.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/scbi SERC Smithsonian Environmental Research Center NEON deciduous broadleaf NEON.D02.SERC.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/serc STEI Steigerwaldt-Chequamegon NEON deciduous broadleaf NEON.D05.STEI.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/stei UKFS University of Kansas Field Station NEON deciduous broadleaf NEON.D06.UKFS.DP1.00033 DB_1000 https://www.neonscience.org/field-sites/ukfs CPER Central Plains Experimental Range NEON grassland NEON.D10.CPER.DP1.00033 GR_1000 https://www.neonscience.org/field-sites/cper DSNY Disney Wilderness Preserve NEON grassland NEON.D03.DSNY.DP1.00033 GR_1000 https://www.neonscience.org/field-sites/dsny JORN Jornada Experimental Range NEON grassland NEON.D14.JORN.DP1.00033 GR_1000 https://www.neonscience.org/field-sites/jorn KONZ Konza Prairie Biological Station NEON grassland NEON.D06.KONZ.DP1.00033 GR_1000 https://www.neonscience.org/field-sites/konz OAES Marvin Klemme Range Research Station NEON grassland NEON.D11.OAES.DP1.00033 GR_1000 https://www.neonscience.org/field-sites/oaes WOOD Chase Lake National Wildlife Refuge NEON grassland NEON.D09.WOOD.DP1.00033 GR_1000 https://www.neonscience.org/field-sites/wood ONAQ Onaqui NEON shrubland NEON.D15.ONAQ.DP1.00033 SH_1000 https://www.neonscience.org/field-sites/onaq SRER Santa Rita Experimental Range NEON shrubland NEON.D14.SRER.DP1.00033 SH_1000 https://www.neonscience.org/field-sites/srer 4.3.4 Target data calculation Digital cameras mounted above forests are pointed at the forest canopy. Images are collected every half hour. The images are a set of pixels values in red, green, and blue color channels (RGB). A pixel value is an 8-bit digital number (DN). Because internal processing (including exposure control) and external factors affecting scene illumination (weather and atmospheric effects) both influence the retrieved RGB signature, we calculate a number of vegetation indices that are effective at suppressing this unwanted variation and maximizing the underlying phenological signal. Most important among these is the green chromatic coordinate (GCC), calculated as GCC = GDN / (RDN + GDN + BDN). The red chromatic coordinate (GCC) is calculated in a similar way. For additional details, see Richardson et al. (2018) Scientific Data, and Richardson (2019) New Phytologist. PhenoCam data are processed and posted daily and the low latency of the PhenoCam data allows for a unique opportunity to evaluate forecasts in real-time. Each image has a defined “region of interest’ (ROI). An ROI is a set of pixels that isolates particular features in the image (i.e., a set of deciduous trees in a mixed forest). The ROI of the below top-of-canopy PhenoCams will be used to assess the forecasts’ accuracy. The mid-day (noon) mean GCC and GCC standard deviation for the ROI will be used for evaluation. All data in the supplied file is available to build and evaluate models before submitting a forecast to challenge. Once new data becomes avialable, the data are appended to the existing file. Within the challenge scoring, only the new data are used to evaluate previously submitted forecasts. 4.3.5 Target file Here is the format of the target file d &lt;- readr::read_csv(&quot;https://data.ecoforecast.org/targets/phenology/phenology-targets.csv.gz&quot;, guess_max = 1e6) The target file has the following columns: time: YYYY-MM-DD siteID: NEON site code (e.g., BART) gcc_90: 90th percentile GCC for the ROI gcc_sd: standard deviation of the 90th percentile rcc_90: 90th percentile RCC for the ROI (see Fall Phenology for more information about this variable) rcc_sd: standard deviation of the 90th percentile (see Fall Phenology for more information about this variable) 4.4 Timeline Forecasts for a minimum of 35 days can be submitted daily by 6 pm ET throughout 2022. A minimum of 35 days in the future must be forecasted for each submission. For example, a forecast submitted on February 1 should be for at least February 1st – March 7th, but it could be for the full spring. New forecasts can be submitted daily as new weather forecasts and observations (e.g., PhenoCam) become available. Processed PhenoCam data will be available daily by 11:59 pm ET for each day. The key is that submissions are predictions of the future. Daily submissions are allowed and encouraged as new observations and weather forecasts become available, therefore the automation of forecast generation may be ideal. There are many ways to automate scripts that are written to download observations and metreology drivers, generate forecasts, and submit forecasts. Two tools that many have used are cron jobs (see the R package cronR) that execute tasks at user specifics times and github actions. See more at Frequently Asked Questions Cron jobs work on unix and mac systems. An example of a script that executes a cron job using R can be found here. 4.5 Submissions Instructions for submitting forecasts are found here: Submission Instructions With the specific file format here: Phenology 4.6 Meterological inputs for modeling Information about forecasted meteorology that is available for you to use when generating your forecasts can be found here: Meteorology Inputs 4.7 Useful functions Functions for validating, evaluating and submitting forecasts can be found here: Helpful Functions Functions for downloading and working with the meteorology forecasts can be be found here: Access EFI snapshots of NOAA forecasts at NEON sites 4.8 Null models Two null models are automatically generated each day. The persistence null model use the most recent measurement of gcc_90 or rcc_90 and predicts that the values will be constant in the future. The climatology null model futures that the gcc_90 or rcc_90 will be equal to the historical mean of that day of year. Code for the persistence null model can be found here Code for the climatology null model can be found here 4.9 FAQ Answers to frequency asks questions can be found here: Frequently Asked Questions 4.10 Design team Min Chen, University of Wisconsin, Madison Michael Dietze, Boston University Kathy Gerst, National Phenology Network Chris Jones, NC State University David LeBauer, University of Arizona Dabasmita Pal, Michigan State University Andrew Richardson, Northern Arizona University Arun Ross, Michigan State University Bijan Seyednasrollah, Northern Arizona University, PhenoCam Network Quinn Thomas, Virginia Tech Kathryn Wheeler, Boston University Luke Zachmann, Conservation Science Partners Kai Zhu, University of California - Santa Cruz 4.11 Partners The challenge is hosted by the Ecological Forecasting Initiative (EFI; https://ecoforecast.org/) and its U.S. National Science Foundation sponsored Research Coordination Network (EFI-RCN; https://ecoforecast.org/rcn/). Data used in the challenge are collected by the National Ecological Observatory Network (NEON; https://www.neonscience.org/) and hosted by the Phenocam Network (http://phenocam.sr.unh.edu/). The forecasting challenge was developed in collaboration with the USA National Phenology Network: https://www.usanpn.org/usa-national-phenology-network. 4.12 References Richardson, A., Hufkens, K., Milliman, T. et al. Tracking vegetation phenology across diverse North American biomes using PhenoCam imagery. Sci Data 5, 180028 (2018). https://doi.org/10.1038/sdata.2018.28 Richardson, A.D. (2019), Tracking seasonal rhythms of plants in diverse ecosystems with digital camera imagery. New Phytol, 222: 1742-1750. https://doi.org/10.1111/nph.15591 "],["theme-beetle-communities.html", "5 Theme: Beetle Communities 5.1 Overview 5.2 Challenge 5.3 Data: Targets 5.4 Timeline 5.5 Design team 5.6 Partners 5.7 References", " 5 Theme: Beetle Communities What: Beetle abundance and species richness Where: 47 terrestrial NEON sites that span the diverse ecosystems of the U.S. When: Weekly forecasts for 20 months in the future starting June 30-December 31, 2022; later submissions after the June 30 start are permissible Why: Improve understanding of habitat quality, conservation potential, land-use sustainability, and biodiversity change in response to global change and ecological disturbances Who: Open to any individual or team that registers. How: REGISTER your team and submit forecast. If you registered for the Round 1 (2021) and are using the same team and method then you do not need to re-register. The video below is an overview of the Beetle Communities Challenge that was recorded for the 2021 Early Career Annual Meeting 5.1 Overview Biodiversity monitoring is critical for understanding environmental quality, evaluating the sustainability of land-use practices, and forecasting future impacts of global change on ecosystems. Sentinel species give forewarning of environmental risk to humans, so are particularly useful for such monitoring and forecasting efforts because they can provide surrogates for other co-located components of biodiversity (Sauberer et al. 2004). Ground beetles (Family: Carabidae) are appropriate candidates for biodiversity monitoring and ecological forecasting as they are well-studied sentinel species that are geographically widespread, and their community dynamics are particularly congruent with the diversity of other invertebrates (Holland 2002; Lundgren &amp; McCravy 2011; Bousquet 2012; Hoekman et al. 2017). Therefore, monitoring carabid communities and forecasting changes in their species richness and abundance can be useful in studying edge effects and habitat quality (Magura 2002), conservation potential (Butterfield 1995), land-use sustainability (Pearce &amp; Venier 2006) and biodiversity change in response to global change and ecological disturbances (Koivula 2011). Most ecological forecasting models are limited in the geographic scale and also suffer from scarcity of temporally extensive data. Further, most existing forecasting efforts focus on a single species (Humphries et al. 2018) with limited community-wide forecasts at the continental scale. Developing forecasts for community-scale metrics (i.e., species richness, abundance) and evaluating such models for accuracy and generalizability can help test our scientific knowledge of spatial (geographical turnover) and temporal (seasonal, inter-annual) carabid community dynamics (Dietze et al. 2018). Such forecasting models can inform regional or local habitat management, identify where biodiversity monitoring efforts should be prioritized, and shed light on what data or modelling techniques are needed to build the best forecasts of ecological dynamics (e.g., can we predict richness or abundance better and why?) (Johansson et al. 2019). With the long-term, community-wide, continental-scale data collection through the National Ecological Observatory Network (NEON), 181 data products are available for 81 sites in the US (47 terrestrial, at which carabids are sampled, and 34 aquatic). Fully initiated in 2019, this sampling will continue for 30 years (Schimel et al. 2007; 2011). NEON has effectively removed the previous barriers to community-scale forecasting across a broader geographical realm. 5.2 Challenge This is an open ecological forecasting challenge to forecast carabid species richness, defined as the total number of species, and abundance, defined as the total number of carabid individuals. The forecasts should be done weekly per site for all NEON terrestrial sites with richness being absolute and abundance scaled by the sampling effort. Contributing teams are required to submit a forecast for May-Dec 2022 and Jan-Dec 2023 on June 30, 2022. However, teams are encouraged to update their forecasts on the last day of each month, ending on December 31, 2021, as NEON validation data are released. NEON releases carabid sampling data weekly and no sooner than 60 days after collection, so a model submitted on June 30 can include a forecast for the first week of May, and so forth. Teams may use any open data products as drivers of richness and abundance so long as they are not from the month being forecast, and are made publicly available (minimum of URL, but ideally a script). Potential driver data sources include: NEON site data (Soil and sediment data, Terrestrial Plant data, weather data), NOAA forecasts, and beyond. 5.3 Data: Targets The challenge uses the following NEON data product: DP1.10022.001: Ground beetles sampled from pitfall traps A file with previously released NEON data that has been processed into the aggregate “target” variables (richness and abundance) is provided below. The same processing will be applied to new data that are used for forecast evaluation. Further information about data structure, initial code for processing, and example null forecasts is provided in the neon4cast-beetles GitHub repository. Forecasts will be made on a weekly basis for the abundance of beetles at a given NEON site at a given month (‘abundance’) and the observed species richness (n, number of species) of carabid beetles at each NEON site, each month. 5.3.1 Abundance of beetles (abundance) Definition Total number of carabid individuals per trap-night, estimated each week of the year at each NEON site Motivation A forecast prediction can be compared against only measured data (i.e. counts) and not latent variables (i.e. true carabid abundance), which are only inferred under specific model assumptions. However, raw count of beetles found in a particular trap depends on many other drivers than local abundance; in particular, the sampling effort. To avoid the need to accurately predict the sampling effort, we compute a target variable as counts per trap-night (number of nights each trap was set at the site; also called ‘catch per unit effort’). We chose this to define this variable in terms of total carabid abundance, rather than resolving to particular taxonomy (in contrast to species-specific relative abundance) because it simplifies issues related to taxonomic resolution of unpinned samples, data latency, and the choice of focal species. As supported by literature (Hoekman et al. 2017 and literature cited therein), we believe that abundance of the beetle family as a whole is an ecologically relevant metric. We considered predictions aggregated to the site level (rather than predicting individual traps or individual plots) to be both the most ecologically meaningful and simplest choice. Traps are typically collected every two weeks. Submitting a forecast for every week avoids the need to predict which weeks of the year collection does or does not occur. See https://github.com/eco4cast/neon4cast-beetles/blob/master/02_targets.R for a programmatic definition of how the abundance metric is defined. 5.3.2 Species richness (n) Definition Total number of unique ‘species’ in a sampling bout for each NEON site each week. For this challenge, we define ‘species’ as the taxonomic unit closest to species (e.g., species, genus, morphospecies) for each individual since not all identifications in the raw data are strictly at species-level. Motivation A forecast prediction can be compared against only measured data (i.e. observed count of taxonomic units) and not latent variables (i.e. count of species), which are only inferred under specific model and taxonomic assumptions. The number of unique taxonomic identities of beetles in a trap depends on many drivers, including sampling effort. As demonstrated by species rarefaction curves in ecology, the more time a trap is left out, the more individual beetles will fall in, and thus the more species can be expected. However, since perfect species-level data are not available to us and to keep the forecasted variables from being overly derived, we define the target variable as the total number of unique ‘species’ per week per NEON site. For this challenge, we chose to define ‘species’ as the taxonomic unit closest to species (e.g., species, genus, morphospecies) since not all identifications in the raw data are strictly at species-level. Species identifications will be used for individuals identified to sub-species level, as these are uncommon in the raw data. NEON taxonomists identify individuals as morphologically distinct units. Thus, it is reasonable to assert that the count of finest morphologically distinct identification (e.g., species, genus, morphospecies) is biologically meaningful, and thus the count of these is an important focal forecast variable. We focus on the NEON site as the spatial resolution and weekly intervals as the temporal resolution for the same reasons stated in the abundance metric. See https://github.com/eco4cast/NEON-community-forecast/blob/master/02_targets.R for a programmatic definition of how the richness metric is defined. 5.3.3 Focal sites All 47bNEON terrestrial sites are included Information on the sites can be found here: site_data &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/eco4cast/neon4cast-beetles/master/Beetles_NEON_Field_Site_Metadata_20210928.csv&quot;) siteID site name vegetation type latitude longtitude NEON site URL ABBY Abby Road NEON Evergreen Forest|Grassland/Herbaceous|Shrub/Scrub 45.76244 -122.33032 https://www.neonscience.org/field-sites/abby BARR Utqiaġvik NEON Emergent Herbaceous Wetlands 71.28241 -156.61936 https://www.neonscience.org/field-sites/barr BART Bartlett Experimental Forest NEON Deciduous Forest|Evergreen Forest|Mixed Forest 44.06389 -71.28737 https://www.neonscience.org/field-sites/bart BLAN Blandy Experimental Farm NEON Deciduous Forest|Pasture/Hay 39.03370 -78.04179 https://www.neonscience.org/field-sites/blan BONA Caribou-Poker Creeks Research Watershed NEON Deciduous Forest|Evergreen Forest|Mixed Forest|Woody Wetlands 65.15401 -147.50258 https://www.neonscience.org/field-sites/bona CLBJ Lyndon B. Johnson National Grassland NEON Deciduous Forest|Grassland/Herbaceous 33.40123 -97.57000 https://www.neonscience.org/field-sites/clbj CPER Central Plains Experimental Range NEON Grassland/Herbaceous 40.81554 -104.74559 https://www.neonscience.org/field-sites/cper DCFS Dakota Coteau Field Site NEON Grassland/Herbaceous 47.16165 -99.10656 https://www.neonscience.org/field-sites/dcfs DEJU Delta Junction NEON Evergreen Forest|Shrub/Scrub|Woody Wetlands 63.88112 -145.75136 https://www.neonscience.org/field-sites/deju DELA Dead Lake NEON Evergreen Forest|Woody Wetlands 32.54173 -87.80388 https://www.neonscience.org/field-sites/dela DSNY Disney Wilderness Preserve NEON Pasture/Hay|Woody Wetlands 28.12505 -81.43619 https://www.neonscience.org/field-sites/dsny GRSM Great Smoky Mountains National Park NEON Deciduous Forest|Evergreen Forest 35.68896 -83.50195 https://www.neonscience.org/field-sites/grsm GUAN Guanica Forest NEON Evergreen Forest 17.96955 -66.86870 https://www.neonscience.org/field-sites/quan HARV Harvard Forest &amp; Quabbin Watershed NEON Deciduous Forest|Evergreen Forest|Mixed Forest|Woody Wetlands 42.53691 -72.17265 https://www.neonscience.org/field-sites/harv HEAL Healy NEON Dwarf Scrub|Evergreen Forest|Shrub/Scrub 63.87580 -149.21335 https://www.neonscience.org/field-sites/heal JERC The Jones Center At Ichauway NEON Cultivated Crops|Deciduous Forest|Evergreen Forest|Mixed Forest 31.19484 -84.46862 https://www.neonscience.org/field-sites/jerc JORN Jornada Experimental Range NEON Shrub/Scrub 32.59069 -106.84254 https://www.neonscience.org/field-sites/jorn KONA Konza Prairie Agroecosystem NEON Cultivated Crops 39.11045 -96.61293 https://www.neonscience.org/field-sites/kona KONZ Konza Prairie Biological Station NEON Deciduous Forest|Grassland/Herbaceous 39.10077 -96.56307 https://www.neonscience.org/field-sites/konz LAJA Lajas Experimental Station NEON Cultivated Crops|Grassland/Herbaceous|Pasture/Hay 18.02126 -67.07689 https://www.neonscience.org/field-sites/laja LENO Lenoir Landing NEON Deciduous Forest|Woody Wetlands 31.85386 -88.16118 https://www.neonscience.org/field-sites/leno MLBS Mountain Lake Biological Station NEON Deciduous Forest 37.37831 -80.52485 https://www.neonscience.org/field-sites/mlbs MOAB Moab NEON Evergreen Forest|Shrub/Scrub 38.24828 -109.38827 https://www.neonscience.org/field-sites/moab NIWO Niwot Ridge NEON Evergreen Forest|Grassland/Herbaceous 40.05425 -105.58237 https://www.neonscience.org/field-sites/niwo NOGP Northern Great Plains Research Laboratory NEON Grassland/Herbaceous 46.76972 -100.91535 https://www.neonscience.org/field-sites/nogp OAES Marvin Klemme Range Research Station NEON Grassland/Herbaceous|Shrub/Scrub 35.41060 -99.05878 https://www.neonscience.org/field-sites/oaes ONAQ Onaqui NEON Evergreen Forest|Shrub/Scrub 40.17760 -112.45245 https://www.neonscience.org/field-sites/onaq ORNL Oak Ridge NEON Deciduous Forest|Evergreen Forest|Pasture/Hay 35.96413 -84.28259 https://www.neonscience.org/field-sites/ornl OSBS Ordway-Swisher Biological Station NEON Emergent Herbaceous Wetlands|Evergreen Forest|Woody Wetlands 29.68928 -81.99343 https://www.neonscience.org/field-sites/osbs PUUM Pu’u Maka’ala Natural Area Reserve NEON Evergreen Forest 19.55309 -155.31731 https://www.neonscience.org/field-sites/puum RMNP Rocky Mountains NEON Evergreen Forest 40.27590 -105.54596 https://www.neonscience.org/field-sites/rmnp SCBI Smithsonian Conservation Biology Institute NEON Deciduous Forest|Evergreen Forest|Pasture/Hay 38.89292 -78.13949 https://www.neonscience.org/field-sites/scbi SERC Smithsonian Environmental Research Center NEON Cultivated Crops|Deciduous Forest 38.89013 -76.56001 https://www.neonscience.org/field-sites/serc SJER San Joaquin Experimental Range NEON Evergreen Forest|Grassland/Herbaceous|Shrub/Scrub 37.10878 -119.73228 https://www.neonscience.org/field-sites/sjer SOAP Soaproot Saddle NEON Evergreen Forest|Shrub/Scrub 37.03337 -119.26219 https://www.neonscience.org/field-sites/soap SRER Santa Rita Experimental Range NEON Shrub/Scrub 31.91068 -110.83549 https://www.neonscience.org/field-sites/srer STEI Steigerwaldt-Chequamegon NEON Deciduous Forest|Mixed Forest|Woody Wetlands 45.50894 -89.58637 https://www.neonscience.org/field-sites/stei STER North Sterling NEON Cultivated Crops 40.46189 -103.02929 https://www.neonscience.org/field-sites/ster TALL Talladega National Forest NEON Deciduous Forest|Evergreen Forest|Mixed Forest 32.95047 -87.39326 https://www.neonscience.org/field-sites/tall TEAK Lower Teakettle NEON Evergreen Forest|Shrub/Scrub 37.00583 -119.00602 https://www.neonscience.org/field-sites/teak TOOL Toolik Field Station NEON Dwarf Scrub|Shrub/Scrub 68.66109 -149.37047 https://www.neonscience.org/field-sites/tool TREE Treehaven NEON Deciduous Forest|Evergreen Forest|Mixed Forest|Woody Wetlands 45.49369 -89.58571 https://www.neonscience.org/field-sites/tree UKFS University of Kansas Field Station NEON Deciduous Forest|Pasture/Hay 39.04043 -95.19215 https://www.neonscience.org/field-sites/ukfs UNDE University of Notre Dame Environmental Research Center NEON Deciduous Forest|Mixed Forest|Woody Wetlands 46.23391 -89.53725 https://www.neonscience.org/field-sites/unde WOOD Chase Lake National Wildlife Refuge NEON Emergent Herbaceous Wetlands|Grassland/Herbaceous 47.12820 -99.24133 https://www.neonscience.org/field-sites/wood WREF Wind River Experimental Forest NEON Evergreen Forest 45.82049 -121.95191 https://www.neonscience.org/field-sites/wref YELL Yellowstone National Park NEON Evergreen Forest|Grassland/Herbaceous|Shrub/Scrub 44.95348 -110.53914 https://www.neonscience.org/field-sites/yell 5.3.4 Target data calculation Ground beetle data are collected at each NEON site every two weeks throughout the sampling season. The sampling season is defined based on measures of growing season, including vegetation indices, phenology, and degree days, for a maximum of 13 bouts per site during which the 10-day average low temperature at the site is &gt;4°C. Samples are collected from pitfall traps placed at each of the cardinal directions within the 10 plots per site representative of up to three dominant vegetation types. Four traps were placed from 2014-2017 and from 2018 onward the northward plot was eliminated leaving three traps for each plot. Ground beetles from the pitfall traps are removed, sorted, and identified to the lowest possible taxonomic rank or morphospecies. A subset of individuals (up to 467 per site and year) are sent to taxonomic experts for subsequent identification with priority on individuals for which species-level identification was not able to be assigned. Further detail can be found in the NEON Ground Beetle User Guide. Raw (NEON L1 ground beetle data product DP1.10022.001) are accessible via the NEON data portal, via the NEON API, via R using the neonUtilties package, and via R using neonStore::neon_download. The raw data is also available through the NEON data portal with archived copies at https://data.ecoforecast.org/minio/neonstore. The raw data is processed to generate total abundance and richness per week per NEON site. All data in the supplied file is available to build and evaluate models before submitting a forecast to challenge. Once new data becomes available, the data are appended to the existing file. Within the challenge scoring, only the new data are used to evaluate previously submitted forecasts. As part of our reproducible workflow, we provide an R script for producing derived tables of total abundance and richness from the raw NEON data. Our workflow gives preference to expert taxonomist identifications when available. Since expert taxonomy lags behind identifications from the sorting and pinning process, newer data will not be updated with expert taxonomy. The abundance table gives total abundance at each site for each week. The richness table gives an aggregate count of the number of ‘species’ at each site in each week. Note: The table includes all data that NEON has collected and can be used for building and training models (new data will be posted after forecasts are submitted) 5.3.5 Target file The code use to process the raw data to the evaluation data can be found here: https://github.com/eco4cast/NEON-community-forecast/blob/master/02_targets.R Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/beetles/beetles-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 3,178 × 4 ## siteID time abundance richness ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ABBY 2016-09-12 1.05 14 ## 2 ABBY 2016-09-26 4.45 13 ## 3 ABBY 2017-05-01 0.0554 10 ## 4 ABBY 2017-05-15 0.180 19 ## 5 ABBY 2017-05-29 0.425 19 ## 6 ABBY 2017-06-12 0.25 18 ## 7 ABBY 2017-06-26 0.271 22 ## 8 ABBY 2017-07-10 0.148 15 ## 9 ABBY 2017-07-24 0.105 14 ## 10 ABBY 2017-08-07 0.116 16 ## # … with 3,168 more rows The table has the following columns: siteID: NEON site ID time: YYYY-MM-DD (the Monday marking the week of sample collection (for training data) or forecast (submission). Per ISO standards, Monday marks the first day of each week.) abundance: abundance of beetles richness: species richness 5.4 Timeline The timeline is determined by the data latency provided by NEON. NEON carabid pitfall trap data is released weekly with a latency of at least 60 days after collection. Weekly forecasts were chosen to best match up with NEON’s weekly release of carabid data. The challenge will begin June 30, 2022 at 11:59 Eastern Standard Time (UTC−05:00) and run through December 31, 2022. Subsequent forecasts are due at 11:59 EST on the final day of each month. As an example, carabid pitfall trap data released in the last week of June would include data as recent as the last week of April. Thus, a model submitted in the last week of June could include forecasts from May onwards. Then, the forecast update submitted at the end of July can use new May data to help refine June forecasts, or forecasts following June, depending on what drivers are used. The July forecast update is due by 11:59 pm EST on July 31. Forecasts updates will not be considered for weeks where NEON validation data has already been released (i.e., no May forecast updates may be submitted on July 31) or for weeks when no NEON carabid data is available. Pitfall traps are collected and reset every 2 weeks throughout the growing season. Due to weather and conditions beyond the field team’s control, this collection schedule may not be followed. Thus, the exact collection dates cannot be known until they have happened. Field data are made publicly available on the data portal as the bet_fielddata dataframe no sooner than 14 days after collection. Teams can use bet_fielddata to inform the actual collection schedule. Data with parataxonomist identifications are made publicly available on the data portal as the bet_sorting dataframe no sooner than 60 days after collection. Data are released on the NEON data portal weekly, but may be released on any day of the week. The forecast schedule follows the ISO week standard with weeks starting on Mondays. 5.5 Design team Anna Spiers, University of Colorado, Boulder Carl Boettiger, University of California, Berkeley Tad Dallas, Louisiana State University Nico Franz, NEON Biorepository at Arizona State University Kari Norman, University of California, Berkeley Thilina Surasinghe, Bridgewater State University Brett Melbourne, University of Colorado, Boulder Eric Sokol, NEON Kelsey Yule, NEON Biorepository at Arizona State University 5.6 Partners The challenge is hosted by the Ecological Forecasting Initiative (EFI; https://ecoforecast.org/) and its U.S. National Science Foundation sponsored Research Coordination Network (EFI-RCN; https://ecoforecast.org/rcn/). Data used in the challenge from National Ecological Observatory Network (NEON): https://www.neonscience.org/. 5.7 References Bousquet, Y. (2012) Catalogue of Geadephaga (Coleoptera: Adephaga) of America, north of Mexico. ZooKeys 245: 1-1722. https://doi.org/10.3897/zookeys.245.3416 Butterfield, J., Luff, M., Baines, M., Eyre, M. (1995) Carabid beetle communities as indicators of conservation potential in upland forests. Forest Ecology and Management 79, 63-77. https://doi.org/10.1016/0378-1127(95)03620-2 Dietze, M.C., Fox, A., Beck-Johnson, L.M., Betancourt, J.L., Hooten, M.B., Jarnevich, C.S., Keitt, T.H., Kenney, M.A., Laney, C.M., Larsen, L.G. (2018) Iterative near-term ecological forecasting: Needs, opportunities, and challenges. Proceedings of the National Academy of Sciences 115, 1424-1432. https://doi.org/10.1073/pnas.1710231115 Gneiting, T., &amp; Raftery, A. E. (2007). Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477), 359–378. https://doi.org/10.1198/016214506000001437 Hoekman, D., LeVan, K.E., Gibson, C., Ball, G.E., Browne, R.A., Davidson, R.L., Eriwin, T.L., Knisley, C.B., LaBonte, J.R., Lundgren, J., Maddison, D.R., Moore, W., Niemela, J., Ober, K.A., Pearson, D.L. Spence, J.R., Will, K., Work, T. (2017) Design for ground beetle abundance and diversity sampling within the National Ecological Observatory Network. Ecosphere, 8(4), e01744. https://doi.org/10.1002/ecs2.1744 Holland, J.M. (2002) The agroecology of carabid beetles. Intercept Limited, Andover. Humphries, G.R., Che-Castaldo, C., Bull, P., Lipstein, G., Ravia, A., Carrión, B., Bolton, T., Ganguly, A., Lynch, H.J. (2018) Predicting the future is hard and other lessons from a population time series data science competition. Ecological Informatics 48, 1-11. https://doi.org/10.1016/j.ecoinf.2018.07.004 Johansson, M.A., Apfeldorf, K.M., Dobson, S., Devita, J., Buczak, A.L., Baugher, B., Moniz, L.J., Bagley, T., Babin, S.M., Guven, E. (2019) An open challenge to advance probabilistic forecasting for dengue epidemics. Proceedings of the National Academy of Sciences 116, 24268-24274. https://doi.org/10.1073/pnas.1909865116 Koivula, M.J. (2011) Useful model organisms, indicators, or both? Ground beetles (Coleoptera, Carabidae) reflecting environmental conditions. ZooKeys, 287-317. https://doi.org/10.3897/zookeys.100.1533 Lundgren, J., McCravy, K. (2011) Carabid beetles (Coleoptera: Carabidae) of the Midwestern United States: A review and synthesis of recent research. Terrestrial arthropod reviews 4, 63-94. https://doi.org/10.1163/187498311X565606 Magura, T. (2002) Carabids and forest edge: spatial pattern and edge effect. Forest Ecology and Management 157, 23-37. https://doi.org/10.1016/S0378-1127(00)00654-X Pearce, J.L., Venier, L.A. (2006) The use of ground beetles (Coleoptera: Carabidae) and spiders (Araneae) as bioindicators of sustainable forest management: A review. Ecological Indicators 6, 780-793. https://doi.org/10.1016/j.ecolind.2005.03.005 Sauberer, N., Zulka, K.P., Abensperg-Traun, M., Berg, H.-M., Bieringer, G., Milasowszky, N., Moser, D., Plutzar, C., Pollheimer, M., Storch, C. (2004) Surrogate taxa for biodiversity in agricultural landscapes of eastern Austria. Biological Conservation 117, 181-190. https://doi.org/10.1016/S0006-3207(03)00291-X Schimel, D., Hargrove, W., Hoffman, F., MacMahon, J. (2007) NEON: a hierarchically designed national ecological network. Frontiers in Ecology and the Environment 5, 59-59. https://doi.org/10.1890/1540-9295(2007)5[59:NAHDNE]2.0.CO;2 Schimel, D., Keller, M., Berukoff, S., Hufft, R., Loescher, H., Powell, H., Kampe, T., Moore, D., Gram, W. (2011) NEON Science Strategy: Enabling Continental-Scale Ecological Forecasting. https://www.neonscience.org/sites/default/files/basic-page-files/NEON_Strategy_2011u2_0.pdf "],["participation.html", "6 Participation 6.1 Participation guidance 6.2 Participation agreement 6.3 NEON Data Use 6.4 Additional data options", " 6 Participation 6.1 Participation guidance 6.1.1 How to participate Participation requires that one contact person from each team: Complete a REGISTRATION for each forecast theme you are participating in and each model you are contributing within a theme The contact person agrees to the participation agreement below on behalf of the team Submit forecast netCDF or csv file(s) Provide the metadata xml file documenting the forecast One contact person should register on behalf of their team. That contact person will be asked to provide the group members’ names, emails, and affiliations so that everyone in the group can receive an invitation to join the Challenge theme Slack channel and access group resources. Teams are allowed and encouraged to join the challenge after the start date of each Challenge theme because there are multiple deadlines to submit forecasts. However, only forecasts submitted by each submission deadline will be officially scored. 6.1.2 Teams Teams can be individuals or groups. They can represent institutions or organizations. You will have 25 characters for a team name (e.g., “EFI Null Model”) and 10 characters for the team name ID (no spaces allowed; e.g., “EFI_Null”). The registration includes team categories (e.g., undergraduate only, graduate only, multi-institution, etc). If your team wants to submit multiple forecasts, please register a different team name for each model . If there are two different time steps in a challenge theme (e.g., the terrestrial carbon flux theme has a 30-minute and 1-day option), register each as separate teams. 6.1.3 Slack and GitHub Communication Once your team is registered, everyone listed will receive an email with an invitation to join the EFI Slack group and the #neon4cast-theme channel. You will also receive details about the GitHub repository associated with the theme your team is registered for. We strongly encourage participants to use the Challenge theme Slack channels to ask questions, discuss ideas and challenges, and share resources. Overall, we strongly encourage a collegial approach to the Challenge – this is a friendly competition to move the field forward and bring more people into the community, not a cutthroat competition to win by denying other teams useful information. GitHub repositories for each Challenge theme will be available with helper code and an example workflow (null models). We encourage teams to contribute code to these repositories (via Pull Request) if they develop additional helper code. This is especially important if an individual or group is going to add additional data constraints to their forecast. Remember, the use of data external to NEON is allowed and encouraged so long as it is publicly available and other teams are notified about it. Also, while most anything could be used to calibrate parameters and constrain initial conditions, only other forecasts (e.g. weather) can be used as drivers/covariates during the actual forecast period. 6.1.4 Archiving models Teams are highly encouraged to publicly archive the code they are using for their forecast models and workflows. Information about where models are archived would be included in your metadata XML. Teams are also encouraged to use Docker or Singularity to containerize their models &amp; workflows. EFI conventions for containerizing forecasts are still being developed, but our aim (particularly in later years of the forecast challenge) is to be able to provide shared cyberinfrastructure that makes it easier for teams to automate containerized forecasts. Containers will also facilitate Challenge themes interested in performing post-hoc analyses, such as uncertainty quantification and sensitivity analysis. 6.1.5 Computational resources We are currently working with CyVerse for access to computational resources for teams that require resources not available through home institutions. We will update with more details as they become available. 6.2 Participation agreement All participants agree to have their forecast posted in real-time on the NEON Ecological Forecast Challenge Dashboard and potentially published in a scientific journal. The manuscripts describing the accuracy of forecasts across teams will be coordinated by the Ecological Forecasting Initiative Research Coordination Network and authorship will be extended to members of each team with an opt-in policy. If a publication is generated by a forecast team, we ask that the manuscript acknowledge the Ecological Forecasting Initiative Research Coordination Network and its support from the National Science Foundation (DEB-1926388). 6.3 NEON Data Use NEON data products, software, and derivatives thereof are freely available for use when accompanied by appropriate disclaimers, acknowledgments, and data citations, defined in the NEON data use policy. The video below explains how to download and utilize NEON data for the Challenge. The video was recorded for the 2021 Early Career Annual Meeting 6.4 Additional data options Individuals and groups may create forecasts that use other publicly available data in addition to the NEON data, so long as other teams participating in the challenge are notified about the existence of the data via the Challenge theme’s Slack channel. Teams are encouraged to make available the code they are using to access, download, and process any additional data constraints they are using, ideally via a pull request to each Challenge Github repo. When considering the use of data in forecasts it is important to distinguish data that are being used as drivers/covariates during each forecast from data being used to constrain model structure, parameters, initial conditions, and error distributions. While the latency of NEON data requires that some of our forecast will be (fully or partly) hindcasts, all forecasts should be run as if they are true forecasts – you cannot use any observed data as a driver/covariate or constraint during the forecast period itself as that info would not have been available at the forecast start date. For example, if you find that a particular variable is a useful covariate during the model development &amp; calibration period (e.g. soil temperature) then you would need to find or make a forecast of that variable if you want to use it as a covariate. Teams using meteorological covariates should use the shared meteorological driver data provided by EFI (see Shared Forecast Drivers). As an example of potentially useful external data, each NEON site has subsets of various remote sensing products that are hosted on the ORNL DAAC (ORNL DAAC subsets). These include: MODIS collection 6: LAI, FPAR, burned area, surface reflectance, land surface temperature, vegetation indices (NDVI, EVI), modeled ET, GPP, NPP. VIIRS collection 1: surface reflectance, vegetation indices, LAI, FPAR, land surface temperature, SMAP: modeled NEE, GPP, Rh, SOC Daymet: daily surface weather data The video below demonstrates how to access meteorological covariate data for the Challenge. The video was recorded for the 2021 Early Career Annual Meeting "],["submission-instructions.html", "7 Submission Instructions 7.1 Forecast format 7.2 Metadata format 7.3 Submission process 7.4 Validating submission 7.5 Visualizing submissions 7.6 Video Describing How to Submit to the Challenge", " 7 Submission Instructions The following provides the requirements for the format of the forecasts that will be submitted. It is important to follow these format guidelines in order for your submitted forecasts to pass a set of internal checks that allow the forecast to be visualized on the NEON Ecological Forecast Challenge dashboard and evaluated with the scoring process. 7.1 Forecast format Teams will submit their forecasts as a single netCDF or csv file with the following naming convention (the correct naming convention is critical for the automated processing of submissions): theme_name-year-month-day-team_name_ID.csv or theme_name-year-month-day-team_name_ID.nc Where year, month, and day are the year, month, and day for the first day of the submitted forecast and the team_name_ID is the code for the team name that is specified in the registration (team_name_ID is a 10 character name with no spaces in it). The theme_name options are: terrestrial_daily, terrestrial_30min, aquatics, beetles, ticks, or phenology. Forecast netCDF or csv files should have the following columns (csv) or variables (netcdf) that correspond to the columns. There are two key options for the format. First, the file can be either in a csv or a netcdf format. Second the file can represent uncertainty using an ensemble column or a statistic column. The ensemble column uses an integer to individual each ensemble member or MCMC member that represent forecast uncertainty. The statistic column uses the words mean or sd to describe which statistic is represented in the forecasted target column. Note for submissions with a statistic column option: Teams that are NOT using ensemble-based forecast methods should replace the ensemble column with a statistic column. Multiple statistics can be reported using a long format in a csv or adding a statistic dimension in netCDF. The required options for this column are mean and sd (standard deviation). You can also include Conf_interv_02.5, Conf_interv_97.5, Pred_interval_02.5, and Pred_interval_97.5 to describe uncertainty but these are optional. The numbers in the last four options indicate equal-tail quantiles for a 95% interval estimate and Conf_=confidence and Pred_=predictive. If statistics are reported we will make a Gaussian assumption when calculating error scores. The Continuous Ranked Probability Score is based on the predictive distribution so reported sd should be for the predictive distribution. Note for those using netCDF option, the order of dimensions on forecast variables should be: time, site, plot [ticks only], and ensemble. In practice using a netCDF for the forecast with the statistic rather than ensemble is not ideal. Below are examples of the forecast file format for each theme. The correct file format is critical for the automated processing of submissions 7.1.1 Terrestrial 30 min Note: remember this theme is “terrestrial_30min” time: YYYY-MM-DD HH:MM UTC of the start of the 30-minute value siteID: NEON code for site ensemble or statistic: if ensemble then integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample); if statistic then either required to be the string mean or sd (see note below about statistic column). forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: set as 0 for each row (0 = no data assimilation occurred because it is a forecast) nee: net ecosystem exchange (umol CO2 m-2 s-1 for 30 minute forecast le: latent heat (W m-2) If you only forecast nee or le, you can exclude the other variable from the file Here is an example of a netcdf forecast file that meets the standard for the 30 minute terrestrial theme. The file is located at https://data.ecoforecast.org/forecasts/terrestrial/terrestrial_30min-2022-02-15-hist30min.nc 7.1.2 Terrestrial Daily Note: remember this theme is “terrestrial_daily” time: YYYY-MM-DD siteID: NEON code for site ensemble or statistic: if ensemble then integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample); if statistic then either required to be the string mean or sd (see note below about statistic column). forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: [Optional] set as 0 for each row (0 = no data assimilation occurred because it is a forecast) nee: g C m-2 day-1 for daily forecasts) le: latent heat (W m-2) If you only forecast nee or le, you can exclude the other variable from the file Here is an example of a csv forecast file that meets the standard for the daily terrestrial theme readr::read_csv(&quot;https://data.ecoforecast.org/forecasts/terrestrial_daily/terrestrial_daily-2022-02-15-climatology.csv.gz&quot;) ## Rows: 720 Columns: 6 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): siteID, statistic ## dbl (3): forecast, nee, le ## date (1): time ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 720 × 6 ## time siteID statistic forecast nee le ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-02-15 BART mean 1 0.630 2.80 ## 2 2022-02-15 BART sd 1 0.243 6.87 ## 3 2022-02-16 BART mean 1 0.584 10.7 ## 4 2022-02-16 BART sd 1 0.243 6.87 ## 5 2022-02-17 BART mean 1 0.505 7.22 ## 6 2022-02-17 BART sd 1 0.243 6.87 ## 7 2022-02-18 BART mean 1 0.855 5.36 ## 8 2022-02-18 BART sd 1 0.243 6.87 ## 9 2022-02-19 BART mean 1 0.639 15.5 ## 10 2022-02-19 BART sd 1 0.243 6.87 ## # … with 710 more rows 7.1.3 Beetles time: YYYY-MM-DD of forecast (where the DD is the first day of the week that is forecasted) siteID: NEON code for site ensemble or statistic: if ensemble then integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample); if statistic then either required to be the string mean or sd (see note below about statistic column). forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: [Optional] set as 0 for each row (0 = no data assimilation occurred because it is a forecast) abundance: abundance of beetles richness: species richness of beetles Here is an example of a csv forecast file that meets the standard for the beetles theme readr::read_csv(&quot;https://data.ecoforecast.org/forecasts/beetles/beetles-2021-07-01-cb_f2.csv.gz&quot;) ## Rows: 4888 Columns: 5 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): siteID, statistic ## dbl (2): richness, abundance ## date (1): time ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 4,888 × 5 ## time siteID statistic richness abundance ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-06-28 ABBY mean 10.7 0.353 ## 2 2021-06-28 ABBY sd 2.38 0.279 ## 3 2021-07-05 ABBY mean 10.7 0.353 ## 4 2021-07-05 ABBY sd 2.38 0.279 ## 5 2021-07-12 ABBY mean 10.7 0.353 ## 6 2021-07-12 ABBY sd 2.38 0.279 ## 7 2021-07-19 ABBY mean 10.7 0.353 ## 8 2021-07-19 ABBY sd 2.38 0.279 ## 9 2021-07-26 ABBY mean 10.7 0.353 ## 10 2021-07-26 ABBY sd 2.38 0.279 ## # … with 4,878 more rows 7.1.4 Aquatics time: YYYY-MM-DD of forecast siteID: NEON code for site ensemble or statistic: if ensemble then integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample); if statistic then either required to be the string mean or sd (see note below about statistic column). forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: [Optional] set as 0 for each row (0 = no data assimilation occurred because it is a forecast) temperature: water temperature (C) oxygen: dissolved oxygen (mg/L) chla: chlorophyll-a (mg/L) Here is an example of a csv forecast file that meets the standard for the aquatics theme readr::read_csv(&quot;https://data.ecoforecast.org/forecasts/aquatics/aquatics-2022-02-15-climatology.csv.gz&quot;) ## Rows: 288 Columns: 7 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): siteID, statistic ## dbl (4): forecast, oxygen, chla, temperature ## date (1): time ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 288 × 7 ## time siteID statistic forecast oxygen chla temperature ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-02-15 BARC mean 1 8.83 8.83 18.6 ## 2 2022-02-15 BARC sd 1 0.205 1.07 1.26 ## 3 2022-02-16 BARC mean 1 8.82 8.82 18.7 ## 4 2022-02-16 BARC sd 1 0.205 1.07 1.26 ## 5 2022-02-17 BARC mean 1 8.77 8.77 18.9 ## 6 2022-02-17 BARC sd 1 0.205 1.07 1.26 ## 7 2022-02-18 BARC mean 1 8.78 8.78 19.5 ## 8 2022-02-18 BARC sd 1 0.205 1.07 1.26 ## 9 2022-02-19 BARC mean 1 8.77 8.77 20.3 ## 10 2022-02-19 BARC sd 1 0.205 1.07 1.26 ## # … with 278 more rows 7.1.5 Phenology time: YYYY-MM-DD siteID: NEON code for site ensemble or statistic: if ensemble then integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample); if statistic then either required to be the string mean or sd (see note below about statistic column). forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: [Optional] set as 0 for each row (0 = no data assimilation occurred because it is a forecast) gcc_90: green chromatic coordinate rcc_90: red chromatic coordinate Here is are examples of csv forecast files that meet the standard for the phenology theme readr::read_csv(&quot;https://data.ecoforecast.org/forecasts/phenology/phenology-2022-02-14-climatology.csv.gz&quot;) ## Rows: 1296 Columns: 6 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): siteID, statistic ## dbl (3): forecast, gcc_90, rcc_90 ## date (1): time ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## # A tibble: 1,296 × 6 ## time siteID statistic forecast gcc_90 rcc_90 ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2022-02-14 BART mean 1 0.344 0.370 ## 2 2022-02-14 BART sd 1 0.00178 0.0104 ## 3 2022-02-15 BART mean 1 0.347 0.353 ## 4 2022-02-15 BART sd 1 0.00178 0.0104 ## 5 2022-02-16 BART mean 1 0.346 0.364 ## 6 2022-02-16 BART sd 1 0.00178 0.0104 ## 7 2022-02-17 BART mean 1 0.344 0.374 ## 8 2022-02-17 BART sd 1 0.00178 0.0104 ## 9 2022-02-18 BART mean 1 0.347 0.362 ## 10 2022-02-18 BART sd 1 0.00178 0.0104 ## # … with 1,286 more rows A netcdf file located at https://data.ecoforecast.org/forecasts/phenology/phenology-2021-02-23-EFInull.nc ncdf4::nc_open(&quot;images/phenology-2021-02-23-EFInull.nc&quot;) ## File images/phenology-2021-02-23-EFInull.nc (NC_FORMAT_NETCDF4): ## ## 2 variables (excluding dimension variables): ## float gcc_90[time,site,ensemble] (Contiguous storage) ## long_name: 90% quantile of daily green chromatic coordinate ## char siteID[nchar,site] (Contiguous storage) ## ## 4 dimensions: ## time Size:35 ## units: days since 2021-02-23 ## long_name: time ## site Size:8 ## long_name: siteID ## ensemble Size:2000 ## long_name: ensemble member ## nchar Size:4 (no dimvar) ## ## 3 global attributes: ## forecast_project_id: EFInull ## forecast_model_id: v0.1 ## forecast_iteration_id: 2021-02-23 22:10:34 7.1.6 Ticks time: YYYY-MM-DD of forecast (where the DD is the first day of the week (Sunday) that is forecasted). Defined by MMWRweek::MMWRweek2Date(Year, mmwrWeek) siteID: NEON code for site ensemble or statistic: if ensemble then integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample); if statistic then either required to be the string mean or sd (see note below about statistic column). forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: set as 0 for each row (0 = no data assimilation occurred because it is a forecast) amblyomma_americanum: Density of Amblyomma americanum nymphs Here is an example of a csv forecast file that meets the standard for the ticks theme readr::read_csv(&quot;https://data.ecoforecast.org/forecasts/ticks/ticks-2019-03-04-tickGlobalNull_RandomWalk.csv.gz&quot;) ## # A tibble: 77,000 × 10 ## ...1 time ixodes_scapularis plotID siteID ensemble data_assimilation ## &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2019-03-04 0.341 BLAN_012 BLAN 1 0 ## 2 2 2019-03-11 0.286 BLAN_012 BLAN 1 0 ## 3 3 2019-03-18 0.372 BLAN_012 BLAN 1 0 ## 4 4 2019-03-25 0.349 BLAN_012 BLAN 1 0 ## 5 5 2019-04-01 0.368 BLAN_012 BLAN 1 0 ## 6 6 2019-04-08 0.443 BLAN_012 BLAN 1 0 ## 7 7 2019-04-15 0.455 BLAN_012 BLAN 1 0 ## 8 8 2019-04-22 0.367 BLAN_012 BLAN 1 0 ## 9 9 2019-04-29 0.368 BLAN_012 BLAN 1 0 ## 10 10 2019-05-06 0.327 BLAN_012 BLAN 1 0 ## # … with 76,990 more rows, and 3 more variables: forecast &lt;dbl&gt;, ## # obs_flag &lt;dbl&gt;, amblyomma_americanum &lt;dbl&gt; 7.2 Metadata format Each submission requires a metadata file to be submitted. The metadata file must have the same name as the submitted forecast, but with the .xml extension. theme_name-year-month-day-team_name_ID.xml Metadata files should be uploaded with the forecast files. The metadata standard has been designed by the Ecological Forecasting Initiative and is built off the widely used Ecological Metadata Language (EML). To help support metadata generation, we have created a function in the neon4cast package (generate_metadata()) and a guide for completing the metadata: [Metadata] The license for the forecast output is required to be from the following Creative Commons License options: CC BY, CC BY-SA, CC BY-NC, CC BY-NC-SA. While we recommend a CC BY license, teams may use less permissive CC licenses if more appropriate. The license entry can be the CC option (i.e., CC BY) and a web link to the full CC license (e.g., https://creativecommons.org/licenses/by/4.0/) We recommend teams read the full metadata standard description for definitions and more information, and in particular that they look at the example vignettes, which demonstrate the standard being used. Note that these Standards are a work in progress. If you find issues as you are applying them, let us know at eco4cast.initaitive@gmail.com. 7.3 Submission process Individual forecast (csv, netCDF) and metadate (xml) files can be uploaded any time before the specific deadlines as defined by each theme. Only the most recent files will be scored. The correct file name and format is critical for the automated processing of submissions Teams will submit their forecast netCDF or csv files manually through the challenge website or with an R script. You can submit from an R script using the following: Sys.setenv(&quot;AWS_DEFAULT_REGION&quot; = &quot;data&quot;, &quot;AWS_S3_ENDPOINT&quot; = &quot;ecoforecast.org&quot;) aws.s3::put_object(object = &quot;theme_name-year-month-day-team_name.csv&quot;, bucket = &quot;submissions&quot;) aws.s3::put_object(object = &quot;theme_name-year-month-day-team_name.xml&quot;, bucket = &quot;submissions&quot;) Finally, we have developed a function called submit in the neon4cast package handles submission process. Internally it performs the aws.s3 commands in option two and executes the submission 11.1.7: neon4cast::submit(forecast_file = &quot;theme_name-forecast-year-month-day-team_name.csv&quot;, metadata = &quot;theme_name-year-month-day-team_name.xml&quot;) Submissions need to adhere to the forecast format that is provided above, including the file naming convention. Our cyberinfastructure automatically evaluates forecasts and relies on the expected formatting. Contact eco4cast.initiative@gmail.com if you experience technical issues with submitting. Note: If you have used AWS in the past you might have credential files in an .aws folder in your home directory that will cause an error when you try to upload to a non-AWS bucket. If you encounter this error you may need to rename your credentials files so put_object doesn’t try to read them. 7.4 Validating submission You can check the status of your submssion using the following function in the neon4cast package neon4cast::check_submission(&quot;phenology-2022-02-07-persistence.nc&quot;) ## Submission was successfully processed A successful submission can be found at the following links within 2 hours of submissions We run a validator script when processing the submissions. If your submission does not meet the file standards above, you can run a function that provides information describing potential issues. The forecast file needs to be in your local working directory or you need to provide a full path to the file neon4cast::forecast_output_validator(&quot;phenology-2022-02-07-persistence.nc&quot;) 7.5 Visualizing submissions Plots of submissions and table of scores can be found at our dashboard 7.6 Video Describing How to Submit to the Challenge This video was recorded for the 2021 Early Career Annual Meeting "],["submission-metadata-generation.html", "8 Submission Metadata Generation 8.1 Team information 8.2 Model Description 8.3 Example R “list” 8.4 Example", " 8 Submission Metadata Generation The challenge organizer have created tools to assist in generating the metadata that describes a forecast submission 8.1 Team information team_list &lt;- list(list(individualName = list(givenName = &quot;Quinn&quot;, surName = &quot;Thomas&quot;), organizationName = &quot;Virginia Tech&quot;, electronicMailAddress = &quot;rqthomas@vt.edu&quot;), list(individualName = list(givenName = &quot;Robert&quot;, surName = &quot;Thomas&quot;), organizationName = &quot;Virginia Tech&quot;)) 8.2 Model Description 8.2.1 Initial conditions Uncertainty in the initialization of state variables (Y). Initial condition uncertainty will be a common feature of any dynamic model, where the future state depends on the current state, such as population models, process-based biogeochemical pool &amp; flux models, and classic time-series analysis. 8.2.2 Drivers Uncertainty in model drivers, covariates, and exogenous scenarios (X). Driver/covariate uncertainties may come directly from a data product, as a reported error estimate or through driver ensembles, or may be estimated based on sampling theory, cal/val documents, or some other source. complexity = Number of different driver variables or covariates in a model. For example, in a multiple regression this would be the number of X’s. For a climate-driven model, this would be the number of climate inputs (temperature, precip, solar radiation, etc.). 8.2.3 Parameters Uncertainty in model parameters (). For most ecological processes the parameters (a.k.a. coefficients) in model equations are not physical constants but need to be estimated from data. complexity = number of estimated parameters/coefficients in a model at a single point in space/time. For example, in a regression it would be the number of beta’s. 8.2.4 Random effects complexity = number of random effect terms, which should be equivalent to the number of random effect variances estimated. For example, if you had a hierarchical univariate regression with a random intercept you would have two parameters (slope and intercept) and one random effect (intercept). At the moment, we are not recording the number of distinct observation units that the model was calibrated from. So, in our random intercept regression example, if this model was fit at 50 sites to be able to estimate the random intercept variance, that would affect the uncertainty about the mean and variance but that ‘50’ would not be part of the complexity dimensions. 8.2.5 Process error Dynamic uncertainty in the process model attributable to both model misspecification and stochasticity. Pragmatically, this is the portion of the residual error from one timestep to the next that is not attributable to any of the other uncertainties listed above, and which typically propagates into the future. complexity = dimension of the error covariance matrix. So if we had a n x n covariance matrix, n is the value entered for complexity. Typically n should match the dimensionality of the initial_conditions unless there are state variables where process error is not being estimated or propagated 8.2.6 Observation error Uncertainty in the observations of the output variables. Note that many statistical modeling approaches do not formally partition errors in observations from errors in the modeling process, but simply lump these into a residual error. Because of this we make the pragmatic distinction and ask that residual errors that a forecast model do not directly propagate into the future be recorded as observation errors. Observation errors now may indeed affect the initial condition uncertainty in the next forecast, but we consider this to be indirect. complexity = dimension of the error covariance matrix. So if we had a n x n covariance matrix, n is the value entered for complexity. Typically n should match the dimensionality of the initial_conditions unless there are state variables where process error is not being estimated or propagated 8.2.7 Progation propogation = method for generating uncertainty in the model predictions to represent uncertainty in initial conditions 8.2.8 assimilation assimilation = how data is used to estimate the uncertainty in initial conditions 8.3 Example R “list” model_metadata = list( forecast = list( model_description = list( forecast_model_id = # model identifier: name = #Name or short description of model type = #General type of model empirical, machine learning, process repository = # put your GitHub Repository in here ), initial_conditions = list( status = , #options: absent, present, data_driven, propagates, assimilates complexity = , #How many models states need initial conditions; delete if status = absent #Delete list below if status = absent, present, or data_driven propagation = list( type = , #How does your model propogate initial conditions (&#39;ensemble&#39; is most common) size = #number of ensemble members ), #Delete list below UNLESS status = assimilates assimilation = list( type = , #description of assimilation method reference = , #reference for assimilation method complexity = #number of states that are updated with assimilation ) ), drivers = list( status = , #options: absent, present, data_driven, propagates, assimilates complexity = , #How many drivers are used? Delete if status = absent #Delete list below if status = absent, present, or data_driven propagation = list( type = , #How does your model propogate driver (ensemble or MCMC is most common size = #number of ensemble or MCMC members ) ), parameters = list( status = , #options: absent, present, data_driven, propagates, assimilates complexity = , #How many parameters are included?; Delete if status = absent #Delete list below below blank if status = absent, present, or data_driven propagation = list( type = , #how does your model propogate parameter uncertainity? size = ), #Delete list below UNLESS status = assimilates assimilation = list( type = , #description of assimilation method reference = , #reference for assimilation method complexity = #number of states that are updated with assimilation ) ), random_effects = list( status = , #options: absent, present, data_driven, propagates, assimilates complexity = , #Delete if status = absent #Delete list below if status = absent, present, or data_driven propagation = list( type = , #How does your model propogate random effects (ensemble or MCMC is most common) size = #number of ensemble or MCMC members ), #Delete list below NLESS status = assimilates assimilation = list( type = , #description of assimilation method reference = , #reference for assimilation method complexity = #number of states that are updated with assimilation ) ), process_error = list( status = , #options: absent, present, data_driven, propagates, assimilates complexity = , #Delete if status = absent #Delete the list below below blank if status = absent, present, or data_driven propagation = list( type = , #How does your model propagate random effects uncertainty (ensemble or MCMC is most common) size = #How many ensemble or MCMC members ), #Delete the list below UNLESS status = assimilates assimilation = list( type = , #Name of data assilimilation method reference = , #Reference for data assimilation method complexity = , #Number of states assimilate covariance = , #TRUE OR FALSE localization = #TRUE OR FALSE ) ), obs_error = list( status = , #options: absent, present, data_driven, propagates, assimilates complexity = , #Delete if status = absent #Delete the list below below blank if status = absent, present, or data_driven propagation = list( type = , #How does your model propagate random effects uncertainty (ensemble or MCMC is most common) size = #How many ensemble or MCMC members ) ) ) ) The metadata XML can be generated using the the forecast_file (path and filename of forecast), team_list (see above), and mode1_metadata (see above). The neon4cast::generate_metadata() function will take this information add additional metdata to complete the XML. The forecast_file must following the format described at Forecast format neon4cast::generate_metadata(forecast_file, team_list, model_metadata) 8.4 Example Below is an example of the model_metadata for the terrestrial daily climatology model. It is a simple model that forecasts the carbon exchange (NEE) and evaporation (LE) is equal to the mean and standard deviation of the historical data for that day-of-year. Since it is a simple model, many of the descriptions of model uncertainty are absent. model_metadata = list( forecast = list( model_description = list( forecast_model_id = &quot;climatology&quot;, name = &quot;Day-of-year mean&quot;, type = &quot;empirical&quot;, repository = &quot;https://github.com/eco4cast/neon4cast-terrestrial/blob/master/03_terrestrial_flux_daily_null.R&quot; ), initial_conditions = list( status = &quot;absent&quot; ), drivers = list( status = &quot;absent&quot; ), parameters = list( status = &quot;absent&quot; ), random_effects = list( status = &quot;absent&quot; ), process_error = list( status = &quot;data_driven&quot;, complexity = 2 ), obs_error = list( status = &quot;absent&quot; ) ) ) "],["evaluation.html", "9 Evaluation 9.1 Results 9.2 Scoring Metric: Continuous Ranked Probability Score 9.3 Null forecast 9.4 Forecast Submission Visualization and Leaderboard 9.5 References", " 9 Evaluation Forecasts will be evaluated at each site and forecast horizon (i.e., time-step into the future), and a summary score will be assigned evaluating overall performance of all forecast submissions across sites. Forecasts will also be compared to a null model. Forecast evaluation results will be presented for all submitted models together and separately for each team category: undergraduate student only team, graduate student only team, post-doc only team, single institution team, multi-institution team, international team (team with individuals from at least two countries). 9.1 Results Preliminary results will be distributed using the NEON Ecological Forecast Challenge dashboard and at https://data.ecoforecast.org/minio/scores/. We intend to write a joint manuscript synthesizing forecasts, authorship will be extended to members of each team with an opt-in policy. Teams are welcome to publish results from their model at any time. If a publication is generated we encourage the manuscript to acknowledge the Ecological Forecasting Research Coordination Network and its support from the National Science Foundation (DEB-1926388). 9.2 Scoring Metric: Continuous Ranked Probability Score Forecasts will be scored using the continuous ranked probability score (CRPS), a proper scoring rule for evaluating forecasts presented as distributions or ensembles (Gneiting &amp; Raftery 2007). The CRPS compares the forecast probability distribution to that of the validation observation and assigns a score based on both the accuracy and precision of the forecast. We will use the ‘crps_sample’ function from the scoringRules package in R to calculate the CRPS for each forecast. We will generate a combined score for all locations and forecast horizons. Forecasts will also be evaluated using the CRPS at each time-step in the forecast horizon and each location included in the forecasts. Importantly, we use the convention for CRPS where zero is lowest and best possible score, therefore teams want to achieve the lowest score. CPRS can be also expressed as a negative number with zero as highest and best possible score (Gneiting &amp; Raftery 2007). The scoringRules package that we use follows the 0 or greater convention. 9.2.1 Example of a CRPS calculation from an ensemble forecast The following uses Equation 2 in Jordan, Kruger, and Lerch 2018 Equation 1 from Jordan, Kruger, and Lerch 2018. First, create a random sample from a probability distribution. This is the “forecast” for a particular point in time. For simplicity, we will use a normal distribution with a mean of 8 and standard deviation of 1 x &lt;- rnorm(1000, mean = 8, sd = 1.0) Second, we have our data point (i.e., the target). We will set it to zero as well y &lt;- 8 Now calculate CRPS using Equation 2 s &lt;- 0 for(i in 1:length(x)){ for(j in 1:length(x)){ s &lt;- s + abs(x[i] - x[j]) } } crps_equation_2 &lt;- mean(abs(x - y)) - s / (2 * length(x)^2) crps_equation_2 ## [1] 0.2225527 Now calculate using the crps_sample() function in the scoringRules package crps_sample(y = y, dat = x) ## [1] 0.2225527 9.2.2 Exploring the scoring surface Now lets see how the CRPS changes as the mean and standard deviation of the forecasted distribution change First, set vectors for the different mean and SD values we want to explore sample_mean &lt;- seq(4, 12, 0.1) sample_sd &lt;- seq(0.1, 10, 0.1) Second, set our observed value to 8 for simplicity y &lt;- 8 Now calculate the CRPS at each combination of forest mean and SD combined &lt;- array(NA, dim = c(length(sample_mean), length(sample_sd))) for(i in 1:length(sample_mean)){ for(j in 1:length(sample_sd)){ sample &lt;- rnorm(10000, sample_mean[i], sample_sd[j]) combined[i, j] &lt;- crps_sample(y = y, dat = sample) } } Finally, visualize the scoring surface with the observed value represented by the red line contour(x = sample_mean, y = sample_sd, z = as.matrix(combined),nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;) abline(v = y, col = &quot;red&quot;) The contour surface highlights the trade-off between the mean and standard deviation. 9.2.3 CRPS from the Normal Distribution If the distributional forecast is a normal distribution represented by a mean \\(\\mu\\) and standard deviation \\(\\sigma\\), an ensemble of predictions is not needed to evaluate CRPS because we can take advantage of the analytic solution to CRPS under the normal assumption (Equation 4 from Gneiting et al. 2005) Equation 5 from Gneiting et al. (2005) gives \\[\\begin{align*} CRPS(N(\\mu, \\sigma^2) | y) = \\sigma \\left( \\frac{y - \\mu}{\\sigma} \\left( 2 \\Phi\\left( \\frac{y - \\mu}{\\sigma} \\right) - 1 \\right) + 2 \\phi \\left( \\frac{y - \\mu}{\\sigma} \\right) - \\frac{1}{\\sqrt{\\pi}} \\right) \\end{align*}\\] for \\(\\Phi(\\cdot)\\) and \\(\\phi(\\cdot)\\) the standard normal CDF and PDF, respectively. Therefore, if the forecast distribution is truly a normal distribution (often this isn’t true in forecasts that only report a mean and sd) a simplified score can be applied as follows: sample_mean &lt;- seq(4, 12, 0.1) sample_sd &lt;- seq(0.1, 10, 0.1) combined_norm &lt;- array(NA, dim = c(length(sample_mean), length(sample_sd))) for(i in 1:length(sample_mean)){ for(j in 1:length(sample_sd)){ combined_norm[i, j] &lt;- crps_norm(y = y, mean = sample_mean[i], sd = sample_sd[j]) } } Finally, visualize the scoring surface with the observed value represented by the red line. contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;) abline(v = y, col = &quot;red&quot;) Note that at a given value of the sd, the lowest score is achieved at \\(\\mu = y\\) as shown for each of the blue lines where the minimum value of the score across each blue line is at the red line. This behavior makes sense because the CRPS is a score that rewards accuracy and precision. Thus, for any given level of precision (represented by the standard deviation), CRPS is optimized by producing the most accurate prediction of the distribution’s location. contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;) abline(v = y, col = &quot;red&quot;) abline(h = 2.5, col = &quot;blue&quot;) abline(h = 4.3, col = &quot;blue&quot;) abline(h = 6.8, col = &quot;blue&quot;) Interestingly, for a given mean \\(\\mu \\neq y\\) we find a pattern that makes intuitive sense given the goal of CRPS to produce forecasts that are both accurate and precise. For a given amount of bias in the prediction (i.e., given a \\(\\mu \\neq y\\)), the optimal score is achieved by a standard deviation that slightly larger than the bias. layout(matrix(1:4, 2, 2, byrow = TRUE)) ## plots for mu = 7 mu &lt;- 7 contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;, main = paste0(&quot;CRPS contour given mu = &quot;, mu)) abline(v = mu, col = &quot;red&quot;) min_sd &lt;- sample_sd[which.min(crps_norm(y, mean = mu, sd = sample_sd))] abline(h = min_sd, col = &quot;blue&quot;) plot(sample_sd, crps_norm(y, mean = mu, sd = sample_sd), type = &#39;l&#39;, main = paste0(&quot;CRPS profile given mu = &quot;, mu)) abline(v = min_sd, col = &quot;blue&quot;) ## plots for mu = 11 mu &lt;- 11 contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;, main = paste0(&quot;CRPS contour given mu = &quot;, mu)) abline(v = mu, col = &quot;red&quot;) min_sd &lt;- sample_sd[which.min(crps_norm(y, mean = mu, sd = sample_sd))] abline(h = min_sd, col = &quot;blue&quot;) plot(sample_sd, crps_norm(y, mean = mu, sd = sample_sd), type = &#39;l&#39;, main = paste0(&quot;CRPS profile given mu = &quot;, mu)) abline(v = min_sd, col = &quot;blue&quot;) Next, we plot the relationship between a given value of \\(\\mu\\) and the \\(\\sigma\\) that produces the optimal CRPS. This looks like a linear relationship. optimal_sd &lt;- rep(0, length(sample_mean)) for (i in 1:length(sample_mean)) { optimal_sd[i] &lt;- sample_sd[which.min(crps_norm(y, mean = sample_mean[i], sd = sample_sd))] } plot(sample_mean, optimal_sd, type = &#39;l&#39;) Let’s estimate the slope of the relationship. It looks like the optimal \\(sd\\) for a normal distribution forecast that is biased by \\(|y - \\mu|\\) is \\(sd = 1.2|y - \\mu|\\) which makes sense as this would put the true value in a region of high probability. coef(lm(optimal_sd[sample_mean &gt; 0] ~ sample_mean[sample_mean &gt; 0])) ## (Intercept) sample_mean[sample_mean &gt; 0] ## 2.430864e+00 -1.688326e-16 9.3 Null forecast All forecasts will be compared to a null forecast produced by a simple historical-means calculation or a random walk. The GitHub repository for each theme has the code for the null model. Ticks: https://github.com/eco4cast/neon4cast-ticks/blob/master/03_nullFitAndForecast.R Terrestrial (Daily): https://github.com/eco4cast/neon4cast-terrestrial/blob/master/03_terrestrial_flux_daily_null.R Terrestrial (30 minute): https://github.com/eco4cast/neon4cast-terrestrial/blob/master/04_terrestrial_flux_30min_clim.R Beetles: https://github.com/eco4cast/neon4cast-beetles/blob/master/03_forecast.R Aquatics: https://github.com/eco4cast/neon4cast-aquatics/blob/master/03_generate_null_forecast_aquatics.R Phenology: https://github.com/eco4cast/neon4cast-phenology/blob/master/nullModel_randomWalk_main.R 9.4 Forecast Submission Visualization and Leaderboard The dashboard shows the forecast submissions by each team for each forecast theme by date and forecast variable. It also provides the CRPS scores for each submitted forecast. 9.5 References Gneiting, T., A.E. Raftery. 2007. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477): 359–378. https://doi.org/10.1198/016214506000001437 Jordan, A., F. Kruger, and S. Lerch 2018. Evaluating probabilistic forecasts with scoringRules. https://cran.r-project.org/web/packages/scoringRules/vignettes/article.pdf Gneiting, T., A.E. Raftery, A.H. Westveld III, T. Goldman. 2005. Calibrated probabilistic forecasting using ensemble model output statistics and minimum CRPS estimation. Monthly Weather Review, 133(5): 1098-1118. https://doi.org/10.1175/MWR2904.1 "],["met_inputs.html", "10 Meteorology Inputs 10.1 NOAA Global Ensemble Forecasting System 10.2 NOAA Global Ensemble Forecasting System Stacked 10.3 NEON Observed", " 10 Meteorology Inputs We are downloading, subsetting, and processing forecasted meteorology drivers for each NEON site. Currently, we have NOAA’s Global Ensemble Forecasting System (GEFS) V12 output available at the 1 hr time resolution for each NEON site. The following are important considerations when using the NOAA GEFS forecasts There are 31 ensemble members for each forecast. Each ensemble member is available as a separate netcdf file. For forecasts generated at four times per day. The directories are organized by these cycles: 00, 06, 12, and 18 cycles For the midnight (00) UTC, the forecasts extend 35-days in the future for the ensemble members 01 - 30. Ensemble member 00 only extends 16-days in the future. For forecasts generated at 06, 12, and 18 UTC, the forecasts extend 16-days in the future. We are constantly downloading and processing the forecasts. Since the 00 forecast runs 35-days in the future, it takes longer to download the complete forecast than the 06, 12, and 18 cycles. As a result you may see the 00 forecast appear later than the other forecasts on the server. The following meteorological variables are included: - air temperature - air pressure - wind speed - precipitation - downwelling longwave radiation - downwelling shortwave radiation - relative humidity The weather forecasts are available through an s3 bucket (see NOAA Global Ensemble Forecasting System below) with multiple ways to access them: - You can click on a file in the browser, you can directly download individual files from the command line using the file address - You can download multiple files using aws.s3 commands. - We provide an R function code in the neon4cast package called noaa.R for downloading all the ensemble members for particular location, forecast cycle (00, 06, 12, or 18), and NEON site Additionally, we provide an R function code in the neon4cast package called read_forecast.R for converting the download netcdf files to a data frame. 10.1 NOAA Global Ensemble Forecasting System 1 Hour NOAA Drivers The data are organized by siteID/date/cycle where cycle is the hour of the day (UTC) that the forecast was started (00, 06, 12, 18). 10.2 NOAA Global Ensemble Forecasting System Stacked We have extracted the first hour of each NOAA GEFS forecast since September 2020 and combined them together to generate a continuous weather product that runs from September 2020 to present. This is available for model calibration and seamlessly transitions to the current day’s NOAA GEFS forecast Historical NOAA Drivers The data are organized by siteID. 10.3 NEON Observed Our goal is to make the observed weather at each NEON site available. This is currently in development through a collaboration with NEON and NCAR. "],["helpful-functions.html", "11 Helpful Functions 11.1 neon4cast package 11.2 neonstore package 11.3 EFIstandards package", " 11 Helpful Functions The following are resources to help you prepare your forecasts for submission. The neon4cast package provides a collection of convenient helper utilities so you can score your forecast locally, validate the format of your forecast files to check for formatting errors before submitting, generate forecast metadata in EML (coming soon!), access EFI snapshots of NOAA forecasts at NEON sites, and submit your forecast. The neonstore package provides quick access and persistent storage of NEON data tables. The EFIstandards package summarizes the proposed community standards for the common formatting and archiving of ecological forecasts by the Ecological Forecasting Initiative. These standards are a work in progress. If you have suggestions for improvement share them with eco4cast.initiative@gmail.com.” 11.1 neon4cast package The neon4cast package is located at https://github.com/eco4cast/neon4cast neon4cast provides the following collection of convenient helper utilities for anyone entering the EFI NEON Forecasting Challenge. 11.1.1 Installation You can install the development version from GitHub with: # install.packages(&quot;remotes&quot;) remotes::install_github(&quot;eco4cast/neon4cast&quot;) 11.1.2 Example forecast library(neon4cast) library(tidyverse) library(fable) library(tsibble) Download and read in the current target file for the Aquatics theme. For convenience, we read this in as a timeseries object, noting that the time is in the ‘time’ column, and timeseries are replicated over sites. aquatic &lt;- read_csv(&quot;https://data.ecoforecast.org/targets/aquatics/aquatics-targets.csv.gz&quot;) %&gt;% as_tsibble(index=time, key=siteID) Create a 35 day forecast for each variable, oxygen, and temperature. For illustrative purposes, we’ll use the fable package because it is concise and well documented. We make separate forecasts for each of the two variables before reformatting them and combining them. Note the use of efi_format helper function from the neon4cast package, which merely replaces the special &lt;S3:distribution&gt; column used by fable with something we can write to text: either columns with a mean/sd (for normal distributions) or otherwise random draws from the distributions. So that we can score our forecast right away instead of waiting for next month’s data, we will filter out the most recent data available first. # drop last 35 days and use explicit NAs for gaps in timeseries blinded_aquatic &lt;- aquatic %&gt;% filter(time &lt; max(time) - 35) %&gt;% fill_gaps() # A simple random walk forecast, see ?fable::RW oxygen_fc &lt;- blinded_aquatic %&gt;% model(null = RW(oxygen)) %&gt;% forecast(h = &quot;35 days&quot;) %&gt;% efi_format() ## also use random walk for temperature temperature_fc &lt;- blinded_aquatic %&gt;% model(null = RW(temperature)) %&gt;% forecast(h = &quot;35 days&quot;) %&gt;% efi_format() # combine into single table, drop the .model column forecast &lt;- inner_join(oxygen_fc, temperature_fc) %&gt;% select(-.model) ## Write the forecast to a file following EFI naming conventions: forecast_file &lt;- glue::glue(&quot;{theme}-{date}-{team}.csv.gz&quot;, theme = &quot;aquatics&quot;, date=Sys.Date(), team = &quot;example_null&quot;) write_csv(forecast, forecast_file) 11.1.3 Score forecast locally Scores for valid forecasts should appear at https://shiny.ecoforecast.org the day after they are submitted. However, it is often more convenient to generate scores locally. Note that the “score” simply the crps_sample (for ensemble forecasts) or crps_norm (for summary statistic forecasts) score from the scoringRules R package, for each unique prediction (i.e.day/site/variable tuple). Note that scores are only possible once the data becomes available in the corresponding targets file! scores &lt;- score(forecast, theme = &quot;aquatics&quot;) # The resulting data.frame scores each day for each site, but is also easy to summarize: scores %&gt;% group_by(siteID, target) %&gt;% summarise(mean_score = mean(score, na.rm=TRUE)) #&gt; # A tibble: 4 x 3 #&gt; siteID target mean_score #&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 BARC oxygen 0.677 #&gt; 2 BARC temperature NaN #&gt; 3 POSE oxygen 0.676 #&gt; 4 POSE temperature 1.42 11.1.4 Validate a forecast file Validating a forecast file runs the same automated checks as the EFI server, verifying that the data is in the correct format for the appropriate challenge. Helpful errors or warnings will displayed on any invalid formats. Note that the validator accepts files in .csv (optionally compressed as .csv.gz) or netcdf. forecast_output_validator(forecast_file) #&gt; aquatics-2021-03-17-example_null.csv.gz #&gt; ✓ file name is correct #&gt; #&gt; ── Column specification ──────────────────────────────────────────────────────── #&gt; cols( #&gt; time = col_date(format = &quot;&quot;), #&gt; siteID = col_character(), #&gt; statistic = col_character(), #&gt; oxygen = col_double(), #&gt; temperature = col_double() #&gt; ) #&gt; ✓ target variables found #&gt; ✓ file has summary statistics column #&gt; ✓ file has summary statistic: mean #&gt; ✓ file has summary statistic: sd #&gt; ✓ file has siteID column #&gt; ✓ file has time column #&gt; ✓ file has correct time column #&gt; [1] TRUE 11.1.5 Generate forecast metadata in EML See [Metadata] 11.1.6 Access EFI snapshots of NOAA forecasts at NEON sites Many forecasts will want to make use of weather forecasts as potential drivers. EFI downscales NOAA GEFS 35-day forecast products at each NEON site and makes this data available. These helper functions provide convenient access for downloading and stacking the individual forecast files. aq_sites &lt;- unique(aquatic$siteID) download_noaa(aq_sites) noaa_fc &lt;- stack_noaa() noaa_fc #&gt; # A tibble: 8,590 x 18 #&gt; model interval siteID startDate endDate ensemble air_temperature air_pressure #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 295. 101473. #&gt; 2 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 291. 101595. #&gt; 3 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 289. 101595. #&gt; 4 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 302. 101602. #&gt; 5 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 296. 101479. #&gt; 6 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 292. 101553. #&gt; 7 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 290. 101461. #&gt; 8 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 302. 101408. #&gt; 9 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 296. 101281. #&gt; 10 NOAA… 6hr BARC 2021-03-… 2021-0… ens00.nc 291. 101360. #&gt; # … with 8,580 more rows, and 10 more variables: relative_humidity &lt;dbl&gt;, #&gt; # surface_downwelling_longwave_flux_in_air &lt;dbl&gt;, #&gt; # surface_downwelling_shortwave_flux_in_air &lt;dbl&gt;, precipitation_flux &lt;dbl&gt;, #&gt; # specific_humidity &lt;dbl&gt;, cloud_area_fraction &lt;dbl&gt;, wind_speed &lt;dbl&gt;, #&gt; # time &lt;dbl&gt;, latitude &lt;dbl&gt;, longitude &lt;dbl&gt; 11.1.7 Submit a forecast When you are ready to submit your forecast to EFI: submit(forecast_file) #&gt; aquatics-2021-03-17-example_null.csv.gz #&gt; ✓ file name is correct #&gt; #&gt; ── Column specification ──────────────────────────────────────────────────────── #&gt; cols( #&gt; time = col_date(format = &quot;&quot;), #&gt; siteID = col_character(), #&gt; statistic = col_character(), #&gt; oxygen = col_double(), #&gt; temperature = col_double() #&gt; ) #&gt; ✓ target variables found #&gt; ✓ file has summary statistics column #&gt; ✓ file has summary statistic: mean #&gt; ✓ file has summary statistic: sd #&gt; ✓ file has siteID column #&gt; ✓ file has time column #&gt; ✓ file has correct time column Ideally you should include the optional metadata = argument with your metadata file. 11.2 neonstore package The neonstore package is located at https://github.com/eco4cast/neon4cast neonstore provides quick access and persistent storage of NEON data tables. neonstore emphasizes simplicity and a clean data provenance trail, see Provenance section below. neonstore provides quick access and persistent storage of NEON data tables. neonstore emphasizes simplicity and a clean data provenance trail, see Provenance section below. 11.2.1 Installation Install the development version from GitHub with: # install.packages(&quot;devtools&quot;) devtools::install_github(&quot;cboettig/neonstore&quot;) 11.2.2 Quickstart library(neonstore) Discover data products of interest: products &lt;- neon_products() i &lt;- grepl(&quot;Populations&quot;, products$themes) products[i, c(&quot;productCode&quot;, &quot;productName&quot;)] #&gt; # A tibble: 50 x 2 #&gt; productCode productName #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 DP1.00033.001 Phenology images #&gt; 2 DP1.10003.001 Breeding landbird point counts #&gt; 3 DP1.10010.001 Coarse downed wood log survey #&gt; 4 DP1.10020.001 Ground beetle sequences DNA barcode #&gt; 5 DP1.10022.001 Ground beetles sampled from pitfall traps #&gt; 6 DP1.10026.001 Plant foliar traits #&gt; 7 DP1.10033.001 Litterfall and fine woody debris production and chemistry #&gt; 8 DP1.10038.001 Mosquito sequences DNA barcode #&gt; 9 DP1.10041.001 Mosquito-borne pathogen status #&gt; 10 DP1.10043.001 Mosquitoes sampled from CO2 traps #&gt; # … with 40 more rows i &lt;- grepl(&quot;bird&quot;, products$keywords) products[i, c(&quot;productCode&quot;, &quot;productName&quot;)] #&gt; # A tibble: 1 x 2 #&gt; productCode productName #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 DP1.10003.001 Breeding landbird point counts Download all data files in the bird survey data products. neon_download(&quot;DP1.10003.001&quot;) #&gt; comparing hashes against local file index... #&gt; updating release manifest... View your store of NEON products: neon_index() #&gt; # A tibble: 854 x 15 #&gt; product site table type ext month timestamp horizontalPosit… #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; #&gt; 1 DP1.100… BART brd_co… basic csv 2015… 2020-12-23 14:17:30 NA #&gt; 2 DP1.100… BART brd_co… basic csv 2016… 2020-12-23 14:17:14 NA #&gt; 3 DP1.100… BART brd_co… basic csv 2017… 2020-12-23 14:17:36 NA #&gt; 4 DP1.100… BART brd_co… basic csv 2018… 2020-12-23 14:17:21 NA #&gt; 5 DP1.100… BART brd_co… basic csv 2019… 2020-12-23 14:17:45 NA #&gt; 6 DP1.100… BART brd_co… basic csv 2020… 2020-12-23 14:17:03 NA #&gt; 7 DP1.100… BART brd_co… basic csv 2020… 2020-12-23 14:17:41 NA #&gt; 8 DP1.100… BART brd_pe… basic csv 2015… 2020-12-23 14:17:30 NA #&gt; 9 DP1.100… BART brd_pe… basic csv 2016… 2020-12-23 14:17:14 NA #&gt; 10 DP1.100… BART brd_pe… basic csv 2017… 2020-12-23 14:17:36 NA #&gt; # … with 844 more rows, and 7 more variables: verticalPosition &lt;dbl&gt;, #&gt; # samplingInterval &lt;chr&gt;, date_range &lt;chr&gt;, path &lt;chr&gt;, md5 &lt;chr&gt;, #&gt; # crc32 &lt;chr&gt;, release &lt;chr&gt; These files will persist between sessions, so you only need to download once or to retrieve updates. neon_index() can take arguments to filter by product or pattern (regular expression) in table name, e.g.neon_index(table = \"brd\"). Once you determine the table of interest, you can read in all the component tables into a single data.frame neon_read(&quot;brd_countdata-expanded&quot;) #&gt; NULL 11.2.3 Database backend neonstore now supports a backend relation database as well. Import data from the raw downloaded files using neon_store(): neon_store(table = &quot;brd_countdata-expanded&quot;) #&gt; table brd_countdata-expanded not found, do you need to download first? Alternately, we could import all data tables associated with a given product: neon_store(product = &quot;DP1.10003.001&quot;) #&gt; importing brd_countdata-basic-DP1.10003.001... #&gt; importing brd_perpoint-basic-DP1.10003.001... Access an imported table using neon_table() instead of neon_read(): neon_table(&quot;brd_countdata&quot;) #&gt; # A tibble: 203,220 x 23 #&gt; uid namedLocation domainID siteID plotID plotType pointID #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 01cef6c1-5851-407… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… C1 #&gt; 2 43990e9a-1412-427… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… C1 #&gt; 3 d4f59f3c-e3f1-4a7… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… C1 #&gt; 4 4ad44b7d-1eb6-465… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… C1 #&gt; 5 944a3e0e-08de-497… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… C1 #&gt; 6 d4cb0f22-923b-449… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… C1 #&gt; 7 0cc69b4f-650f-4f7… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… B1 #&gt; 8 c6367f2f-8b74-402… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… B1 #&gt; 9 406e8277-2c18-4b2… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… B1 #&gt; 10 ef879541-c8d5-41c… HEAL_006.birdGri… D19 HEAL HEAL_… distribu… B1 #&gt; # … with 203,210 more rows, and 16 more variables: startDate &lt;dttm&gt;, #&gt; # eventID &lt;chr&gt;, pointCountMinute &lt;dbl&gt;, targetTaxaPresent &lt;chr&gt;, #&gt; # taxonID &lt;chr&gt;, scientificName &lt;chr&gt;, taxonRank &lt;chr&gt;, vernacularName &lt;chr&gt;, #&gt; # observerDistance &lt;dbl&gt;, detectionMethod &lt;chr&gt;, visualConfirmation &lt;chr&gt;, #&gt; # sexOrAge &lt;chr&gt;, clusterSize &lt;dbl&gt;, clusterCode &lt;chr&gt;, identifiedBy &lt;chr&gt;, #&gt; # file &lt;chr&gt; Access the remote database using neon_db(). This is a DBIConnection that can easily be used with dplyr functions like tbl() or filter(). Remember that dplyr translates these into SQL queries that run directly on the database. library(dplyr) #&gt; #&gt; Attaching package: &#39;dplyr&#39; #&gt; The following objects are masked from &#39;package:stats&#39;: #&gt; #&gt; filter, lag #&gt; The following objects are masked from &#39;package:base&#39;: #&gt; #&gt; intersect, setdiff, setequal, union con &lt;- neon_db() brd &lt;- tbl(con, &quot;brd_countdata-basic-DP1.10003.001&quot;) brd %&gt;% filter(siteID == &quot;ORNL&quot;) #&gt; # A tibble: 8,797 x 23 #&gt; uid namedLocation domainID siteID plotID plotType pointID #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 33425600-9ce1-4a9… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 2 faf5ee98-43e9-40f… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 3 2dc63a4a-3da1-4e0… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 4 7952192b-55b4-48f… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 5 41bf843e-3433-4d0… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 6 e88d8ada-e43a-409… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 7 04604bac-dd88-4d1… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 8 05a8d535-3f59-413… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 9 b5cccafa-acbf-41e… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; 10 63d9e30e-ab6c-41b… ORNL_002.birdGri… D07 ORNL ORNL_… distribu… A1 #&gt; # … with 8,787 more rows, and 16 more variables: startDate &lt;dttm&gt;, #&gt; # eventID &lt;chr&gt;, pointCountMinute &lt;dbl&gt;, targetTaxaPresent &lt;chr&gt;, #&gt; # taxonID &lt;chr&gt;, scientificName &lt;chr&gt;, taxonRank &lt;chr&gt;, vernacularName &lt;chr&gt;, #&gt; # observerDistance &lt;dbl&gt;, detectionMethod &lt;chr&gt;, visualConfirmation &lt;chr&gt;, #&gt; # sexOrAge &lt;chr&gt;, clusterSize &lt;dbl&gt;, clusterCode &lt;chr&gt;, identifiedBy &lt;chr&gt;, #&gt; # file &lt;chr&gt; Note that we need to include the product name in the table name when accessing the database, as table names alone may not be unique. RStudio users can also list and explore all tables interactively in the Connections pane in RStudio using neon_pane(). 11.2.4 Note on API limits If neon_download() exceeds the API request limit (with or without the token), neonstore will simply pause for the required amount of time to avoid rate-limit-based errors. The NEON API now rate-limits requests.. Using a personal token will increase the number of requests you can make before encountering this delay. See link for directions on registering for a token. Then pass this token in .token argument of neon_download(), or for frequent use, add this token as an environmental variable, NEON_DATA to your local .Renviron file in your user’s home directory. neon_download() must first query each the API of each NEON site which collects that product, for each month the product is collected. (It would be much more efficient on the NEON server if the API could take queries of the from /data/&lt;product&gt;/&lt;site&gt;, and pool the results, rather than require each month of sampling separately!) 11.2.5 Non-stacking files and low-level interface At it’s core, neonstore is simply a mechanism to download files from the NEON API. While the .csv files from the Observation Systems (OS, e.g. bird count surveys), and Instrument Systems (e.g. aquatic sensors) are typically stacked into large tables, other products, such as the .laz and .tif images produced by the airborne observation platform LIDAR and cameras may require a different approach. # Read in a large file list for illustration purposes cper_data &lt;- readr::read_csv(&quot;https://minio.thelio.carlboettiger.info/shared-data/neon_data_catalog.csv.gz&quot;) #&gt; Registered S3 methods overwritten by &#39;readr&#39;: #&gt; method from #&gt; format.col_spec vroom #&gt; print.col_spec vroom #&gt; print.collector vroom #&gt; print.date_names vroom #&gt; print.locale vroom #&gt; str.col_spec vroom #&gt; #&gt; ── Column specification ──────────────────────────────────────────────────────── #&gt; cols( #&gt; crc32 = col_character(), #&gt; name = col_character(), #&gt; size = col_double(), #&gt; url = col_character() #&gt; ) ## Typically one would read all files in local store, e.g. list.file(neon_dir()) df &lt;- neon_filename_parser(cper_data$name) library(dplyr) df %&gt;% count(EXT, sort=TRUE) #&gt; # A tibble: 13 x 2 #&gt; EXT n #&gt; &lt;chr&gt; &lt;int&gt; #&gt; 1 csv 38816 #&gt; 2 &lt;NA&gt; 8938 #&gt; 3 zip 4197 #&gt; 4 tif 3994 #&gt; 5 txt 3359 #&gt; 6 xml 3316 #&gt; 7 kml 1155 #&gt; 8 dbf 1100 #&gt; 9 prj 1100 #&gt; 10 shp 1100 #&gt; 11 shx 1100 #&gt; 12 h5 1093 #&gt; 13 laz 330 We can take a look at all laz LIDAR files: df %&gt;% filter(EXT == &quot;laz&quot;) #&gt; # A tibble: 330 x 31 #&gt; NEON DOM SITE DPL PRNUM REV DESC YYYY_MM PKGTYPE GENTIME EXT name #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 2 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 3 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 4 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 5 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; uncl… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 6 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 7 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 8 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 9 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; clas… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; 10 NEON D10 CPER DP1 &lt;NA&gt; &lt;NA&gt; uncl… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; laz NEON… #&gt; # … with 320 more rows, and 19 more variables: MISC &lt;chr&gt;, HOR &lt;chr&gt;, #&gt; # VER &lt;chr&gt;, TMI &lt;chr&gt;, YYYY_MM_DD &lt;chr&gt;, DATE_RANGE &lt;chr&gt;, FLHTSTRT &lt;chr&gt;, #&gt; # EHCCCCCC &lt;chr&gt;, IMAGEDATETIME &lt;chr&gt;, NNNN &lt;chr&gt;, NNN &lt;chr&gt;, R &lt;chr&gt;, #&gt; # FLIGHTSTRT &lt;chr&gt;, EEEEEE &lt;chr&gt;, NNNNNNN &lt;chr&gt;, FLHTDATE &lt;chr&gt;, #&gt; # FFFFFF &lt;chr&gt;, README &lt;lgl&gt;, COMPRESSION &lt;lgl&gt; Note that many of the airborne observation platform (AOP) products, such as these LIDAR files, do not include the PRNUM or REV components that make up part of the productCodes used in the NEON product tables. 11.3 EFIstandards package This package summarizes the proposed community standards for the common formatting and archiving of ecological forecasts developed by the Ecological Forecasting Initiative (EFI). Such open standards are intended to promote interoperability and facilitate forecast adoption, distribution, validation, and synthesis. 11.3.1 Output Files: EFI has proposed a three-tiered approach reflecting trade-offs in forecast data volume and technical expertise. The prefered output file format is in netCDF following standard CF conventions for dimensions and variable naming conventions, with ensemble member as a dimension where appropriate. The second-tier option is a semi-long CSV format, with state variables as columns and each row representing a unique issue datetime, prediction datetime, location, ensemble member, etc. The third-tier option is similar to option 2, but each row represents a specific summary statistic (mean, upper/lower CI) rather than individual ensemble members. 11.3.2 Output Metadata: EFI’s proposed metadata represents an expansion upon the Ecological Metadata Language (EML), with two key differences. First, is the specification of additonalMetadata tags to store forecast specific information (e.g. uncertainty propagation and data assimilation) as well as some summary information about model complexity, included uncertainties, etc. designed to facilitate cross-forecast synthesis. Second, a number of EML tags (e.g. temporal resolution, output variables) are considered a required part of forecast metadata that are otherwise optional in base EML. This package includes an R tool for validating these EML files. 11.3.3 Archiving: EFI envisions a three-tiered approach to forecast archiving. At the most basic level, forecasts should be archived before new observations become available (not possible for hindcasts), preferably in a FAIR public archive that permits forecasts to be uploaded automatically, allows metadata to be searchable, and assigns a DOI. Second, in addition to this the codes used to generate forecasts should also be archived, preferably in an open archive or code repository (e.g. Github) that can be assigned a DOI. Finally, in addition to output and code archiving, we encourage running forecast workflows to be archived using virtualization approaches, such as Docker or Singularity containers. 11.3.4 Vignettes: This package includes a number of vignettes illustrating the application of the EFI standards to different forecasts 11.3.5 Documentation: A more detailed description of the EFI standard can be found at https://shorturl.at/irMQW. Note that the Standard is a work in progress. If you find issues as you are applying them, let us know at eco4cast.initiative@gmail.com. Pkgdown rendered documentation of functions and vignettes can be found at https://eco4cast.github.io/EFIstandards/ "],["example-forecast-workflow.html", "12 Example Forecast Workflow 12.1 Step 0: Set up R environment and directories 12.2 Step 0: Define team name and team members 12.3 Step 1: Download latest target data and site description data 12.4 Step 2: Get drivers 12.5 Step 3.0: Generate forecasts for each site 12.6 Step 4: Generate metadata 12.7 Step 5: Submit forecast! 12.8 Example on github", " 12 Example Forecast Workflow Here is an example of a complete workflow for generating a forecast submission to the Challenge. The example is for the aquatics theme and it forecasts water temperature and oxygen. The water temperature forecast uses a linear regression between air temperature and water temperature to predict water temperature in the future. It then uses the prediction of water temperature to predict oxygen water oxygen concentration by assuming that the oxygen is 100% saturated given the predicted temperature. To generate the forecast we need to: 1) Build a relationship between past air temperature and past water temperature. 2) Apply the relationships from #1 to forecasted air temperature. 3) Calculate oxygen concentration from the forecasted water temperature. Therefore we need to: 1) Download the historical water temperature data for the NEON sites (called “targets”). 2) Download historical air temperature data for the NEON sites (we the stacked NOAA GEFS weather). 3) Download NOAA weather forecast for the NEON sites. 4) Create linear regression model based on historical data for each NEON site. 5) Apply linear regression to using weather forecasts for each NEON. 6) Write forecast output file. 7) Correct metadata describing forecast. 8) Submit forecast to Challenge. Each of these steps are below 12.1 Step 0: Set up R environment and directories We will be downloading NOAA forecasts from the Challenge s3 bucket and submitting to the s3 bucket. Therefore the AWS information is needed. library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.5 ✔ purrr 0.3.4 ## ✔ tibble 3.1.6 ✔ dplyr 1.0.8 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(neon4cast) library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(rMR) ## Loading required package: biglm ## Loading required package: DBI #library(EFIstandards) Sys.setenv(&quot;AWS_DEFAULT_REGION&quot; = &quot;data&quot;, &quot;AWS_S3_ENDPOINT&quot; = &quot;ecoforecast.org&quot;) dir.create(&quot;drivers&quot;, showWarnings = FALSE) Define the date that the forecast starts. For demonstration purposes, we are setting the date to 2022-02-15. In a real-time application, use forecast_date &lt;- Sys.Date() forecast_date &lt;- lubridate::as_date(&quot;2022-02-15&quot;) 12.2 Step 0: Define team name and team members team_name &lt;- &quot;air2waterSat&quot; team_list &lt;- list(list(individualName = list(givenName = &quot;Quinn&quot;, surName = &quot;Thomas&quot;), organizationName = &quot;Virginia Tech&quot;, electronicMailAddress = &quot;rqthomas@vt.edu&quot;)) 12.3 Step 1: Download latest target data and site description data These targets are updated when new data is available from NEON. target &lt;- readr::read_csv(&quot;https://data.ecoforecast.org/targets/aquatics/aquatics-targets.csv.gz&quot;, guess_max = 1e6) ## Rows: 9763 Columns: 10 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): siteID ## dbl (8): oxygen, temperature, chla, oxygen_sd, temperature_sd, chla_sd, dep... ## date (1): time ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. A table is available with NEON site descriptions. The calculation of oxygen saturation requires the elevation of each site, which is included in the site description table. site_data &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/eco4cast/neon4cast-aquatics/master/Aquatic_NEON_Field_Site_Metadata_20210928.csv&quot;) ## Rows: 5 Columns: 46 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (22): field_domain_id, field_site_id, field_site_name, field_site_type, ... ## dbl (10): field_latitude, field_longitude, field_utm_northing, field_utm_eas... ## lgl (14): field_minimum_elevation_m, field_maximum_elevation_m, field_domina... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. 12.4 Step 2: Get drivers 12.4.1 Step 2.1: Download Paste NOAA forecast stacked together To build the relations between air and water temperature, we need historical air temperature data to associate with historical water temperature data. Here we use a product that the Challenge organizers created that combines day 1 NOAA weather forecasts (i.e., when the forecasts are most accurate) together to generate an estimate of past weather. He we download this “stack” NOAA product for the set of NEON sites in the targets file. sites &lt;- unique(target$siteID) for(i in 1:length(sites)){ neon4cast::get_stacked_noaa_s3(&quot;.&quot;,site = sites[i], averaged = FALSE) } 12.4.2 Step 2.2: Download NOAA future forecast We need NOAA Weather forecasts of the future. Fortunately, the Challenge organizers are downloading and subsetting the weather forecasts for each NEON site. Here we download the weather forecast (date = forecast_date) that started at mid-night UTC (cycle=00) for the set of sites in the target file. sites &lt;- unique(target$siteID) for(i in 1:length(sites)){ neon4cast::get_noaa_forecast_s3(&quot;.&quot;,model = &quot;NOAAGEFS_1hr&quot;, site = sites[i], date = forecast_date, cycle = &quot;00&quot;) } 12.4.3 Step 2.3 Create data frames of drivers The NOAA stacked and forecast files are netcdf files. Here we convert to data frames to used in our analyses. noaa_past &lt;- neon4cast::stack_noaa(dir = &quot;drivers&quot;, model = &quot;NOAAGEFS_1hr_stacked&quot;) noaa_future &lt;- neon4cast::stack_noaa(dir = &quot;drivers&quot;, model = &quot;NOAAGEFS_1hr&quot;, forecast_date = forecast_date) 12.4.4 Step 2.4 Aggregate (to day) and convert units of drivers Since we are forecasting daily mean water temperature and oxygen, we need to aggregate the 1 hr weather data to the daily time-scale. We also need to convert from Kelvin to Celsius. noaa_past_mean &lt;- noaa_past %&gt;% mutate(date = as_date(time)) %&gt;% group_by(date) %&gt;% summarize(air_temperature = mean(air_temperature, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% rename(time = date) %&gt;% mutate(air_temperature = air_temperature - 273.15) For the future weather has 31 ensemble members (i.e., different trajectories of weather), that we want to use to generate uncertainty in our water temperature and oxygen forecasts. The aggregation below maintains the separate ensemble members (group_by(date, ensemble)). noaa_future_mean &lt;- noaa_future %&gt;% mutate(date = as_date(time)) %&gt;% group_by(date, ensemble) %&gt;% summarize(air_temperature = mean(air_temperature, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% rename(time = date) %&gt;% mutate(ensemble = as.numeric(stringr::str_sub(ensemble, start = 4, end = 6)), air_temperature = air_temperature - 273.15) 12.4.5 Step 2.5: Merge in past NOAA data into the targets file, matching by date. Before building our linear model we need merge in the historical air temperature to match with the historical water temperature target &lt;- left_join(target, noaa_past_mean, by = &quot;time&quot;) 12.5 Step 3.0: Generate forecasts for each site We generate a forecast for each site. forecast &lt;- NULL for(i in 1:length(sites)){ # Get site information for elevation site_info &lt;- site_data %&gt;% filter(field_site_id == sites[i]) #Fit linear model based on past data: water temperature = m * air temperature + b fit &lt;- lm(target$temperature~target$air_temperature) #use linear regression to forecast water temperature for each ensemble member forecasted_temperature &lt;- fit$coefficients[1] + fit$coefficients[2] * noaa_future_mean$air_temperature #use forecasted temperature to predict oxygen by assuming that oxygen is saturated. forecasted_oxygen &lt;- rMR::Eq.Ox.conc(forecasted_temperature, elevation.m = ,site_info$field_mean_elevation_m, bar.press = NULL, bar.units = NULL, out.DO.meas = &quot;mg/L&quot;, salinity = 0, salinity.units = &quot;pp.thou&quot;) #Build site level dataframe. Note we are not forecasting chla site_forecast &lt;- tibble(time = noaa_future_mean$time, siteID = sites[i], ensemble = noaa_future_mean$ensemble, forecast = 1, temperature = forecasted_temperature, oxygen = forecasted_oxygen, chla = NA) #Bind with other sites forecast &lt;- bind_rows(forecast, site_forecast) } Use ggplot to visualize the forecast for each variable and site. The spread in forecast is due to uncertainty in the weather forecast, where each line is associated with a different NOAA GEFS weather forecast ensemble member. forecast %&gt;% select(-chla) %&gt;% pivot_longer(cols = c(&quot;temperature&quot;,&quot;oxygen&quot;), names_to = &quot;variable&quot;, values_to = &quot;values&quot;) %&gt;% ggplot(aes(x = time, y = values, group = ensemble)) + geom_line() + facet_grid(variable~siteID, scale =&quot;free&quot;) Forecast output file name in standards requires for Challenge. “csv.gz” means that it will be compressed forecast_file &lt;- paste0(&quot;aquatics&quot;,&quot;-&quot;,min(forecast$time),&quot;-&quot;,team_name,&quot;.csv.gz&quot;) Write csv to disk write_csv(forecast, forecast_file) Confirm that output file meets standard for Challenge neon4cast::forecast_output_validator(forecast_file) 12.6 Step 4: Generate metadata First we need to create a “list” in R that describes the forecast model. We only have one source of uncertainty (driver). It is propagated (i.e., represented in the forecasted output) using 31 ensemble members. model_metadata = list( forecast = list( model_description = list( forecast_model_id = &quot;air2waterSat&quot;, #What goes here name = &quot;Air temperature to water temperature linear regression plus assume saturated oxygen&quot;, type = &quot;empirical&quot;, repository = &quot;https://github.com/rqthomas/neon4cast-example&quot; ), initial_conditions = list( status = &quot;absent&quot; ), drivers = list( status = &quot;propagates&quot;, complexity = 1, #Just temperature propagation = list( type = &quot;ensemble&quot;, size = 31) ), parameters = list( status = &quot;absent&quot; ), random_effects = list( status = &quot;absent&quot; ), process_error = list( status = &quot;absent&quot; ), obs_error = list( status = &quot;absent&quot; ) ) ) Using the team_list and model_metadata above, we can create the metadata file. The function neon4cast::generate_metadata adds additional information to complete the metadata (i.e., geographic information about the site, etc.) metadata_file &lt;- neon4cast::generate_metadata(forecast_file, team_list, model_metadata) 12.7 Step 5: Submit forecast! Now we can submit the forecast output and the metadata file to the Challenge using the neon4cast::submit() function neon4cast::submit(forecast_file = forecast_file, metadata = metadata_file, ask = FALSE) You can check on the status of your submission using neon4cast::check_submission(forecast_file) On following day after submission, you can see the forecast on the dashboard at shiny.ecoforecast.org 12.8 Example on github The example code above can be found on GitHub as a template repository at [https://github.com/eco4cast/neon4cast-example.git]. See the Readme for more information about using the template "],["using-the-challenge-in-classes.html", "13 Using the Challenge in Classes", " 13 Using the Challenge in Classes Under construction! If you are interested in using the Challenge in a class or workshop, we welcome you to reach out to us at eco4cast.initiative@gmail.com "],["frequently-asked-questions.html", "14 Frequently Asked Questions 14.1 My model uses meterology inputs. Where can I find forecasts of weather to use in my ecological forecast? 14.2 I need historical weather data to build my model. Where can I find it? 14.3 I submitted my forecast but cannot find it on the dashboard or in the directory of forecasts 14.4 Do I need to submit forecasts to every submission date? 14.5 Where can I find examples of forecasts that match the required standard? 14.6 Is it possible to automate my forecast submissions? 14.7 I am having trouble generating the metadata. Can you point me to more information, tutorials, or examples? 14.8 How many years are you planning to run the Challenge? 14.9 Are there certain types of models that I need to use? 14.10 What is the relationship between the Challenge and NEON? 14.11 I am interested in submitting different models or to multiple themes. How should I register to do this? 14.12 Where can I find resources that provide how to participate in the Challenge?", " 14 Frequently Asked Questions 14.1 My model uses meterology inputs. Where can I find forecasts of weather to use in my ecological forecast? We have downloaded and temporally downscaled (6 hr to 1 hr) weather forecasts from NOAA’s Global Ensemble Forecasting System (GEFS). GEFS produces 31 different forecasts (called an ensemble with 31 members) at four cycles a day (00:00, 06:00, 12:00, and 18:00 UTC), where these are the times that the forecast starts. The forecast that starts at the 00:00 cycle runs 30 of the 31 ensemble members 35-days in the future. All other forecast cycles have members that run 16-days in the future. The forecasts can be found at https://data.ecoforecast.org/minio/drivers/noaa/NOAAGEFS_1hr/ The following variables are available: air temperature, wind speed, relative humidity, downwelling shortwave, downwelling longwave, precipitation, and air pressure. This video demonstrates how to access meteorological covariate data for the Challenge. The video was recorded for the 2021 Early Career Annual Meeting 14.2 I need historical weather data to build my model. Where can I find it? NEON collects weather variables at each of the sites. Their data products become available in 1-month data packages that are release ~ 2 weeks after the completion of the month. For example, the June 1 data will be in the June package that is released mid-July. Therefore there is up to a 1.5 month delay. Furthermore, NEON data can have gaps that need to be gap-filled. We are working with NEON to develop gap-filled weather data that becomes available sooner than the current 1.5 month delay. The timing of the gap-filled low-latency weather product is unknown. If you don’t need real-time data, NEON weather data products are available on the NEON data portal at the following data products: Air temperature: https://data.neonscience.org/data-products/DP1.00002.001 Precipitation: https://data.neonscience.org/data-products/DP1.00006.001 Radiation: https://data.neonscience.org/data-products/DP1.00023.001 Wind: https://data.neonscience.org/data-products/DP1.00001.001 Relative humidity: https://data.neonscience.org/data-products/DP1.00098.001 Air pressure: https://data.neonscience.org/data-products/DP1.00004.001 Summary statistics (daily, monthly, annually): https://data.neonscience.org/data-products/DP4.00001.001 Gridded weather from models that have been assimilated with observations are available from other sources including: NASAs National Land Data Assimilation System: 4 day delay Daymet is an option for daily meteorology variables, though it doesn’t yet cover 2020-2021. Daymet has an R package that can be used to download data for a single location or a set of locations. ERA5 product has high-quality subdaily data with ensemble-based uncertainties. Download scripts are available through the PEcAn project: https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/download.ERA5.R Other meteorology products can be downloading using functions in PEcAn: https://github.com/PecanProject/pecan/blob/develop/modules/data.atmosphere/R/download.ERA5.R 14.3 I submitted my forecast but cannot find it on the dashboard or in the directory of forecasts A successful submission can be found at the following links within 2 hours of submissions You can check the status of your submssion using the following function in the neon4cast package neon4cast::check_submission(&quot;phenology-2022-02-07-persistence.nc&quot;) ## Submission was successfully processed We run a validator script when processing the submissions. If your submission does not meet the file standards above, you can run a function that provides information describing potential issues. The forecast file needs to be in your local working directory or you need to provide a full path to the file neon4cast::forecast_output_validator(&quot;phenology-2022-02-07-persistence.nc&quot;) If your submission did not meet the standard contact us and we can help you work through the issues. 14.4 Do I need to submit forecasts to every submission date? No, we are excited to have submissions at any of the submissions dates. 14.5 Where can I find examples of forecasts that match the required standard? Aquatics https://data.ecoforecast.org/forecasts/aquatics/aquatics-2021-03-01-EFInull.csv.gz Phenology https://data.ecoforecast.org/forecasts/phenology/phenology-2021-02-23-UCSC_P_EDM.csv https://data.ecoforecast.org/forecasts/phenology/phenology-2021-02-23-EFInull.nc Beetles https://data.ecoforecast.org/forecasts/beetles/beetles-2020-EFI_avg_null.csv.gz Terrestrial https://data.ecoforecast.org/forecasts/terrestrial/terrestrial_daily-2020-10-01-EFInulldaily.csv.gz https://data.ecoforecast.org/forecasts/terrestrial/terrestrial_30min-2021-04-01-hist30min.nc Ticks https://data.ecoforecast.org/forecasts/ticks/ticks-2019-03-04-tickGlobalNull_RandomWalk.csv.gz 14.6 Is it possible to automate my forecast submissions? Yes. There are many ways to automate scripts that are written to download observations and metreology drivers, generate forecasts, and submit forecasts. Two tools that many have used are cron jobs (see the R package cronR) that execute tasks at user specifics times and github actions. See more at Frequently Asked Questions Cron jobs work on unix and mac systems. An example of a script that executes a cron job using R can be found here. 14.7 I am having trouble generating the metadata. Can you point me to more information, tutorials, or examples? Pending 14.8 How many years are you planning to run the Challenge? The RCN is a 5-year project and we aim to run the Challenge for the duration of the project. Each year will be a new round where we revise the rules (if necessary) and add new Themes. Your feedback on the Challenge will be critical to revising and clarifying the rules and information about the Challenge. 14.9 Are there certain types of models that I need to use? No, you can use any type of model, including empirical and process-based models. The only requirement is that your forecast includes uncertainty. The uncertainty can be represents using different model runs (ensemble members) or the statistics of the forecast (mean and standard deviation). 14.10 What is the relationship between the Challenge and NEON? The Challenge is run by the Ecological Forecasting Initiative Research Coordination Network that is funded by the U.S. National Science Foundation. While this effort is separate from NEON, NEON staff have been in involved in all stages of planning. NEON staff are on the project steering committee and theme design teams. Members of the RCN are also on NEON’s Ecological Forecasting Technical Working Group. This is formal pathway to provide feedback to NEON. 14.11 I am interested in submitting different models or to multiple themes. How should I register to do this? Each new model needs its own registration with a different model name. If you have a large team where entering everyone’s contact inforamtion will preclude submitting multiple registrations, contact us at eco4cast.initiative@gmail.com for assistance. 14.12 Where can I find resources that provide how to participate in the Challenge? These following videos were recorded for the 2021 Early Career Annual Meeting. You can see the full playlist HERE or view individual videos below. Videos Related to Specific Steps in Forecast Creation and Submission Introduction to the NEON Forecast Challenge Reproducible Workflows Using NEON data for the NEON Forecast Challenge Accessing Meteorological Covariate Data From Models to Forecasts Submitting to the NEON Forecast Challenge Ecological Forecasting Resources Overview of Each of the Challenge Themes Terrestrial Carbon and Water Fluxes Spring and Fall Phenology Beetle Communities Aquatic Ecosystems Tick Populations Flash Talks Highlighting Experiences By Early Career Individuals As They Submitted Their Forecasts Phenology Forecast and the Kalman Filter Phenology Forecast using the DALEC-SIP Model Using GitHub Actions to Automate Forecast Execution and Submission "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
