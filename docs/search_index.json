[["index.html", "NEON Ecological Forecasting Challenge Introduction", " NEON Ecological Forecasting Challenge Ecological Forecasting Initative Research Coordination Network 2021-04-02 Introduction The NSF funded EFI Research Coordination Network (EFI-RCN) is hosting a NEON Ecological Forecast Challenge with the goal to create a community of practice that builds capacity for ecological forecasting by leveraging NEON data products. The Challenge revolves around the five theme areas listed below that span aquatic and terrestrial systems, and population, community, and ecosystem processes across a broad range of ecoregions that uses data collected by NEON. As a community, we are excited to learn more about the predictability of ecological processes by forecasting NEON data prior to its release. What modeling frameworks, mechanistic processes, and statistical approaches best capture community, population, and ecosystem dynamics? These questions are answerable by a community generating a diverse array of forecasts. The Challenge is open to any individual or team that wants to submit forecasts and includes categories for different career stages. Individuals or team contacts can register to submit forecasts HERE. The design of the Challenge is the result of contributions of over 200 participants in the May 2020 virtual EFI-RCN meeting, including partner organizations, and the hard work from the Design Teams that have developed the protocols for each of the themes. Computational resources are supported by NSF funded CyVerse, Jetstream, and XSEDE. We have prepared introductory videos from the December 9, 2020 AGU EFI Town Hall. They providing an overview of 1. the Challenge 2. the Challenge cyberinfrastructure 3. the NEON data streams "],["theme-aquatic-ecosystems.html", "1 Theme: Aquatic Ecosystems 1.1 Overview 1.2 Challenge 1.3 Data: Targets 1.4 Timeline 1.5 Design Team 1.6 Partners 1.7 References", " 1 Theme: Aquatic Ecosystems What: Freshwater temperature and dissolved oxygen Where: 1 lake and 1 river NEON sites. Click to expand the image in a new tab. When: Daily forecasts with a 7-day forecast horizon at the beginning of the month and submitted monthly from May 31-August 2021; later submissions after the May 31 start are permissible Why: Temperature and oxygen are critical for life in aquatic environments and can represent the health of the system Who: Open to any individual or team that registers How: REGISTER your team and submit forecast 1.1 Overview In streams and rivers, forecasting water temperature can be meaningful for protecting aquatic communities while maintaining socio-economic benefits (Ouellet-Proulx et al. 2017). In lentic systems, successfully forecasting surface water temperatures can be important for fisheries and water utilities that need to manage the outflowing temperatures (Zhu et al. 2020). Recently, water temperature forecasts in lakes have been used to predict seasonal turnover when nutrients from the bottom can be mixed to the surface and impair the water quality. Dissolved oxygen concentration is a critically important variable in limnology. Forecasts of dissolved oxygen in freshwaters is the first step to understanding other freshwater ecosystem processes. For example, oxygen serves as the gatekeeper to other biogeochemical reactions that occur in rivers and lakes. Preemptive forecasts of dissolved oxygen concentrations can anticipate periods of high or low oxygen availability, thereby providing insight into how the ecosystem may change at relatively short timescales. 1.2 Challenge This design challenge asks teams to produce forecasts of mean daily surface water temperature and/or dissolved oxygen in one NEON lake and/or one NEON river site in the Southeastern U.S. 35 days from the first of the month. The NEON lake site is Barco Lake (BARC) in Florida and the NEON river site is Posey Creek (POSE) in Virginia. Each forecast will start on the 1st day of each month and must forecast up to 7 days into the future. Forecasts are welcome to go past the 7 day timeline but those dates will not be evaluated. Teams are asked to submit their 7 day forecasts of NEON surface water temperature and/or dissolved oxygen measurements along with uncertainty estimates and metadata. Any NEON surface water temperature and/or dissolved oxygen data prior to the 7 days being forecasted will be provided and may be used to build and improve the forecast models. Other data (other than temperature and/or dissolved oxygen data provided from NEON) can be used so long as they are not from the 7 days being forecasted at the beginning of each month, that they are publicly available, and that teams provide access (minimum of URL, but ideally a script) to all teams in the challenge. Submissions of forecast and metadata will be through https://data.ecoforecast.org/minio/submissions/ using prescribed file formats described in the challenge theme documentation Forecasts will be scored and compared using the Continuous Ranked Probability Score, a metric that combines accuracy and uncertainty estimation (Gneiting, T., &amp; Raftery, A. E., 2007). 1.3 Data: Targets The R script for generating the evaluation and training data (i.e., targets) can be found at: https://github.com/eco4cast/neon4cast-aquatics The challenge uses the following NEON data products: DP1.20264.001: Temperature at specific depth in surface water DP1.20288.001: Water quality A file with previously released NEON data that has been processed into targets is provided below. The target script can be found here. The same processing will be applied to new data that are used for forecast evaluation. Before the Aquatics challenge begins, a processing script is available in the neon4cast-aquatics GitHub repository. Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/aquatics/aquatics-targets.csv.gz&quot;) ## # A tibble: 2,556 x 9 ## time siteID oxygen temperature oxygen_sd temperature_sd depth_oxygen ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2017-10-20 BARC 6.01 26.4 0.0114 0.00104 1.19 ## 2 2017-10-21 BARC 6.06 26.3 0.00717 0.000986 1.20 ## 3 2017-10-22 BARC 6.13 26.4 0.00721 0.00119 1.19 ## 4 2017-10-23 BARC 6.43 26.6 0.00765 0.000944 1.16 ## 5 2017-10-24 BARC 6.31 26.4 0.00746 0.00118 1.11 ## 6 2017-10-25 BARC 6.27 25.9 0.00737 0.00107 1.13 ## 7 2017-10-26 BARC 6.30 25.0 0.00743 0.00105 1.19 ## 8 2017-10-27 BARC 6.41 24.3 0.00762 0.00104 1.22 ## 9 2017-10-28 BARC 6.48 24.1 0.00766 0.00111 1.17 ## 10 2017-10-29 BARC 6.64 23.8 0.00783 0.00101 1.10 ## # … with 2,546 more rows, and 2 more variables: depth_temperature &lt;dbl&gt;, ## # neon_product_ids &lt;chr&gt; 1.3.1 Surface Mean Daily Dissolved Oxygen Concentration Definition Dissolved oxygen (DO) is the concentration of oxygen dissolved in water. NEON’s 30-minute time resolution from deployed water quality sondes among the freshwater sites reports this concentration as mg L-1. We have adapted the available NEON DO data to output the mean daily DO concentration in mg L-1 from a water quality sonde deployed 1m below the water surface at a lake site (Barco Lake) and a water quality sonde deployed in a stream site (Posey Creek). Common DO concentrations range between 0 and 12 mg L-1 and DO concentrations less than 2 mg L-1 are considered hypoxic. Motivation Dissolved oxygen concentration is a critically important variable in limnology. Forecasts of dissolved oxygen in freshwaters is the first step to understanding other freshwater ecosystem processes. For example, oxygen serves as the gatekeeper to other biogeochemical reactions that occur as well as determine the variety and health of aquatic organisms present in rivers and lakes. Preemptive forecasts of dissolved oxygen concentrations can anticipate periods of high or low oxygen availability, thereby providing insight into how the ecosystem may change at relatively short timescales. 1.3.2 Surface Mean Daily Water Temperature Definition Water temperature is the temperature of the water. NEON’s 30-minute time resolution from deployed water temperature sondes in the freshwater sites reports this in degrees celsius (°C). We have adapted the available NEON water temperature data to output the mean daily water temperature in °C from a water temperature sonde deployed 1m below the water surface at a lake site (Barco Lake) and a water temperature sonde deployed in a stream site (Posey Creek). Common water temperatures in lakes and streams range between 4 and 35 °C. Motivation In streams and rivers, forecasting water temperature can be meaningful for protecting aquatic communities while maintaining socio-economic benefits (Ouellet-Proulx et al. 2017). In lentic and lotic systems, successfully forecasting water temperatures can be important for management of fisheries and water utilities that rely on specific threshold temperatures (Zhu et al. 2020). Recently, lake temperature forecasts have been used to predict seasonal turnover, mixing bottom nutrients into the surface and impairing water quality.Data 1.4 Timeline The timeline is determined by the data latency provided by NEON. NEON data is released in month long sets, 2 weeks after the month ends. NEON data for a given month is scheduled to be released around the 15th of the following month. Once the NEON data for a previous month is released, teams have between the release of those data to the end of the month to forecast the 7 days of the current month (see table). Forecast submissions will due beginning May 31, 2021 at 11:59 Eastern Standard Time (UTC−05:00) for forecasts that start May 1. Final forecast submissions will be due on August 31, 2021 at 11:59 Eastern Standard Time (UTC−05:00) for forecasts that start August 1. As an example, if NEON water temperature data is released on April 15 for data from March 1 - 31, teams then can use these new March data and the NOAA GEFS forecast issued on April 1 at 00:00 to help generate forecasts from April 1 - April 8 (7 days). This April forecast is due by 11:59 pm EST on April 30. The forecast issue date for the April forecast is April 1, so no new observational data from after that date can be used to constrain forecasts and the forecast should use the weather forecast issued at midnight April 1 (i.e. start of day) as the driver (not the observed meteorology in April or forecasts made at later dates). Evaluation will occur as new NEON data is released. Forecast Timeline Table 1.5 Design Team James Guinnip, Kansas State University Sarah Burnet, University of Idaho Ryan McClure, Virginia Tech Chris Brown, National Oceanic and Atmospheric Administration Cayelan Carey, Virginia Tech Whitney Woelmer, Virginia Tech Jake Zwart, United States Geological Survey 1.6 Partners The challenge is hosted by the Ecological Forecasting Initiative (EFI; https://ecoforecast.org/) and its U.S. National Science Foundation sponsored Research Coordination Network (EFI-RCN; https://ecoforecast.org/rcn/). Data used in the challenge are from the National Ecological Observatory Network (NEON): https://www.neonscience.org/. Scientists from NOAA and USGS have been involved in the design of the challenge. 1.7 References Gneiting, T., &amp; Raftery, A. E. (2007). Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477), 359–378. https://doi.org/10.1198/016214506000001437 Ouellet-Proulx, S., St-Hilaire, A., and Bouchar, M.-A.. 2017. Water temperature ensemble forecasts: Implementation using the CEQUEAU model on two contrasted river systems. Water 9(7):457. https://doi.org/10.3390/w9070457 Zhu, S., Ptak, M., Yaseen, Z.M., Dai, J. and Sivakumar, B. 2020. Forecasting surface water temperature in lakes: a comparison of approaches. Journal of Hydrology 585, 124809. https://doi.org/10.1016/j.jhydrol.2020.124809 "],["theme-carbon-and-water-fluxes.html", "2 Theme: Carbon and Water Fluxes 2.1 Overview 2.2 Challenge 2.3 Data: Targets 2.4 Timeline 2.5 Design team 2.6 Partners 2.7 References", " 2 Theme: Carbon and Water Fluxes What: Net ecosystem exchange of CO2, evapotranspiration, and soil moisture Where: 4 NEON sites that span a water stress gradient in the U.S. The images below show the flux tower at the center of each site. When: Half hour and/or daily forecasts for a 35 day period are submitted once per month January 31-December 31, 2021; later submissions after the January 31 start are permissible Why: Carbon and water cycling are fundamental for climate and water regulation services provided by ecosystems Who: Open to any individual or team that registers How: REGISTER your team and submit forecast We held a Q&amp;A session on January 22, 2021. You can find a recording from that session HERE. 2.1 Overview The exchange of water and carbon dioxide between the atmosphere and the land is akin to earth’s terrestrial ecosystems breathing rate and lung capacity. The water available to plant roots plays a critical role in plant function, and subsequently represents a predominant source of uncertainty for predictions of how much carbon is entering or exiting an ecosystem. One of the best ways to monitor changes in the amount of carbon and water in an ecosystem is the eddy-covariance method. This method observes the net amount of carbon and water entering and exiting ecosystems at half-hourly timesteps, which is important because it can provide information on ecosystem processes such as photosynthesis, respiration, and transpiration, their sensitivities to ongoing climate and land use change, and greenhouse gas budgets for carbon accounting and natural climate solutions. Forecasts of carbon uptake and release, water use, and soil moisture can provide insights into future production of food, fiber, timber, and carbon credits. Additionally, forecasts will highlight the influence that stress and disturbance have on carbon and water cycling. 2.2 Challenge This design challenge asks teams to produce forecasts of net ecosystem exchange of carbon dioxide (NEE), latent heat flux of evapotranspiration (LE), and soil moisture across four NEON sites with differing climates. These target variables are important because they can be used to inform energy budgets and further reduce uncertainty in the CO2 sink or source behavior of the terrestrial biosphere. This forecasting challenge asks teams to forecast NEE, LE, and soil moisture at either the 30-minute or daily time step over the next 35-days using NOAA Global Ensemble Forecast System weather forecasts as drivers (if forecasting model uses meteorological inputs). Monthly forecasts can be submitted for each month in 2021. The challenge will take place using the eddy covariance flux towers at 4 NEON sites: Bartlett Experimental Forest (BART), Konza Prairie Biological Station (KONZ), Ordway-Swisher Biological Station (OSBS), and Santa Rita Experimental Range (SRER). Users are asked to submit their forecast of measured NEON NEE, LE, and soil moisture data, along with uncertainty estimates and metadata. Any NEE, LE, and soil moisture data prior to the month being forecasted may be used to build and improve the models used to generate forecasts. Other data can be used so long as they are not from the month being forecast and the data are made publicly available (minimum of URL, but ideally a script) and accessible to all teams in the challenge. 2.3 Data: Targets The challenge uses the following NEON data products: DP4.00200.001: Bundled data products - eddy covariance DP1.00094.001: Soil water content and water salinity A file with previously released NEON data that has been processed into “targets” is provided below. The same processing will be applied to new data that are used for forecast evaluation. Before the Terrestrial Carbon and Water Flux challenge begins, a processing script will be available in the neon4cast-terrestrial GitHub repository. 2.3.1 Net ecosystem exchange Definition Net ecosystem exchange (NEE) is the net movement of carbon dioxide from the atmosphere to the ecosystem. At the 30-minute time resolution is reported as \\(\\mu\\)mol CO2 m-2 s-1. At the daily time resolution it is reported as g C m-2 day-1. Negative values correspond to an ecosystem absorbing CO2 from the atmosphere, positive values correspond to an ecosystem emitting CO2 to the atmosphere. Motivation NEE quantifies the net exchange of CO2 between the ecosystem and the atmosphere over that 30-minute or daily time period. Assessing skill at predicting 1/2 hourly - sub daily measurements provides more insight into ability to capture diel processes. The diel curve contains information on how plants and soil immediately respond to variations in meteorology. Making daily predictions will allow us to rapidly assess skill and provide information in a timeframe pertinent to inform and implement natural resource management. It also allows for models that do not produce sub-daily estimates to participate 2.3.2 Latent heat flux Definition Latent heat flux is the movement of water as water vapor from the ecosystem to the atmosphere. It is reported as W m-2 (equivalent to J m-2 s-1). At the daily time resolution it is reported as g H2O m-2 day-1. Positive values correspond to a transfer of water vapor from the ecosystem to the atmosphere. Motivation Latent heat measures the water loss from an ecosystem to the atmosphere through evapotranspiration (transpiration through plants + evaporation from surfaces). Forecasting latent heat (evapotranspiration) can provide insights to water stress for plants and the efficiency that plants are using water relative to NEE, and to the amount of liquid water remaining in the soil for soil moisture forecasting 2.3.3 Soil moisture Definition Volumetric soil water content integrated at one station (station 3) at 15 cm depth. It is reported as a proportion of water volume to soil volume. Motivation Volumetric water content is the measurement of water availability in soil. This water can be transpired during photosynthesis by plants. Forecasts of volumetric water content can provide insights into water stress for plants. 2.3.4 Focal sites Site Name SiteID NEON Domain Latitude Longitude Dominant Species Bartlett Experimental Forest, NH BART D01: Northeast 44.0639 -71.2874 Fagus grandifolia, Tsuga canadensis, Acer pensylvanicum Ordway Swisher Biological Station, FL OSBS D03: Southeast 31.91068 -81.99343 Herbaceous and woody wetlands, Evergreen forest Konza Prairie Biological Station, KS KONZ D06: Prairie Peninsula 39.10077 -96.56309 Midwestern tallgrass prairie Santa Rita Experimental Range, AZ SRER D14: Desert Southwest 31.91068 -110.83549 Southwest desert shrub/scrub All sites are near Ameriflux sites that could be used when developing the models if the data are publicly available in the Ameriflux database. If Ameriflux data is used, teams MUST follow Ameriflux data use policy (which is different from NEON’s) Bartlett - US-Bar: Bartlett Experimental Forest (2004-2017) Konza - US-Kon: Konza Prairie LTER (KNZ) (2004-2019) - US-KFB: Konza Prairie LTER (4B) (2006-present) Santa Rita - US-SRC: Santa Rita Creosote (2008-2018, physically closest tower to the NEON tower) - US-SRG: Santa Rita Grassland (2008-2019) - US-SRM: Santa Rita Mesquite (2003-2019) - US-SRS: Santa Rita Experimental Range Mesquite Savanna (2011-2019) Ordway-Swisher - US-SP1: Slashpine-Austin Cary- 65yrs nat regen (2000-2011) - US-SP2: Slashpine-Mize-clearcut-3yr,regen (1998-2008) - US-SP3: Slashpine-Donaldson-mid-rot- 12yrs (1999 - 2010) - US-SP4: Slashpine-Rayonier-mid-rot- 12yrs (1998) Images of the four focal sites 2.3.5 30-minute target data calulation To create the data for evaluation (and training) for NEE and LE we extract NEE and LE that pass the turbulence quality control flags (qfqm.fluxCo2.turb.qfFinl and qfqm.fluxH2o.turb.qfFinl = 0) provided by NEON. To calculate depth integrated soil moisture (VSWC) for the half-hourly, we used the depth of each sensor. The midpoints between each sensor were used to calculate the proportion of the depth profile each sensor occupied. Soil moisture values from each sensor were weighted by the proportion of the depth profile, then summed to generate the target variable. The table with the half-hour NEE, LE, and VSWC has the following columns siteID: NEON site code (e.g., BART) time: YYYY-MM-DD HH:MM for the start of the 30-minute period in UTC nee: umol CO2 m-2 s-1 le: W m-2 vswc: (%) nee_sd_intercept: intercept in the nee observation uncertainty standard deviation nee_sd_slopeP: slope in the relationship between nee and observation uncertainty standard deviation for positive values of nee nee_sd_slopeN: slope in the relationship between nee and observation uncertainty standard deviation for negative values of nee le_sd_intercept: intercept in the le observation uncertainty standard deviation le_sd_slopeP:slope in the relationship between le and observation uncertainty standard deviation for positive values of le le_sd_slopeN: slope in the relationship between le and observation uncertainty standard deviation for negative values of le vswc_sd: observation uncertainty standard deviation vswc The observation uncertainty estimates for nee and le are derived from the PECAN project and can be used by sd_nee &lt;- nee_sd_intercept + nee_sd_slopeP * nee. They are not supplied by NEON. The standard derivation for the vswc (vswc_sd) is the uncertainty reported by NEON. Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/terrestrial/terrestrial_30min-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 285,768 x 12 ## time siteID nee le nee_sd_intercept nee_sd_slopeP ## &lt;dttm&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2017-02-01 15:00:00 BART 3.13 2.52 0.710 0.217 ## 2 2017-02-01 15:30:00 BART NA NA 0.710 0.217 ## 3 2017-02-01 16:00:00 BART NA NA 0.710 0.217 ## 4 2017-02-01 16:30:00 BART 0.476 5.69 0.710 0.217 ## 5 2017-02-01 17:00:00 BART NA NA 0.710 0.217 ## 6 2017-02-01 17:30:00 BART 0.412 7.27 0.710 0.217 ## 7 2017-02-01 18:00:00 BART 0.812 23.7 0.710 0.217 ## 8 2017-02-01 18:30:00 BART NA NA 0.710 0.217 ## 9 2017-02-01 19:00:00 BART 0.820 19.1 0.710 0.217 ## 10 2017-02-01 19:30:00 BART 0.364 3.95 0.710 0.217 ## # … with 285,758 more rows, and 6 more variables: nee_sd_slopeN &lt;dbl&gt;, ## # le_sd_intercept &lt;dbl&gt;, le_sd_slopeP &lt;dbl&gt;, le_sd_slopeN &lt;dbl&gt;, vswc &lt;dbl&gt;, ## # vswc_sd &lt;dbl&gt; 2.3.6 Daily target data calulation To evaluate the models that produce daily flux forecasts, we select only days with at least 44 of 48 half hours that pass the quality control flags. For these days, we average the half-hours and convert to daily units (gC/m2/day). The daily data table has the following columns. siteID: NEON site code (e.g., BART) time: YYYY-MM-DD (the day is determined using UTC time) nee: g C m-2 day-1 le: g H2O m-2 day-1 vswc: (%) vswc_sd: observation uncertainty standard deviation vswc NEED TO ADD WHERE vswc_sd comes from readr::read_csv(&quot;https://data.ecoforecast.org/targets/terrestrial/terrestrial_daily-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 5,956 x 6 ## time siteID nee le vswc vswc_sd ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2017-02-01 BART NA NA NA NA ## 2 2017-02-01 KONZ NA NA NA NA ## 3 2017-02-01 OSBS NA NA NA NA ## 4 2017-02-01 SRER NA NA NA NA ## 5 2017-02-02 BART NA NA NA NA ## 6 2017-02-02 KONZ NA NA NA NA ## 7 2017-02-02 OSBS NA NA NA NA ## 8 2017-02-02 SRER NA NA NA NA ## 9 2017-02-03 BART NA NA NA NA ## 10 2017-02-03 KONZ NA NA NA NA ## # … with 5,946 more rows The R script for generating the evaluation and training data can be found at: https://github.com/eco4cast/neon4cast-terrestrial 2.4 Timeline The timeline is determined by the data latency provided by NEON. NEON data is released in month long sets, 2 weeks after the month ends. The challenge will begin January 31, 2021 at 11:59 Eastern Standard Time (UTC−05:00) and run through December 31, 2021. Subsequent forecasts are due at 11:59 EST on the final day of each month. NEON data for a given month is scheduled to be released around the 15th of the following month. Once the NEON data for a previous month is released, teams have between the release of those data to the end of the month to forecast the current month. For example, NEON eddy-covariance data area will be released on January 15 that contains values for December 1 - 31. Teams can use these December eddy-covariance data to help generate forecasts from Jan 1 - February 5 (35 days). This January forecast is due by 11:59 pm EST on January 31. The forecast issue date for the January forecast is January 1, so no new observational data from after that date can be used to constrain forecasts and the forecast should use the weather forecast issued at midnight January 1 (i.e. start of day) as the driver (not the observed meteorology in January or forecasts made at later dates). See the calendar below for a visual depiction of the data availability and forecast submission timeline. Evaluation will occur as new NEON data is released. 2.5 Design team Alex Young, SUNY - College of Environmental Science &amp; Forestry George Burba, LI-COR Biosciences Jamie Cleverly, Terrestrial Ecosystem Research Network (TERN) Ankur Desai, University of Wisconsin, Madison Mike Dietze, Boston University Andy Fox, Joint Center for Satellite Data Assimilation William Hammond, Oklahoma State University Danica Lombardozzi, National Center for Atmospheric Research Quinn Thomas, Virginia Tech 2.6 Partners Data used in the challenge are from the National Ecological Observatory Network (NEON) Ameriflux is an excellent database of eddy-covariance data, including historical data for some of the four challenge sites. Terrestrial Ecosystem Research Network (TERN) has been involved in the design of the challenge: 2.7 References "],["theme-tick-populations.html", "3 Theme: Tick Populations 3.1 Overview 3.2 Challenge 3.3 Data: Targets 3.4 Timeline 3.5 Design team 3.6 Partners 3.7 References", " 3 Theme: Tick Populations What: Amblyomma americanum and Ixodes scapularis nymphal tick abundance per sampled area Where: 22 plots at 7 NEON sites When: Weekly forecasts for 34 weeks into the future starting March 31-October 31, 2021 with training data available January 31, 2021. Forecasts are submitted monthly and later submissions after the March 31 start are permissible. Why: There is a correlation between tick population abundance and disease incidence, meaning forecasts for tick abundance have the potential to aid in our understanding of disease risk through time and space. Who: Open to any individual or team that registers How: REGISTER your team and submit forecast 3.1 Overview Target species for the population forecasts are Amblyomma americanum and Ixodes scapularis nymphal ticks. A. americanum is a vector of ehrlichiosis, tularemia, and southern tick-associated rash illness, while I. scapularis is a vector for Lyme disease, the most prevalent tick-borne disease in North America. Both species are present in the eastern United States, and have been collected at numerous NEON sites. There is a correlation between tick population abundance and disease incidence, meaning forecasts for tick abundance have the potential to aid in our understanding of disease risk through time and space. 3.2 Challenge The challenge is open to any individual, group, or institution that may want to participate. The goals of this challenge are to forecast total Ixodes scapularis and Amblyomma americanum nymphs each epidemiological week (Sun-Sat) per sampled area at a set of NEON plots within NEON sites. Due to challenges in data collected in 2020, this round of the forecasting challenge will simulate a true forecasting challenge by focusing on data from the 2019 field season. NOAA Global Ensemble Forecast System weather forecasts for each NEON site is provided for teams to use: https://data.ecoforecast.org/minio/drivers/noaa/ Teams must provide access (minimum of URL, but ideally a script) to any additional data they wish to use to all teams in the challenge. Teams of various career stages and disciplines are encouraged. 3.3 Data: Targets The challenge uses the following NEON data products: DP1.10093.001: Ticks sampled using drag cloths Total Ixodes scapularis will be forecasting for the following plots (siteID_plotID): BLAN_012, BLAN_005, SCBI_013, SCBI_002, SERC_001, SERC_005, SERC_006, SERC_012, ORNL_007 Total Amblyomma americanum will be forecasting for the following plots (siteID_plotID): SCBI_013, SERC_001, SERC_005, SERC_006, SERC_002, SERC_012, KONZ_025, UKFS_001, UKFS_004, UKFS_003, ORNL_002, ORNL_040, ORNL_008, ORNL_007, ORNL_009, ORNL_003, TALL_001, TALL_008, TALL_002 A file with previously released NEON data that has been processed into “targets” is provided below. The same processing will be applied to new data that are used for forecast evaluation. Before the Tick challenge begins, a processing script will be available in the neon4cast-ticks GitHub repository. 3.3.1 Amblyomma americanum nymphs Definition Total Amblyomma americanum nymphs per week per plot. Determined by the number of individuals caught and identified to species each epidemiological week at each plot. Each tick caught is identified to the lowest taxonomic level possible, and we are only interested in nymphal ticks identified to species (instead of only being identified to Family, Order, Genus etc.) Motivation Species is a vector of disease, so forecasting tick abundance can potentially aid in assessing disease risk. 3.3.2 Ixodes scapularis nymphs Definition Total Ixodes scapularis nymphs per week per plot. Determined by the number of individuals caught and identified to species each epidemiological week at each plot. Each tick caught is identified to the lowest taxonomic level possible, and we are only interested in nymphal ticks identified to species (instead of only being identified to Family, Order, Genus etc.) Motivation Species is a vector of disease, so forecasting tick abundance can potentially aid in assessing disease risk. 3.3.3 Focal sites Site Name SiteID NEON Domain Latitude Longitude Ixodes scapularis Plots Amblyomma americanum Plots Blandy Experimental Farm, VA BLAN D02: Mid-Atlantic 39.06026 -78.07164 BLAN_012, BLAN_005 Smithsonian Conservation Biology Institute, VA SCBI D02: Mid-Atlantic 38.89292 -78.1395 SCBI_013, SCBI_002 SCBI_013 Smithsonian Environmental Research Center, MD SRER D02: Mid-Atlantic 38.89008 -76.56001 SERC_001, SERC_005, SERC_006, SERC_012 SERC_001, SERC_002, SERC_005, SERC_006 SERC_012 Oak Ridge, TN ORNL D07: Appalachians &amp; Cumberland Plateau 35.96412 -84.2826 ORNL_007 ORNL_002, ORNL_003, ORNL_007, ORNL_008, ORNL_009, ORNL_040 Konza Prairie Biological Station, KS KONZ D06: Prairie Peninsula 39.10077 -96.56309 KONZ_025 The University of Kansas Field Station, KS UKFS D06: Prairie Peninsula 39.04043 -95.19215 UKFS_001, UKFS_003, UKFS_004 Talladega National Forest, AL TALL DO8: Ozarks Complex 32.95046 -87.39327 TALL_001, TALL_002, TALL_008 3.3.4 Target data calulation The data used for this challenge is a subset of the full NEON tick data set. While ticks of multiple species have been identified at most NEON sites, not all species-by-site combinations have enough non-zero observations to build adequate population models. Therefore, the targets for this challenge are A. americanum and I. scapularis nymphs, which represent the two most abundant species observed at NEON. Additionally, the plots that forecasts will be made are plots where these ticks have been identified at least three times each year from 2016 to 2018. The latency for taxonomic identifications of the NEON tick field data is roughly one year (meaning forecast for 2021 won’t be validated until 2022), and the 2020 field season was irregular due to the COVID-19 pandemic. Therefore, the target year of 2019 was chosen so that forecasts can be evaluated in a timely manner for a regular field season. Use of 2019 data: The forecasting challenge is for the 2019 field season, thus tick observations and environmental covariates are known. However, in the spirit of keeping this as much of a “forecasting” challenge as possible, 2019 data (tick and environmental covariates) can only be used in the timeline described below in the timeline section. For example, if a forecast is submitted on May 31st, and a team is using temperature as a covariate in their model, it is up to the team to forecast temperature from May 31st through the end of the season. This policy is in place because if forecasts use the observed temperature from May 31 through the end of the season in their forecast, these forecasts will be overconfident. 3.3.5 Target file Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/ticks/ticks-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 3,969 x 21 ## Year epiWeek yearWeek plotID siteID nlcdClass decimalLatitude ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2015 37 201537 BLAN_005 BLAN deciduousForest 39.1 ## 2 2015 38 201538 BLAN_005 BLAN deciduousForest 39.1 ## 3 2015 39 201539 BLAN_005 BLAN deciduousForest 39.1 ## 4 2015 40 201540 BLAN_005 BLAN deciduousForest 39.1 ## 5 2015 41 201541 BLAN_005 BLAN deciduousForest 39.1 ## 6 2015 42 201542 BLAN_005 BLAN deciduousForest 39.1 ## 7 2015 43 201543 BLAN_005 BLAN deciduousForest 39.1 ## 8 2015 44 201544 BLAN_005 BLAN deciduousForest 39.1 ## 9 2015 45 201545 BLAN_005 BLAN deciduousForest 39.1 ## 10 2015 46 201546 BLAN_005 BLAN deciduousForest 39.1 ## # … with 3,959 more rows, and 14 more variables: decimalLongitude &lt;dbl&gt;, ## # elevation &lt;dbl&gt;, totalSampledArea &lt;dbl&gt;, amblyomma_americanum &lt;dbl&gt;, ## # ixodes_scapularis &lt;dbl&gt;, time &lt;date&gt;, RHMin_precent &lt;dbl&gt;, ## # RHMin_variance &lt;dbl&gt;, RHMax_precent &lt;dbl&gt;, RHMax_variance &lt;dbl&gt;, ## # airTempMin_degC &lt;dbl&gt;, airTempMin_variance &lt;dbl&gt;, airTempMax_degC &lt;dbl&gt;, ## # airTempMax_variance &lt;dbl&gt; Year: Year of observation epiWeek: The ISO week that starts on Sunday, consistent with CDC version of the epidemiological week (integer, WW) yearWeek: (YYYYWW) Year week, combination of year and epidemiological week ixodes_scapularis: Count. If no observation in the associated yearWeek: NA amblyomma_americanum: Count. If no observation in the associated yearWeek: NA plotID: Plot where ticks are observed (HARV_002). Combination of targetSpecied and targetPlotID. A single identifier that represents the species being forecasted at the given plot. Used to save and score forecasts. siteID: Site where ticks are observed (HARV) nlcdClass: Land cover classification (mixedForest) decimalLatitude: Latitude of the site decimalLongitude: Longitude of the site Elevation: Elevation of the plot (meters) totalSampledArea: Area sampled by drag cloth (sq. m). If there is not a sampling event in given week: NA RHMin_percent: The minimum relative humidity percent recorded in the associated yearWeek. If no observation: NA RHMin_variance: Variance (percent squared) of the minimum relative humidity recorded in the associated yearWeek. If no observation: NA RHMax_percent: The maximum relative humidity percent recorded in the associated yearWeek. If no observation: NA RHMax_variance: Variance (percent squared) of the maximum relative humidity recorded in the associated yearWeek. If no observation: NA airTempMin_degC: The minimum air temperature, in degrees celsius, recorded in the associated yearWeek. If no observation: NA airTempMin_variance: Variance (degrees celsius squared) of the minimum air temperature recorded in the associated yearWeek. If no observation: NA airTempMax_degC: The maximum air temperature, in degrees Celsius, recorded in the associated yearWeek. If no observation: NA airTempMax_variance: Variance (degrees celsius squared) of the maximum air temperature recorded in the associated yearWeek. If no observation: NA Environmental data (weekly relative humidity and air temperature) in the challenge data set are provided as a starting point for teams that may not want to look for other environmental data. The challenge design team does not recommend one of these variables over another (from NEON or otherwise) or guarantee that their use will improve forecast accuracy. Furthermore, the environmental data provided is only available for the core terrestrial sites (KONZ, ORNL, SCBI, TALL). 3.4 Timeline The timeline for this challenge will be monthly, which is how often new data will be released by the EFI RCN. The final data set containing the training data will be available no later than January 31st, 2021. The challenge will begin (first forecast submission) on March 31st, 2021 at 11:59 PM Eastern Standard Time, and will run through October 31st, 2021 (last forecast submission). 2019 data will be released on the first of the month following a submission deadline, which gives teams a month to assimilate new data. For example, the forecasts submitted on March 31st, 2021 will be for every epidemiological week starting at the beginning of March 2019 through the end of November 2019. Then, on April 1st, 2021, tick counts from March 2019 will be released. The next forecast submission is April 30th, 2021, which will be for every epidemiological week starting at the beginning of April 2019 through the end of November 2019. The table below shows which epidemiological weeks are to be forecasted for each submission date. 2021 Forecast Submission date 2019 Target Epidemiological weeks March 31 10-44 April 30 14-44 May 31 19-44 June 30 23-44 July 31 28-44 August 31 32-44 September 31 36-44 October 31 41-44 Evaluation will occur shortly after each forecast submission. 3.5 Design team John Foster, Boston University Matt Bitters, University of Colorado, Boulder Melissa Chen, University of Colorado, Boulder Leah Johnson, Virginia Tech Shannon LaDeau, Cary Institute of Ecosystem Studies Cat Lippi, University of Florida Brett Melbourne, University of Colorado, Boulder Wynne Moss, University of Colorado, Boulder Sadie Ryan, University of Florida 3.6 Partners Data used in the challenge are collected by the National Ecological Observatory Network (NEON; https://www.neonscience.org/). 3.7 References "],["theme-phenology.html", "4 Theme: Phenology 4.1 Overview 4.2 Challenge 4.3 Data: Targets: 4.4 Timeline 4.5 Design team 4.6 Partners 4.7 References", " 4 Theme: Phenology What: Terrestrial phenology defined by daily greenness of plants Where: 8 deciduous broadleaf forest NEON sites in the continental U.S. When: Daily forecasts for 35-days in the future from February 1 - July 1, 2021 with a second round being run for the autumn. Forecast submissions are accepted daily, and later submissions after the February 1 start are permissible. Why: Phenology has been identified as one of the primary ecological fingerprints of global climate change. Who: Open to any individual or team that registers How: REGISTER your team and submit forecast We held a Q&amp;A session on January 27, 2021. You can find a recording from that session HERE. 4.1 Overview Phenology has been shown to be a robust integrator of the effects of year-to-year climate variability and longer-term climate change on natural systems (e.g., recent warming trends). Experimental studies have shown how other global change factors (e.g., elevated CO2 and N deposition) can also influence phenology. There is a need to better document biological responses to a changing world, and improved phenological monitoring at scales from individual organisms to ecosystems, regions, and continents will contribute to achieving this goal. Phenology researchers often use digital cameras (such as those that are part of the PhenoCam Network) that take regular repeated images of plant canopies to monitor changes in greenness throughout the year. The PhenoCam Network is a cooperative continental-scale phenological observatory that uses digital repeat photography to track vegetation phenology in a diverse range of ecosystems across North America and around the World. Imagery and data are made publicly available in near-real-time through the PhenoCam webpage: http://phenocam.sr.unh.edu/. 4.2 Challenge This is an open ecological forecasting challenge to forecast spring green-up of the common greenness index (GCC), as measured by digital cameras at various deciduous broadleaf NEON sites. The forecasts will be forecasts of daily mean GCC (specifically the 90% quantile, which has been shown to be more robust). The sites include Harvard Forest (HARV), Bartlett Experimental Forest (BART), Smithsonian Conservation Biology Institute, (SCBI), Steigerwaldt Land Services (STEI), The University of Kansas Field Station, KS (UKFS), Great Smoky Mountains National Park (GRSM), Dead Lake (DELA), and National Grassland (CLBJ). NOAA Global Ensemble Forecast System weather forecasts for each NEON site is provided for teams to use: https://data.ecoforecast.org/minio/drivers/noaa/ Teams must provide access (minimum of URL, but ideally a script) to any additional data they wish to use to all teams in the challenge. Teams of various career stages and disciplines are encouraged to submit forecasts. Submissions of forecast and metadata will be through https://data.ecoforecast.org/minio/submissions/ using prescribed file formats described in the challenge theme documentation (PENDING). Forecasts will be scored and compared using the Continuous Ranked Probability Score, a metric that combines accuracy and uncertainty estimation (Gneiting, T., &amp; Raftery, A. E., 2007). 4.3 Data: Targets: The challenge uses the following NEON data products: DP1.00033.001: Phenology images A file with previously released NEON data that has been processed into “targets” is provided below. The same processing will be applied to new data that are used for forecast evaluation. Before the Phenology challenge begins, a processing script will be available in the neon4cast-phenology GitHub repository. 4.3.1 Green chromatic coordinate (gcc) Definition The ratio of the green digital number to the sum of the red, green, blue digital numbers from a digital camera Motivation Quantitative metrics of vegetation color extracted from PhenoCam imagery provide data that are consistent with ground observations of phenology and as well as other conventional vegetation indices across ecosystems. 4.3.2 Focal sites Site Name Site (and PhenoCam) ID NEON Domain Latitude Longitude Dominant Species Harvard Forest, MA NEON.D01.HARV.DP1.00033 D01: Northeast 42.537 -72.173 Quercus rubra, Acer rubrum, Aralia nudicaulis Bartlett Experimental Forest, NH NEON.D01.BART.DP1.00033 D01: Northeast 44.0639 -71.2874 Liriodendron tulipifera, Microstegium vimineum, Juglans nigra Steigerwaldt Land Services, WI NEON.D05.STEI.DP1.00033 D05: Great Lakes 45.509 -89.586 Populus tremuloides, Abies balsamea, Acer rubrum The University of Kansas Field Station, KS NEON.D06.UKFS.DP1.00033 D06: Prairie Peninsula 39.040 -95.192 Symphoricarpos orbiculatus, Celtis occidentalis, Carya ovata Great Smoky Mountains National Park, TN NEON.D07.GRSM.DP1.00033 D07: Appalachians and Cumberland Plateau 35.689 -83.502 Liriodendron tulipifera, Acer rubrum, Acer pensylvanicum Dead Lake, AL NEON.D08.DELA.DP1.00033 D08: Ozarks Complex 32.542 -87.804 Celtis laevigata, Ligustrum sinense, Liquidambar styraciflua National Grassland, TX NEON.D11.CLBJ.DP1.00033 D11: Southern Plains 33.401 -97.570 Quercus marilandica, Schizachyrium scoparium 4.3.3 Target data calulation Digital cameras mounted above forests are pointed at the forest canopy. Images are collected every half hour. The images are a set of pixels values in red, blue, and blue color channels (RGB). A pixel value is an 8-bit digital number (DN). Because internal processing (including exposure control) and external factors affecting scene illumination (weather and atmospheric effects) both influence the retrieved RGB signature, we calculate a number of vegetation indices that are effective at suppressing this unwanted variation and maximizing the underlying phenological signal. Most important among these is the green chromatic coordinate (GCC), calculated as GCC = GDN / (RDN + GDN + BDN). For additional details, see Richardson et al. (2018) Scientific Data, and Richardson (2019) New Phytologist. PhenoCam data are processed and posted daily and the low latency of the PhenoCam data allows for a unique opportunity to evaluate forecasts in real-time. Each image has a defined “region of interest’ (ROI). An ROI is a set of pixels that isolates particular features in the image (i.e., a set of deciduous trees in a mixed forest). The ROI of “DB_1000” for the below top-of-canopy PhenoCams will be used to assess the forecasts’ accuracy. The mid-day (noon) mean GCC and GCC standard deviation for the “DB_1000” ROI will be used for evaluation. All data in the supplied file is available to build and evaluate models before submitting a forecast to challenge. Once new data becomes, the data are appended to the existing file. Within the challenge scoring, only the new data are used to evaluate previously submitted forecasts. 4.3.4 Target file time: YYYY-MM-DD statistic: variable name (“mean” or “sd”) gcc_90: siteID: NEON site code (e.g., BART) Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/ticks/ticks-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 3,969 x 21 ## Year epiWeek yearWeek plotID siteID nlcdClass decimalLatitude ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2015 37 201537 BLAN_005 BLAN deciduousForest 39.1 ## 2 2015 38 201538 BLAN_005 BLAN deciduousForest 39.1 ## 3 2015 39 201539 BLAN_005 BLAN deciduousForest 39.1 ## 4 2015 40 201540 BLAN_005 BLAN deciduousForest 39.1 ## 5 2015 41 201541 BLAN_005 BLAN deciduousForest 39.1 ## 6 2015 42 201542 BLAN_005 BLAN deciduousForest 39.1 ## 7 2015 43 201543 BLAN_005 BLAN deciduousForest 39.1 ## 8 2015 44 201544 BLAN_005 BLAN deciduousForest 39.1 ## 9 2015 45 201545 BLAN_005 BLAN deciduousForest 39.1 ## 10 2015 46 201546 BLAN_005 BLAN deciduousForest 39.1 ## # … with 3,959 more rows, and 14 more variables: decimalLongitude &lt;dbl&gt;, ## # elevation &lt;dbl&gt;, totalSampledArea &lt;dbl&gt;, amblyomma_americanum &lt;dbl&gt;, ## # ixodes_scapularis &lt;dbl&gt;, time &lt;date&gt;, RHMin_precent &lt;dbl&gt;, ## # RHMin_variance &lt;dbl&gt;, RHMax_precent &lt;dbl&gt;, RHMax_variance &lt;dbl&gt;, ## # airTempMin_degC &lt;dbl&gt;, airTempMin_variance &lt;dbl&gt;, airTempMax_degC &lt;dbl&gt;, ## # airTempMax_variance &lt;dbl&gt; 4.4 Timeline Forecasts for a minimum of 35 days can be submitted daily by 6 pm ET for the period of February 1st through July 1st, 2021. Forecast should be submitted starting February 1st by 6 pm ET. A minimum of 35 days in the future must be forecasted for each submission. For example, the first submitted forecast should be for at least February 1st – March 7th, but it could be for the full spring. New forecasts can be submitted daily as new weather forecasts and observations (e.g., PhenoCam) become available. Processed PhenoCam data will be available daily by 11:59 pm ET for each day. Teams are allowed to start submitting forecasts after February 1st, but only forecasts of future days (when submitted) will be allowed. Late forecasts might be allowed under extenuating circumstances related to computer failure or processing delayed on our end. Forecasts do not have to be submitted daily and can be longer than 35 days. 4.5 Design team Kathryn Wheeler, Boston University Michael Dietze, Boston University Kathy Gerst, National Phenology Network Chris Jones, NC State University Andrew Richardson, Northern Arizona University Bijan Seyednasrollah, Northern Arizona University, PhenoCam Network 4.6 Partners The challenge is hosted by the Ecological Forecasting Initiative (EFI; https://ecoforecast.org/) and its U.S. National Science Foundation sponsored Research Coordination Network (EFI-RCN; https://ecoforecast.org/rcn/). Data used in the challenge are collected by the National Ecological Observatory Network (NEON; https://www.neonscience.org/) and hosted by the Phenocam Network (http://phenocam.sr.unh.edu/). The forecasting challenge was developed in collaboration with the USA National Phenology Network: https://www.usanpn.org/usa-national-phenology-network. 4.7 References Gneiting, T., &amp; Raftery, A. E. (2007). Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477), 359–378. https://doi.org/10.1198/016214506000001437 "],["theme-beetle-communities.html", "5 Theme: Beetle Communities 5.1 Overview 5.2 Challenge 5.3 Data: Targets 5.4 Timeline 5.5 Design team 5.6 Partners 5.7 References", " 5 Theme: Beetle Communities What: Beetle abundance and species richness from the National Ecological Observatory Network Where: 47 terrestrial NEON sites that span the diverse ecosystems of the U.S. When: Weekly forecasts for 20 months in the future starting June 30-December 31, 2021; later submissions after the June 30 start are permissible Why: Improve understanding of habitat quality, conservation potential, land-use sustainability, and biodiversity change in response to global change and ecological disturbances Who: Open to any individual or team that registers How: REGISTER your team and submit forecast 5.1 Overview Biodiversity monitoring is critical for understanding environmental quality, evaluating the sustainability of land-use practices, and forecasting future impacts of global change on ecosystems. Sentinel species give forewarning of environmental risk to humans, so are particularly useful for such monitoring and forecasting efforts because they can provide surrogates for other co-located components of biodiversity (Sauberer et al. 2004). Ground beetles (Family: Carabidae) are appropriate candidates for biodiversity monitoring and ecological forecasting as they are well-studied sentinel species that are geographically widespread, and their community dynamics are particularly congruent with the diversity of other invertebrates (Holland 2002; Lundgren &amp; McCravy 2011; Bousquet 2012; Hoekman et al. 2017). Therefore, monitoring carabid communities and forecasting changes in their species richness and abundance can be useful in studying edge effects and habitat quality (Magura 2002), conservation potential (Butterfield 1995), land-use sustainability (Pearce &amp; Venier 2006) and biodiversity change in response to global change and ecological disturbances (Koivula 2011). Most ecological forecasting models are limited in the geographic scale and also suffer from scarcity of temporally extensive data. Further, most existing forecasting efforts focus on a single species (Humphries et al. 2018) with limited community-wide forecasts at the continental scale. Developing forecasts for community-scale metrics (i.e., species richness, abundance) and evaluating such models for accuracy and generalizability can help test our scientific knowledge of spatial (geographical turnover) and temporal (seasonal, inter-annual) carabid community dynamics (Dietze et al. 2018). Such forecasting models can inform regional or local habitat management, identify where biodiversity monitoring efforts should be prioritized, and shed light on what data or modelling techniques are needed to build the best forecasts of ecological dynamics (e.g., can we predict richness or abundance better and why?) (Johansson et al. 2019). With the long-term, community-wide, continental-scale data collection through the National Ecological Observatory Network (NEON), 181 data products are available for 81 sites in the US (47 terrestrial, at which carabids are sampled, and 34 aquatic). Fully initiated in 2019, this sampling will continue for 30 years (Schimel et al. 2007; 2011). NEON has effectively removed the previous barriers to community-scale forecasting across a broader geographical realm. 5.2 Challenge This is an open ecological forecasting challenge to forecast carabid species richness, defined as the total number of species, and abundance, defined as the total number of carabid individuals. The forecasts should be done weekly per site for all NEON terrestrial sites with richness being absolute and abundance scaled by the sampling effort. Contributing teams are required to submit a forecast for May-Dec 2021 and Jan-Dec 2022 on June 30, 2021. However, teams are encouraged to update their forecasts on the last day of each month, ending on December 31, 2021, as NEON validation data are released. NEON releases carabid sampling data weekly and no sooner than 60 days after collection, so a model submitted on June 30 can include a forecast for the first week of May, and so forth. Teams may use any open data products as drivers of richness and abundance so long as they are not from the month being forecast, and are made publicly available (minimum of URL, but ideally a script). Potential driver data sources include: NEON site data (Soil and sediment data, Terrestrial Plant data, weather data), NOAA forecasts, and beyond. 5.3 Data: Targets The challenge uses the following NEON data product: DP1.10022.001: Ground beetles sampled from pitfall traps A file with previously released NEON data that has been processed into the aggregate “target” variables (richness and abundance) is provided below. The same processing will be applied to new data that are used for forecast evaluation. Further information about data structure, initial code for processing, and example null forecasts is provided in the neon4cast-beetles GitHub repository. Forecasts will be made on a weekly basis for the abundance of beetles at a given NEON site at a given month (‘abundance’) and the observed species richness (n, number of species) of carabid beetles at each NEON site, each month. 5.3.1 Abundance of beetles (abundance) Definition Total number of carabid individuals per trap-night, estimated each week of the year at each NEON site Motivation A forecast prediction can be compared against only measured data (i.e. counts) and not latent variables (i.e. true carabid abundance), which are only inferred under specific model assumptions. However, raw count of beetles found in a particular trap depends on many other drivers than local abundance; in particular, the sampling effort. To avoid the need to accurately predict the sampling effort, we compute a target variable as counts per trap-night (number of nights each trap was set at the site; also called ‘catch per unit effort’). We chose this to define this variable in terms of total carabid abundance, rather than resolving to particular taxonomy (in contrast to species-specific relative abundance) because it simplifies issues related to taxonomic resolution of unpinned samples, data latency, and the choice of focal species. As supported by literature (Hoekman et al. 2017 and literature cited therein), we believe that abundance of the beetle family as a whole is an ecologically relevant metric. We considered predictions aggregated to the site level (rather than predicting individual traps or individual plots) to be both the most ecologically meaningful and simplest choice. Traps are typically collected every two weeks. Submitting a forecast for every week avoids the need to predict which weeks of the year collection does or does not occur. See https://github.com/eco4cast/NEON-community-forecast/blob/master/02_targets.R for a programmatic definition of how the abundance metric is defined. 5.3.2 Species richness (n) Definition Total number of unique ‘species’ in a sampling bout for each NEON site each week. For this challenge, we define ‘species’ as the taxonomic unit closest to species (e.g., species, genus, morphospecies) for each individual since not all identifications in the raw data are strictly at species-level. Motivation A forecast prediction can be compared against only measured data (i.e. observed count of taxonomic units) and not latent variables (i.e. count of species), which are only inferred under specific model and taxonomic assumptions. The number of unique taxonomic identities of beetles in a trap depends on many drivers, including sampling effort. As demonstrated by species rarefaction curves in ecology, the more time a trap is left out, the more individual beetles will fall in, and thus the more species can be expected. However, since perfect species-level data are not available to us and to keep the forecasted variables from being overly derived, we define the target variable as the total number of unique ‘species’ per week per NEON site. For this challenge, we chose to define ‘species’ as the taxonomic unit closest to species (e.g., species, genus, morphospecies) since not all identifications in the raw data are strictly at species-level. Species identifications will be used for individuals identified to sub-species level, as these are uncommon in the raw data. NEON taxonomists identify individuals as morphologically distinct units. Thus, it is reasonable to assert that the count of finest morphologically distinct identification (e.g., species, genus, morphospecies) is biologically meaningful, and thus the count of these is an important focal forecast variable. We focus on the NEON site as the spatial resolution and weekly intervals as the temporal resolution for the same reasons stated in the abundance metric. See https://github.com/eco4cast/NEON-community-forecast/blob/master/02_targets.R for a programmatic definition of how the richness metric is defined. 5.3.3 Focal sites All NEON terrestrial sites are included 5.3.4 Target data calulation Ground beetle data are collected at each NEON site every two weeks throughout the sampling season. The sampling season is defined based on measures of growing season, including vegetation indices, phenology, and degree days, for a maximum of 13 bouts per site during which the 10-day average low temperature at the site is &gt;4°C. Samples are collected from pitfall traps placed at each of the cardinal directions within the 10 plots per site representative of up to three dominant vegetation types. Four traps were placed from 2014-2017 and from 2018 onward the northward plot was eliminated leaving three traps for each plot. Ground beetles from the pitfall traps are removed, sorted, and identified to the lowest possible taxonomic rank or morphospecies. A subset of individuals (up to 467 per site and year) are sent to taxonomic experts for subsequent identification with priority on individuals for which species-level identification was not able to be assigned. Further detail can be found in the NEON Ground Beetle User Guide. Raw (NEON L1 ground beetle data product DP1.10022.001) are accessible via the NEON data portal, via the NEON API, via R using the neonUtilties package, and via R using neonStore::neon_download. The raw data is also available through the NEON data portal with archived copies at https://data.ecoforecast.org/minio/neonstore. The raw data is processed to generate total abundance and richness per week per NEON site. All data in the supplied file is available to build and evaluate models before submitting a forecast to challenge. Once new data becomes, the data are appended to the existing file. Within the challenge scoring, only the new data are used to evaluate previously submitted forecasts. As part of our reproducible workflow, we provide an R script for producing derived tables of total abundance and richness from the raw NEON data. Our workflow gives preference to expert taxonomist identifications when available. Since expert taxonomy lags behind identifications from the sorting and pinning process, newer data will not be updated with expert taxonomy. The abundance table gives total abundance at each site for each week. The richness table gives an aggregate count of the number of ‘species’ at each site in each week. Note: The table included all data that NEON has collected and can be used for building and training models (new data will be posted after forecasts are submitted) 5.3.5 Target file The table has the following columns: siteID: NEON site ID time: YYYY-MM-DD (the Monday marking the week of sample collection (for training data) or forecast (submission). Per ISO standards, Monday marks the first day of each week.) abundance: abundance of beetles richness: species richness The code use to process the raw data to the evaluation data can be found here: https://github.com/eco4cast/NEON-community-forecast/blob/master/02_targets.R Here is the format of the target file readr::read_csv(&quot;https://data.ecoforecast.org/targets/beetles/beetles-targets.csv.gz&quot;, guess_max = 1e6) ## # A tibble: 2,330 x 4 ## siteID time abundance richness ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CPER 2013-07-01 0.305 13 ## 2 DSNY 2013-07-01 0 NA ## 3 OSBS 2013-07-08 0 NA ## 4 STER 2013-07-08 0.116 6 ## 5 CPER 2013-07-15 0.493 12 ## 6 DSNY 2013-07-15 0 NA ## 7 HARV 2013-07-15 0.187 26 ## 8 OSBS 2013-07-22 0 NA ## 9 STER 2013-07-22 0.0952 7 ## 10 CPER 2013-07-29 0.220 13 ## # … with 2,320 more rows 5.4 Timeline The timeline is determined by the data latency provided by NEON. NEON carabid pitfall trap data is released weekly with a latency of at least 60 days after collection. Weekly forecasts were chosen to best match up with NEON’s weekly release of carabid data. The challenge will begin June 30, 2021 at 11:59 Eastern Standard Time (UTC−05:00) and run through December 31, 2021. Subsequent forecasts are due at 11:59 EST on the final day of each month. As an example, carabid pitfall trap data released in the last week of June would include data as recent as the last week of April. Thus, a model submitted in the last week of June could include forecasts from May onwards. Then, the forecast update submitted at the end of July can use new May data to help refine June forecasts, or forecasts following June, depending on what drivers are used. The July forecast update is due by 11:59 pm EST on July 31. Forecasts updates will not be considered for weeks where NEON validation data has already been released (i.e., no May forecast updates may be submitted on July 31) or for weeks when no NEON carabid data is available. Pitfall traps are collected and reset every 2 weeks throughout the growing season. Due to weather and conditions beyond the field team’s control, this collection schedule may not be followed. Thus, the exact collection dates cannot be known until they have happened. Field data are made publicly available on the data portal as the bet_fielddata dataframe no sooner than 14 days after collection. Teams can use bet_fielddata to inform the actual collection schedule. Data with parataxonomist identifications are made publicly available on the data portal as the bet_sorting dataframe no sooner than 60 days after collection. Data are released on the NEON data portal weekly, but may be released on any day of the week. The forecast schedule follows the ISO week standard with weeks starting on Mondays. 5.5 Design team Anna Spiers, University of Colorado, Boulder Carl Boettiger, University of California, Berkeley Tad Dallas, Louisiana State University Nico Franz, NEON Biorepository at Arizona State University Kari Norman, University of California, Berkeley Thilina Surasinghe, Bridgewater State University Brett Melbourne, University of Colorado, Boulder Eric Sokol, NEON Kelsey Yule, NEON Biorepository at Arizona State University 5.6 Partners The challenge is hosted by the Ecological Forecasting Initiative (EFI; https://ecoforecast.org/) and its U.S. National Science Foundation sponsored Research Coordination Network (EFI-RCN; https://ecoforecast.org/rcn/). Data used in the challenge from National Ecological Observatory Network (NEON): https://www.neonscience.org/. 5.7 References Bousquet, Y. (2012) Catalogue of Geadephaga (Coleoptera: Adephaga) of America, north of Mexico. ZooKeys 245: 1-1722. https://doi.org/10.3897/zookeys.245.3416 Butterfield, J., Luff, M., Baines, M., Eyre, M. (1995) Carabid beetle communities as indicators of conservation potential in upland forests. Forest Ecology and Management 79, 63-77. https://doi.org/10.1016/0378-1127(95)03620-2 Dietze, M.C., Fox, A., Beck-Johnson, L.M., Betancourt, J.L., Hooten, M.B., Jarnevich, C.S., Keitt, T.H., Kenney, M.A., Laney, C.M., Larsen, L.G. (2018) Iterative near-term ecological forecasting: Needs, opportunities, and challenges. Proceedings of the National Academy of Sciences 115, 1424-1432. https://doi.org/10.1073/pnas.1710231115 Gneiting, T., &amp; Raftery, A. E. (2007). Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477), 359–378. https://doi.org/10.1198/016214506000001437 Hoekman, D., LeVan, K.E., Gibson, C., Ball, G.E., Browne, R.A., Davidson, R.L., Eriwin, T.L., Knisley, C.B., LaBonte, J.R., Lundgren, J., Maddison, D.R., Moore, W., Niemela, J., Ober, K.A., Pearson, D.L. Spence, J.R., Will, K., Work, T. (2017) Design for ground beetle abundance and diversity sampling within the National Ecological Observatory Network. Ecosphere, 8(4), e01744. https://doi.org/10.1002/ecs2.1744 Holland, J.M. (2002) The agroecology of carabid beetles. Intercept Limited, Andover. Humphries, G.R., Che-Castaldo, C., Bull, P., Lipstein, G., Ravia, A., Carrión, B., Bolton, T., Ganguly, A., Lynch, H.J. (2018) Predicting the future is hard and other lessons from a population time series data science competition. Ecological Informatics 48, 1-11. https://doi.org/10.1016/j.ecoinf.2018.07.004 Johansson, M.A., Apfeldorf, K.M., Dobson, S., Devita, J., Buczak, A.L., Baugher, B., Moniz, L.J., Bagley, T., Babin, S.M., Guven, E. (2019) An open challenge to advance probabilistic forecasting for dengue epidemics. Proceedings of the National Academy of Sciences 116, 24268-24274. https://doi.org/10.1073/pnas.1909865116 Koivula, M.J. (2011) Useful model organisms, indicators, or both? Ground beetles (Coleoptera, Carabidae) reflecting environmental conditions. ZooKeys, 287-317. https://doi.org/10.3897/zookeys.100.1533 Lundgren, J., McCravy, K. (2011) Carabid beetles (Coleoptera: Carabidae) of the Midwestern United States: A review and synthesis of recent research. Terrestrial arthropod reviews 4, 63-94. https://doi.org/10.1163/187498311X565606 Magura, T. (2002) Carabids and forest edge: spatial pattern and edge effect. Forest Ecology and Management 157, 23-37. https://doi.org/10.1016/S0378-1127(00)00654-X Pearce, J.L., Venier, L.A. (2006) The use of ground beetles (Coleoptera: Carabidae) and spiders (Araneae) as bioindicators of sustainable forest management: A review. Ecological Indicators 6, 780-793. https://doi.org/10.1016/j.ecolind.2005.03.005 Sauberer, N., Zulka, K.P., Abensperg-Traun, M., Berg, H.-M., Bieringer, G., Milasowszky, N., Moser, D., Plutzar, C., Pollheimer, M., Storch, C. (2004) Surrogate taxa for biodiversity in agricultural landscapes of eastern Austria. Biological Conservation 117, 181-190. https://doi.org/10.1016/S0006-3207(03)00291-X Schimel, D., Hargrove, W., Hoffman, F., MacMahon, J. (2007) NEON: a hierarchically designed national ecological network. Frontiers in Ecology and the Environment 5, 59-59. https://doi.org/10.1890/1540-9295(2007)5[59:NAHDNE]2.0.CO;2 Schimel, D., Keller, M., Berukoff, S., Hufft, R., Loescher, H., Powell, H., Kampe, T., Moore, D., Gram, W. (2011) NEON Science Strategy: Enabling Continental-Scale Ecological Forecasting. https://www.neonscience.org/sites/default/files/basic-page-files/NEON_Strategy_2011u2_0.pdf "],["participation.html", "6 Participation 6.1 Participation guidance 6.2 Participation agreement 6.3 NEON Data Use 6.4 Additional data options", " 6 Participation 6.1 Participation guidance 6.1.1 How to participate Participation requires that teams: Complete a REGISTRATION for each forecast theme you are participating in and each model you are contributing within a theme Agree to the participation agreement below Submit forecast netCDF or csv file(s) Provide the metadata xml file documenting the forecast One contact person should register on behalf of their team. That contact person will be asked to provide the group members’ names, emails, and affiliations so that everyone in the group can receive an invitation to join the Challenge theme Slack channel and access group resources. Teams are allowed and encouraged to join the challenge after the start date of each Challenge theme because there are multiple deadlines to submit forecasts. However, only forecasts submitted by each submission deadline will be officially scored. 6.1.2 Teams Teams can be individuals or groups. They can represent institutions or organizations. You will have 25 characters for a team name (e.g., “EFI Null Model”) and 10 characters for the team name ID (no spaces allowed; e.g., EFI_Null). The registration includes team categories (e.g., undergraduate only, graduate only, multi-institution, etc). Please check all that apply. If your team wants to submit multiple forecasts, please register a team for each model as only one forecast model per cycle per team is allowed. If there are two different time steps in a challenge theme (e.g., the terrestrial carbon flux theme has a 30-minute and 1-day option), register each as separate teams. 6.1.3 Slack and GitHub Communication We strongly encourage participants to use the Challenge theme Slack channels to ask questions, discuss ideas and challenges, and share resources. Overall, we strongly encourage a collegial approach to the Challenge – this is a friendly competition to move the field forward and bring more people into the community, not a cutthroat competition to win by denying other teams useful information. GitHub repositories for each Challenge theme will be available with helper code and an example workflow (null models). We encourage teams to contribute code to these repositories (via Pull Request) if they develop additional helper code. This is especially important if an individual or group is going to add additional data constraints to their forecast. Remember, the use of data external to NEON is allowed and encouraged so long as it is publicly available and other teams are notified about it. Also, while most anything could be used to calibrate parameters and constrain initial conditions, only other forecasts (e.g. weather) can be used as drivers/covariates during the actual forecast period. 6.1.4 Archiving models Teams are highly encouraged to publicly archive the code they are using for their forecast models and workflows. Information about where models are archived would be included in your metadata XML. Teams are also encouraged to use Docker or Singularity to containerize their models &amp; workflows. EFI conventions for containerizing forecasts are still being developed, but our aim (particularly in later years of the forecast challenge) is to be able to provide shared cyberinfrastructure that makes it easier for teams to automate containerized forecasts. Containers will also facilitate Challenge themes interested in performing post-hoc analyses, such as uncertainty quantification and sensitivity analysis. 6.1.5 Computational reesources We are currently working with CyVerse for access to computational resources for teams that require resources not available through home institutions. We will update with more details as they become available. 6.2 Participation agreement All participants agree to have their forecast posted in real-time on the NEON Ecological Forecast Challenge Output RShiny app (in development) and potentially published in a scientific journal. The manuscripts describing the accuracy of forecasts across teams will be coordinated by the Ecological Forecasting Initiative Research Coordination Network and extend authorship to members of each team with an opt-in policy. If a publication is generated by a forecast team, we ask that the manuscript acknowledge the Ecological Forecasting Initiative Research Coordination Network and its support from the National Science Foundation (DEB-1926388). 6.3 NEON Data Use NEON data products, software, and derivatives thereof are freely available for use when accompanied by appropriate disclaimers, acknowledgments, and data citations, defined in the NEON data use policy. 6.4 Additional data options Individuals and groups may create forecasts that use other publicly available data in addition to the NEON data, so long as other teams participating in the challenge are notified about the existence of the data via the Challenge theme’s Slack channel. Teams are encouraged to make available the code they are using to access, download, and process any additional data constraints they are using, ideally via a pull request to each Challenge Github repo. When considering the use of data in forecasts it is important to distinguish data that are being used as drivers/covariates during each forecast from data being used to constrain model structure, parameters, initial conditions, and error distributions. While the latency of NEON data requires that some of our forecast will be (fully or partly) hindcasts, all forecasts should be run as if they are true forecasts – you cannot use any observed data as a driver/covariate or constraint during the forecast period itself as that info would not have been available at the forecast start date. For example, if you find that a particular variable is a useful covariate during the model development &amp; calibration period (e.g. soil temperature) then you would need to find or make a forecast of that variable if you want to use it as a covariate. Teams using meteorological covariates should use the shared meteorological driver data provided by EFI (see Shared Forecast Drivers). As an example of potentially useful external data, each NEON site has subsets of various remote sensing products that are hosted on the ORNL DAAC (ORNL DAAC subsets). These include: MODIS collection 6: LAI, FPAR, burned area, surface reflectance, land surface temperature, vegetation indices (NDVI, EVI), modeled ET, GPP, NPP. VIIRS collection 1: surface reflectance, vegetation indices, LAI, FPAR, land surface temperature, SMAP: modeled NEE, GPP, Rh, SOC Daymet: daily surface weather data "],["submission-instructions.html", "7 Submission instructions", " 7 Submission instructions 7.0.1 Forecast format Teams will submit their forecasts as a single netCDF or csv file with the following naming convention: theme_name-year-month-day-team_name_ID.csv or theme_name-year-month-day-team_name_ID.nc Where year, month, and day are the year, month, and day for the first day of the submitted forecast and the team_name_ID is the code for the team name that is specified in the registration (team_name_ID is a 10 character name with no spaces in it). The theme_name options are: terrestrial_daily, terrestrial_30min, aquatics, beetles, ticks, or phenology. Forecast netCDF or csv files should have the following columns (csv) or variables (netcdf) that correspond to the columns. 7.0.1.1 Terrestrial time: YYYY-MM-DD HH:MM UTC of the start of the 30-minute value or YYYY-MM-DD for daily forecasts siteID: NEON code for site ensemble*: integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample) forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: set as 0 for each row (0 = no data assimilation occurred because it is a forecast) nee: net ecosystem exchange (umol CO2 m-2 s-1) le: latent heat (W m-2) vswc: volumetric soil water content (%) 7.0.1.2 Beetles time: YYYY-MM-DD of forecast (where the DD is the first day of the week that is forecasted) siteID: NEON code for site ensemble*: integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample) forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: set as 0 for each row (0 = no data assimilation occurred because it is a forecast) abundance: abundance of beetles richness: species richness of beetles 7.0.1.3 Aquatics time: YYYY-MM-DD of forecast siteID: NEON code for site ensemble*: integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample) forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: set as 0 for each row (0 = no data assimilation occurred because it is a forecast) oxygen: dissolved oxygen (ug/L) temp: water temperature (C) Here is an example of a forecast file that meets the standard for the aquatics theme readr::read_csv(&quot;https://data.ecoforecast.org/forecasts/aquatics/aquatics-2021-03-01-EFInull.csv.gz&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## time = col_date(format = &quot;&quot;), ## ensemble = col_double(), ## siteID = col_character(), ## oxygen = col_double(), ## temperature = col_double(), ## obs_flag = col_double(), ## forecast = col_double(), ## data_assimilation = col_double() ## ) ## # A tibble: 28,000 x 8 ## time ensemble siteID oxygen temperature obs_flag forecast ## &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2021-03-01 1 BARC 8.98 19.1 2 1 ## 2 2021-03-01 2 BARC 8.67 21.6 2 1 ## 3 2021-03-01 3 BARC 8.73 28.9 2 1 ## 4 2021-03-01 4 BARC 8.12 28.2 2 1 ## 5 2021-03-01 5 BARC 8.18 17.6 2 1 ## 6 2021-03-01 6 BARC 8.70 34.1 2 1 ## 7 2021-03-01 7 BARC 8.83 14.9 2 1 ## 8 2021-03-01 8 BARC 8.25 23.7 2 1 ## 9 2021-03-01 9 BARC 8.47 15.0 2 1 ## 10 2021-03-01 10 BARC 8.68 26.3 2 1 ## # … with 27,990 more rows, and 1 more variable: data_assimilation &lt;dbl&gt; 7.0.1.4 Phenology time: YYYY-MM-DD siteID: NEON code for site ensemble*: integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample) forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: set as 0 for each row (0 = no data assimilation occurred because it is a forecast) gcc_90: green chromatic coordinate Here is an example of a forecast file that meets the standard for the phenology theme 7.0.1.5 Ticks time: YYYY-MM-DD of forecast (where the DD is the first day of the week that is forecasted) siteID: NEON code for site plotID: NEON plotID ensemble*: integer value for forecast replicate within the year and month (i.e. ensemble member or MCMC sample) forecast: set as 1 for each row (1 = variables were forecasted; a 0 would designate a hindcast which does not apply to submissions to the challenge) data_assimilation: set as 0 for each row (0 = no data assimilation occurred because it is a forecast) amblyomma_americanum: Number of Amblyomma americanum nymphs per plot per week ixodes_scapularis: Number of Ixodes scapularis nymphs per plot per week *Teams that are NOT using ensemble-based forecast methods should replace the ensemble column with a statistic column. Multiple statistics can be reported using a long format in a csv or adding a statistic dimension in netCDF. The required options for this column are mean and sd (standard deviation). You can also include Conf_interv_02.5, Conf_interv_97.5, Pred_interval_02.5, and Pred_interval_97.5 to describe uncertainty but these are optional. The numbers in the last four options indicate equal-tail quantiles for a 95% interval estimate and Conf_=confidence and Pred_=predictive. If statistics are reported we will make a Gaussian assumption when calculating error scores. The Continuous Ranked Probability Score is based on the predictive distribution so reported sd should be for the predictive distribution. For those using netCDF, the order of dimensions on forecast variables should be: time, site, plot [ticks only], and ensemble. In practice using a netCDF for the forecast forecast with the statistic rather than ensemble is not ideal. Additional detail about file formats can be found in the EFI Forecast Standard Documentation. 7.0.2 Metadata format Each submission requires a metadata file to be submitted. The metadata file must have the same name as the submitted forecast, but with the .xml extension. Model descriptions can be uploaded to https://data.ecoforecast.org/minio/submissions/ theme_name-year-month-day-team_name_ID.xml The metadata standard has been designed by the Ecological Forecasting Initiative and is build off the widely used Ecological Metadata Language (EML). The following components are required: - Title - pubDate: date that forecast is generated - License: See below for details - Creator(s) - Spatial and temporal coverage - File descriptions - Model timestep - forecast_horizon (length) - forecast_issue_time - forecast_iteration_id - forecast_project_id: team_name_ID (e.g., EFI_NULL) - model_description which includes: forecast_model_id, model name, type (statistical, process-based, machine-learning, etc), and repository (url or DOI). - Info on model structure and uncertainty (standards section 2.1.2) The license for the forecast output is required to be from the following Creative Commons License options: CC BY, CC BY-SA, CC BY-NC, CC BY-NC-SA. While we recommend a CC BY license, teams may use less permissive CC licenses if more appropriate. The license entry can be the CC option (i.e., CC BY) and a web link to the full CC license (e.g., https://creativecommons.org/licenses/by/4.0/) We recommend teams read the full metadata standard description for definitions and more information, and in particular that they look at the example vignettes, which demonstrate the standard being used. Note that these Standards are a work in progress. If you find issues as you are applying them, let us know at eco4cast.initaitive@gmail.com. The Ecological Forecasting Initiative has provided R scripts to assist in generating the metadata XML file. The scripts can be found at the GitHub repository for the standard: https://github.com/eco4cast/EFIstandards as well as the EML validator. Teams are encouraged to check the validity of their metadata before submission. 7.0.3 Submission process Individual forecast (csv, netCDF) and metadate (xml) files can be uploaded any time before the specific deadlines as defined by each theme. Only the most recent files will be scored. Teams will submit their forecast netCDF or csv files through the challenge website. You can manually submit your forecast through the https://data.ecoforecast.org/minio/submissions/ website using the red plus on the bottom left. You can submit from an R script using the following: Sys.setenv(&quot;AWS_DEFAULT_REGION&quot; = &quot;data&quot;, &quot;AWS_S3_ENDPOINT&quot; = &quot;ecoforecast.org&quot;) aws.s3::put_object(object = &quot;theme_name-forecast-year-month-day-team_name.csv&quot;, bucket = &quot;submissions&quot;) Submissions need to adhere to the forecast format that is provided above, including the file naming convention. Our cyberinfastructure automatically evaluates forecasts and relies on the expected formatting. Contact eco4cast.initiative@gmail.com if you experience technical issues with submitting. Note: If you have used AWS in the past you might have credential files in an .aws folder in your home directory that will cause an error when you try to upload to a non-AWS bucket. If you encounter this error you may need to rename your credentials files so put_object doesn’t try to read them. "],["shared-forecast-drivers.html", "8 Shared Forecast Drivers 8.1 Meteorology: NOAA Global Ensemble Forecasting System 8.2 Meteorology: NEON Observed", " 8 Shared Forecast Drivers We are downloading, subsetting, and processing forecasted meteorology drivers for each NEON site. Currently, we have NOAA’s Global Ensemble Forecasting System V12 output available at the 1 hr time resolution for each NEON site. For forecasts generated at midnight (00) UTC, the forecasts extend 35-days in the future. For forecasts generated at 06, 12, and 18 UTC, the forecasts extend 16-days in the future. There are 31 ensemble members for each forecast. Each ensemble member is available as a separate netcdf file. The following meteorological variables are included: air temperature, air pressure, wind speed, precipitation, downwelling longwave radiation, downwelling shortwave radiation, relative humidity, specific humidity, and total cloud cover. The weather forecasts are available through an s3 bucket (see Meteorology: NOAA Global Ensemble Forecasting System below) with multiple ways to access them: You can click on a file in the browser, you can directly download individual files from the command line using the file address, or you can download multiple files using aws.s3 commands. We provide an example using the aws.s3 package in R for downloading all the ensemble members for particular location, forecast cycle (00, 06, 12, or 18), and NEON site at: https://github.com/eco4cast/neon4cast-shared-utilities/blob/main/download_noaa_files_s3.R Additionally we provide example code in R for converting the netcdf files to csv files https://github.com/eco4cast/neon4cast-shared-utilities/blob/main/noaa_gefs_read_example.R https://github.com/eco4cast/neon4cast-shared-utilities/blob/main/noaa_gefs_read.R 8.1 Meteorology: NOAA Global Ensemble Forecasting System 1 Hour NOAA Drivers 8.2 Meteorology: NEON Observed In development through collaboration with NEON and NCAR. "],["evaluation.html", "9 Evaluation 9.1 Results 9.2 Scoring Metric: Continuous Ranked Probability Score 9.3 Null forecast 9.4 Forecast Submission Visualization and Leaderboard", " 9 Evaluation Forecasts will be evaluated at each site and forecast horizon (i.e., time-step into the future), and a summary score will be assigned evaluating overall performance of all forecast submissions across sites. Forecasts will also be compared to a null model. Forecast evaluation results will be presented for all submitted models together and separately for each team category: undergraduate student only team, graduate student only team, post-doc only team, single institution team, multi-institution team, international team (team with individuals from at least two countries). 9.1 Results Preliminary results will be distributed using the NEON Ecological Forecast Challenge Output RShiny app and at https://data.ecoforecast.org/minio/scores/. We intend to write a joint manuscript synthesizing forecasts. Teams are welcome to publish results from their model at any time. If a publication is generated we encourage the manuscript to acknowledge the Ecological Forecasting Research Coordination Network and its support from the National Science Foundation (DEB-1926388). 9.2 Scoring Metric: Continuous Ranked Probability Score Forecasts will be scored using the continuous ranked probability score (CRPS), a proper scoring rule for evaluating forecasts presented as distributions or ensembles (Gneiting &amp; Raftery 2007). The CRPS compares the forecast probability distribution to that of the validation observation and assigns a score based on both the accuracy and precision of the forecast. We will use the ‘crps_sample’ function from the scoringRules package in R to calculate the CRPS for each forecast. We will generate a combined score for all locations and forecast horizons. Forecasts will also be evaluated using the CRPS at each time-step in the forecast horizon and each location included in the forecasts. 9.2.1 Example of a CRPS calculation from an ensemble forecast The following uses Equation 2 in Jordan, Kruger, and Lerch 2018 Equation 1 from Jordan, Kruger, and Lerch 2018. First, create a random sample from a probability distribution. This is the “forecast” for a particular point in time. For simplicity, we will use a normal distribution with a mean of 8 and standard deviation of 1 x &lt;- rnorm(1000, mean = 8, sd = 1.0) Second, we have our data point (i.e., the target). We will set it to zero as well y &lt;- 8 Now calculate CRPS using Equation 2 s &lt;- 0 for(i in 1:length(x)){ for(j in 1:length(x)){ s &lt;- s + abs(x[i] - x[j]) } } crps_equation_2 &lt;- mean(abs(x - y)) - s / (2 * length(x)^2) crps_equation_2 ## [1] 0.2285474 Now calculate using the crps_sample() function in the scoringRules package crps_sample(y = y, dat = x) ## [1] 0.2285474 9.2.2 Exploring the scoring surface Now lets see how the CRPS changes as the mean and standard deviation of the forecasted distribution change First, set vectors for the different mean and SD values we want to explore sample_mean &lt;- seq(4, 12, 0.1) sample_sd &lt;- seq(0.1, 10, 0.1) Second, set our observed value to 8 for simplicity y &lt;- 8 Now calculate the CRPS at each combination of forest mean and SD combined &lt;- array(NA, dim = c(length(sample_mean), length(sample_sd))) for(i in 1:length(sample_mean)){ for(j in 1:length(sample_sd)){ sample &lt;- rnorm(10000, sample_mean[i], sample_sd[j]) combined[i, j] &lt;- crps_sample(y = y, dat = sample) } } Finally, visualize the scoring surface with the observed value represented by the red line contour(x = sample_mean, y = sample_sd, z = as.matrix(combined),nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;) abline(v = y, col = &quot;red&quot;) The contour surface highlights the trade-off between the mean and standard deviation. 9.2.3 CRPS from the Normal Distribution If the distributional forecast is a normal distribution represented by a mean \\(\\mu\\) and standard deviation \\(\\sigma\\), an ensemble of predictions is not needed to evaluate CRPS because we can take advantage of the analytic solution to CRPS under the normal assumption (Equation 4 from Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum CRPS Estimation). Equation 5 from Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum CRPS Estimation gives \\[\\begin{align*} CRPS(N(\\mu, \\sigma^2) | y) = \\sigma \\left( \\frac{y - \\mu}{\\sigma} \\left( 2 \\Phi\\left( \\frac{y - \\mu}{\\sigma} \\right) - 1 \\right) + 2 \\phi \\left( \\frac{y - \\mu}{\\sigma} \\right) - \\frac{1}{\\sqrt{\\pi}} \\right) \\end{align*}\\] for \\(\\Phi(\\cdot)\\) and \\(\\phi(\\cdot)\\) the standard normal CDF and PDF, respectively. Therefore, if the forecast distribution is truly a normal distribution (often this isn’t true in forecasts that only report a mean and sd) a simplified score can be applied as follows: sample_mean &lt;- seq(4, 12, 0.1) sample_sd &lt;- seq(0.1, 10, 0.1) combined_norm &lt;- array(NA, dim = c(length(sample_mean), length(sample_sd))) for(i in 1:length(sample_mean)){ for(j in 1:length(sample_sd)){ combined_norm[i, j] &lt;- crps_norm(y = y, mean = sample_mean[i], sd = sample_sd[j]) } } Finally, visualize the scoring surface with the observed value represented by the red line contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;) abline(v = y, col = &quot;red&quot;) Note that at a given value of the sd, the lowest score is achieved at \\(\\mu = y\\) as shown for each of the blue lines where the minmum value of the score across each blue line is at the red line. This behavior make sense because the CRPS is a score that reward accuracy and precision. Thus, for any given level of precision (represented by the standard deviation), CRPS is optimized by producing the most accurate prediction of the distribution’s location. contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;) abline(v = y, col = &quot;red&quot;) abline(h = 2.5, col = &quot;blue&quot;) abline(h = 4.3, col = &quot;blue&quot;) abline(h = 6.8, col = &quot;blue&quot;) Interestingly, for a given mean \\(\\mu \\neq y\\) we find a pattern that makes intuitive sense given the goal of CRPS to produce forecasts that are both accurate and precise. For a given amount of bias in the prediction (i.e., given a \\(\\mu \\neq y\\)), the optimal score is achieved by a standard deviation that slightly larger than the bias layout(matrix(1:4, 2, 2, byrow = TRUE)) ## plots for mu = 7 mu &lt;- 7 contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;, main = paste0(&quot;CRPS contour given mu = &quot;, mu)) abline(v = mu, col = &quot;red&quot;) min_sd &lt;- sample_sd[which.min(crps_norm(y, mean = mu, sd = sample_sd))] abline(h = min_sd, col = &quot;blue&quot;) plot(sample_sd, crps_norm(y, mean = mu, sd = sample_sd), type = &#39;l&#39;, main = paste0(&quot;CRPS profile given mu = &quot;, mu)) abline(v = min_sd, col = &quot;blue&quot;) ## plots for mu = 11 mu &lt;- 11 contour(x = sample_mean, y = sample_sd, z = as.matrix(combined_norm), nlevels = 20, xlab = &quot;Mean&quot;, ylab = &quot;SD&quot;, main = paste0(&quot;CRPS contour given mu = &quot;, mu)) abline(v = mu, col = &quot;red&quot;) min_sd &lt;- sample_sd[which.min(crps_norm(y, mean = mu, sd = sample_sd))] abline(h = min_sd, col = &quot;blue&quot;) plot(sample_sd, crps_norm(y, mean = mu, sd = sample_sd), type = &#39;l&#39;, main = paste0(&quot;CRPS profile given mu = &quot;, mu)) abline(v = min_sd, col = &quot;blue&quot;) Next, we plot the relationship between a given value of \\(\\mu\\) and the \\(\\sigma\\) that produces the optimal CRPS. This looks like a linear relationship. optimal_sd &lt;- rep(0, length(sample_mean)) for (i in 1:length(sample_mean)) { optimal_sd[i] &lt;- sample_sd[which.min(crps_norm(y, mean = sample_mean[i], sd = sample_sd))] } plot(sample_mean, optimal_sd, type = &#39;l&#39;) Let’s estimate the slope of the relationship. It looks like the optimal \\(sd\\) for a normal distribution forecast that is biased by \\(|y - \\mu|\\) is \\(sd = 1.2|y - \\mu|\\) which makes sense as this would put the true value in a region of high probability. coef(lm(optimal_sd[sample_mean &gt; 0] ~ sample_mean[sample_mean &gt; 0])) ## (Intercept) sample_mean[sample_mean &gt; 0] ## 2.430864e+00 -1.688326e-16 9.3 Null forecast All forecasts will be compared to a null forecast produced by a simple historical-means calculation or a random walk. The GitHub repository for each theme has the code for the null model. 9.4 Forecast Submission Visualization and Leaderboard The dashboard shows the forecast submissions by each team for each forecast theme by date and forecast variable. It also provides the CRPS scores for each submitted forecast. "],["helpful-functions.html", "10 Helpful functions", " 10 Helpful functions Pending: Adding examples of helpful functions "],["frequently-asked-questions.html", "11 Frequently Asked Questions", " 11 Frequently Asked Questions Pending "]]
