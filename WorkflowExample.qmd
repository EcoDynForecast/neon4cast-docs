# Example Forecast Workflow {#sec-example}

Here is an example of a complete workflow for generating a forecast submission to the Challenge. The example is for the aquatics theme and it forecasts water temperature and oxygen. The water temperature forecast uses a linear regression between air temperature and water temperature to predict water temperature in the future. It then uses the prediction of water temperature to predict oxygen water oxygen concentration by assuming that the oxygen is 100% saturated given the predicted temperature.

To generate the forecast we need to:

1)  Build a relationship between past air temperature and past water temperature.\
2)  Apply the relationships from #1 to forecasted air temperature.\
3)  Calculate oxygen concentration from the forecasted water temperature.

Therefore we need to:

1)  Download the historical water temperature data for the NEON sites (called "targets").\
2)  Download historical air temperature data for the NEON sites (we the stacked NOAA GEFS weather).\
3)  Download NOAA weather forecast for the NEON sites.\
4)  Create linear regression model based on historical data for each NEON site.\
5)  Apply linear regression to using weather forecasts for each NEON.\
6)  Write forecast output file.\
7)  Submit forecast to Challenge.

Each of these steps are below

## Step 0: Set up R environment and directories

We will be downloading NOAA forecasts from the Challenge s3 bucket and submitting to the s3 bucket. Therefore the AWS information is needed.

```{r eval = FALSE}
library(tidyverse)
library(neon4cast)
library(lubridate)
library(rMR)
library(arrow)
```

Define the date that the forecast starts. For demonstration purposes, we are setting the date to `2022-02-15`. In a real-time application, use `forecast_date <- Sys.Date()` or `forecast_date <- Sys.Date() - lubridate::days(1)` (in some cases the NOAA data the current day is not available by the time you run your forecast).

```{r eval = FALSE}
forecast_date <- lubridate::as_date("2022-02-15")  
```

## Step 0: Define team name

```{r eval = FALSE}
model_id <- "neon4cast-example"
```

## Step 1: Complete metadata

Complete the Google Form that defines your model.

## Step 2: Download latest target data and site description data

These targets are updated when new data is available from NEON.

```{r eval = FALSE}
target <- readr::read_csv("https://data.ecoforecast.org/neon4cast-targets/aquatics/aquatics-targets.csv.gz", guess_max = 1e6)
```

A table is available with NEON site descriptions. The calculation of oxygen saturation requires the elevation of each site, which is included in the site description table.

```{r eval = FALSE}
site_data <- readr::read_csv("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/main/NEON_Field_Site_Metadata_20220412.csv") |> 
  filter(aquatics == 1)
```

## Step 3: Get drivers

### Step 3.1: Download Paste NOAA forecast stacked together

To build the relations between air and water temperature, we need historical air temperature data to associate with historical water temperature data. Here we use a product that the Challenge organizers created that combines day 1 NOAA weather forecasts (i.e., when the forecasts are most accurate) together to generate an estimate of past weather. He we download this "stack" NOAA product for the set of NEON sites in the targets file.

```{r eval = FALSE}
sites <- unique(target$site_id)
df_past <- neon4cast::noaa_stage3()
noaa_past <- df_past |> 
  dplyr::filter(site_id %in% sites,
                variable == "air_temperature") |> 
  dplyr::rename(ensemble = parameter) |> 
  dplyr::collect()
```

### Step 3.2: Download NOAA future forecast

We need NOAA Weather forecasts of the future. Fortunately, the Challenge organizers are downloading and subsetting the weather forecasts for each NEON site. Here we download the weather forecast (`start_date = forecast_date`) that started at mid-night UTC (`cycle=0`) for the set of sites in the target file.

```{r eval = FALSE}
df_future <- neon4cast::noaa_stage2(cycle = 0)
noaa_future <- df_future |> 
  dplyr::filter(start_date == forecast_date,
                variable == "air_temperature") |> 
  dplyr::rename(ensemble = parameter) |> 
  dplyr::collect()
```

### Step 3.3 Aggregate (to day) and convert units of drivers

Since we are forecasting daily mean water temperature and oxygen, we need to aggregate the 1 hr weather data to the daily time-scale. We also need to convert from Kelvin to Celsius.

```{r eval = FALSE}
noaa_past_mean <- noaa_past |> 
  mutate(date = as_date(time)) |> 
  group_by(date, site_id) |> 
  summarize(air_temperature = mean(predicted, na.rm = TRUE), .groups = "drop") |> 
  rename(datetime = date) |> 
  mutate(air_temperature = air_temperature - 273.15)

```

For the future weather has 31 ensemble members (i.e., different trajectories of weather), that we want to use to generate uncertainty in our water temperature and oxygen forecasts. The aggregation below maintains the separate ensemble members (`group_by(date, ensemble)`).

```{r eval = FALSE}
noaa_future <- noaa_future |> 
  mutate(datetime = as_date(time)) |> 
  group_by(datetime, site_id, ensemble) |> 
  summarize(air_temperature = mean(predicted)) |> 
  mutate(air_temperature = air_temperature - 273.15) |> 
  select(datetime, site_id, air_temperature, ensemble)
```

### Step 3.4: Merge in past NOAA data into the targets file, matching by date.

Before building our linear model we need merge in the historical air temperature to match with the historical water temperature

```{r eval = FALSE}
target <- target |> 
  select(datetime, site_id, variable, observed) |> 
  filter(variable %in% c("temperature", "oxygen")) |> 
  pivot_wider(names_from = "variable", values_from = "observation")

target <- left_join(target, noaa_past_mean, by = c("datetime","site_id"))
```

## Step 4.0: Generate forecasts for each site

We generate a forecast for each site.

```{r eval = FALSE}
forecast <- NULL

for(i in 1:length(sites)){
  
  # Get site information for elevation
  site_info <- site_data %>% filter(field_site_id == sites[i]) 
  
  site_target <- target |> 
    filter(site_id == sites[i])
  
  noaa_future_site <- noaa_future |> 
    filter(site_id == sites[i])
  
  if(length(which(!is.na(site_target$air_temperature) & !is.na(site_target$temperature))) > 0){
    
    #Fit linear model based on past data: water temperature = m * air temperature + b
    fit <- lm(site_target$temperature~site_target$air_temperature)
    
    #use linear regression to forecast water temperature for each ensemble member
    forecasted_temperature <- fit$coefficients[1] + fit$coefficients[2] * noaa_future_site$air_temperature
    
    #use forecasted temperature to predict oyxgen by assuming that oxygen is saturated.  
    forecasted_oxygen <- rMR::Eq.Ox.conc(forecasted_temperature, elevation.m = ,site_info$field_mean_elevation_m, 
                                         bar.press = NULL, 
                                         bar.units = NULL,
                                         out.DO.meas = "mg/L",
                                         salinity = 0, 
                                         salinity.units = "pp.thou")
    
    temperature <- tibble(datetime = noaa_future_site$datetime,
                          site_id = sites[i],
                          ensemble = noaa_future_site$ensemble,
                          prediction = forecasted_temperature,
                          variable = "temperature")
    
    oxygen <- tibble(datetime = noaa_future_site$datetime,
                     site_id = sites[i],
                     ensemble = noaa_future_site$ensemble,
                     prediction = forecasted_oxygen,
                     variable = "oxygen")
    
    
    #Build site level dataframe.  Note we are not forecasting chla
    forecast <- dplyr::bind_rows(forecast, temperature, oxygen)
  }
}
```

Make sure columns match the required standard that has a `family` column and a `parameter` column

```{r eval = FALSE}
forecast <- forecast |> 
  mutate(reference_datetime = forecast_date,
         family = "ensemble",
         model_id = model_id) |> 
  rename(parameter = ensemble) |> 
  select(model_id, datetime, reference_datetime, site_id, family, parameter, variable, prediction)
```

Use ggplot to visualize the forecast for each variable and site. The spread in forecast is due to uncertainty in the weather forecast, where each line is associated with a different NOAA GEFS weather forecast ensemble member.

```{r eval = FALSE}
forecast %>% 
  ggplot(aes(x = datetime, y = predicted, group = parameter)) +
  geom_line() +
  facet_grid(variable~site_id, scale ="free")
```

Forecast output file name in standards requires for Challenge. "csv.gz" means that it will be compressed

```{r eval = FALSE}
file_date <- forecast$reference_datetime[1]
forecast_file <- paste0("aquatics","-",file_date,"-",model_id,".csv.gz")
```

Write csv to disk

```{r eval = FALSE}
write_csv(forecast, forecast_file)
```

Confirm that output file meets standard for Challenge

```{r eval = FALSE}
neon4cast::forecast_output_validator(forecast_file)
```

## Step 5: Submit forecast!

Now we can submit the forecast output and the metadata file to the Challenge using the `neon4cast::submit()` function

```{r eval = FALSE}
neon4cast::submit(forecast_file = forecast_file, ask = FALSE)
```

You can check on the status of your submission using

```{r eval = FALSE}
neon4cast::check_submission(forecast_file)
```

On following day after submission, you can see the forecast on the dashboard at [shiny.ecoforecast.org](https://shiny.ecoforecast.org)

## Example on github

The example code above can be found on [GitHub as a template repository](https://github.com/eco4cast/neon4cast-example.git). See the Readme for more information about using the template
